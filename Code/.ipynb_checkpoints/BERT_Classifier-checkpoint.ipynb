{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "eLrzqIEIZaq0"
   },
   "source": [
    "<p>Using code from: https://mccormickml.com/2019/07/22/BERT-fine-tuning/</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "foOutumNZaq1",
    "outputId": "daaba730-cf6d-4a4d-a760-f8b57891a9f2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
     ]
    }
   ],
   "source": [
    "# import libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "#!conda install -y tensorflow\n",
    "#!conda install -y pytorch torchvision -c pytorch\n",
    "#!pip install transformers\n",
    "import tensorflow as tf\n",
    "import torch\n",
    "\n",
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 279
    },
    "id": "FyJyM0PAcJf0",
    "outputId": "46ce49c7-15e1-4e76-aba4-8f916ae58177"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>rev_id</th>\n",
       "      <th>comment</th>\n",
       "      <th>year</th>\n",
       "      <th>logged_in</th>\n",
       "      <th>ns</th>\n",
       "      <th>sample</th>\n",
       "      <th>split</th>\n",
       "      <th>worker_id</th>\n",
       "      <th>toxicity</th>\n",
       "      <th>toxicity_score</th>\n",
       "      <th>gender</th>\n",
       "      <th>english_first_language</th>\n",
       "      <th>age_group</th>\n",
       "      <th>education</th>\n",
       "      <th>female_binary</th>\n",
       "      <th>male_binary</th>\n",
       "      <th>other_binary</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3467</th>\n",
       "      <td>2232.0</td>\n",
       "      <td>This: :One can make an analogy in mathematical...</td>\n",
       "      <td>2002</td>\n",
       "      <td>True</td>\n",
       "      <td>article</td>\n",
       "      <td>random</td>\n",
       "      <td>train</td>\n",
       "      <td>405</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>male</td>\n",
       "      <td>0.0</td>\n",
       "      <td>30-45</td>\n",
       "      <td>masters</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3039</th>\n",
       "      <td>2232.0</td>\n",
       "      <td>This: :One can make an analogy in mathematical...</td>\n",
       "      <td>2002</td>\n",
       "      <td>True</td>\n",
       "      <td>article</td>\n",
       "      <td>random</td>\n",
       "      <td>train</td>\n",
       "      <td>680</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>male</td>\n",
       "      <td>0.0</td>\n",
       "      <td>18-30</td>\n",
       "      <td>masters</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2232.0</td>\n",
       "      <td>This: :One can make an analogy in mathematical...</td>\n",
       "      <td>2002</td>\n",
       "      <td>True</td>\n",
       "      <td>article</td>\n",
       "      <td>random</td>\n",
       "      <td>train</td>\n",
       "      <td>723</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>female</td>\n",
       "      <td>0.0</td>\n",
       "      <td>30-45</td>\n",
       "      <td>bachelors</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2600</th>\n",
       "      <td>2232.0</td>\n",
       "      <td>This: :One can make an analogy in mathematical...</td>\n",
       "      <td>2002</td>\n",
       "      <td>True</td>\n",
       "      <td>article</td>\n",
       "      <td>random</td>\n",
       "      <td>train</td>\n",
       "      <td>772</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>male</td>\n",
       "      <td>0.0</td>\n",
       "      <td>18-30</td>\n",
       "      <td>bachelors</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2169</th>\n",
       "      <td>2232.0</td>\n",
       "      <td>This: :One can make an analogy in mathematical...</td>\n",
       "      <td>2002</td>\n",
       "      <td>True</td>\n",
       "      <td>article</td>\n",
       "      <td>random</td>\n",
       "      <td>train</td>\n",
       "      <td>1508</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>female</td>\n",
       "      <td>1.0</td>\n",
       "      <td>45-60</td>\n",
       "      <td>hs</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      rev_id  ... other_binary\n",
       "3467  2232.0  ...            0\n",
       "3039  2232.0  ...            0\n",
       "0     2232.0  ...            0\n",
       "2600  2232.0  ...            0\n",
       "2169  2232.0  ...            0\n",
       "\n",
       "[5 rows x 17 columns]"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# read files and create dataframe\n",
    "toxicity_comments = pd.read_csv('/content/drive/MyDrive/Colab Notebooks/toxicity_annotated_comments.tsv', sep = '\\t', index_col = 0)\n",
    "toxicity_annotations = pd.read_csv('/content/drive/MyDrive/Colab Notebooks/toxicity_annotations.tsv',  sep = '\\t')\n",
    "toxicity_demographics = pd.read_csv('/content/drive/MyDrive/Colab Notebooks/toxicity_worker_demographics.tsv', sep = '\\t')\n",
    "\n",
    "toxicity = toxicity_comments.merge(toxicity_annotations, how ='outer', on=\"rev_id\")\n",
    "toxicity = toxicity.merge(toxicity_demographics, how ='outer', on=\"worker_id\").sort_values(by=['rev_id','worker_id'])\n",
    "\n",
    "# remove newline and tab tokens\n",
    "toxicity['comment'] = toxicity['comment'].apply(lambda x: x.replace(\"NEWLINE_TOKEN\", \" \"))\n",
    "toxicity['comment'] = toxicity['comment'].apply(lambda x: x.replace(\"TAB_TOKEN\", \" \"))\n",
    "\n",
    "# add binary gender columns\n",
    "toxicity = pd.concat([toxicity, pd.get_dummies(toxicity.gender).rename(columns = \"{}_binary\".format)], axis = 1)\n",
    "\n",
    "# limit size of dataset for testing purposes\n",
    "toxic = toxicity[toxicity.toxicity == 1]\n",
    "nontoxic = toxicity[toxicity.toxicity == 0]\n",
    "small_toxicity = pd.concat([toxic[:2500], nontoxic[:2500]])\n",
    "\n",
    "display (toxicity.head(5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "uMItNCQcZaq3",
    "outputId": "adda9ef6-2110-4b8c-d64b-467915ff2e67"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 1 GPU(s) available.\n",
      "We will use the GPU: Tesla K80\n"
     ]
    }
   ],
   "source": [
    "# try to use gpu\n",
    "if torch.cuda.is_available():      \n",
    "    device = torch.device(\"cuda\")\n",
    "    print('There are %d GPU(s) available.' % torch.cuda.device_count())\n",
    "    print('We will use the GPU:', torch.cuda.get_device_name(0))\n",
    "\n",
    "else:\n",
    "    print('No GPU available, using the CPU instead.')\n",
    "    device = torch.device(\"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "cbHVLmF0Zaq4"
   },
   "outputs": [],
   "source": [
    "# extract relevant information\n",
    "comments = small_toxicity.comment.values\n",
    "labels = small_toxicity.toxicity.values\n",
    "female = small_toxicity.female_binary.values\n",
    "male = small_toxicity.male_binary.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Wy8-0FX4Zaq4",
    "outputId": "ade81467-9a82-4306-e60e-f711c3f31b0c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading BERT tokenizer...\n"
     ]
    }
   ],
   "source": [
    "# ! pip install transformers\n",
    "from transformers import BertTokenizer\n",
    "\n",
    "# Load the BERT tokenizer.\n",
    "print('Loading BERT tokenizer...')\n",
    "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased', do_lower_case=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "xt9loGrHZaq4",
    "outputId": "d5d4d251-a6d4-4612-bb52-f9fa11883b29"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "/usr/local/lib/python3.6/dist-packages/transformers/tokenization_utils_base.py:2022: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
      "  FutureWarning,\n"
     ]
    }
   ],
   "source": [
    "# Tokenize all of the sentences and map the tokens to their word IDs.\n",
    "input_ids = []\n",
    "attention_masks = []\n",
    "\n",
    "# For every sentence...\n",
    "for cmt in comments:\n",
    "    # `encode_plus` will:\n",
    "    #   (1) Tokenize the sentence.\n",
    "    #   (2) Prepend the `[CLS]` token to the start.\n",
    "    #   (3) Append the `[SEP]` token to the end.\n",
    "    #   (4) Map tokens to their IDs.\n",
    "    #   (5) Pad or truncate the sentence to `max_length`\n",
    "    #   (6) Create attention masks for [PAD] tokens.\n",
    "    encoded_dict = tokenizer.encode_plus(\n",
    "                        cmt,                      # Sentence to encode.\n",
    "                        add_special_tokens = True, # Add '[CLS]' and '[SEP]'\n",
    "                        max_length = 100,           # Pad & truncate all sentences.\n",
    "                        pad_to_max_length = True,\n",
    "                        return_attention_mask = True,   # Construct attn. masks.\n",
    "                        return_tensors = 'pt',     # Return pytorch tensors.\n",
    "                   )\n",
    "    \n",
    "    # Add the encoded sentence to the list.    \n",
    "    input_ids.append(encoded_dict['input_ids'])\n",
    "    \n",
    "    # And its attention mask (simply differentiates padding from non-padding).\n",
    "    attention_masks.append(encoded_dict['attention_mask'])\n",
    "\n",
    "# Convert the lists into tensors.\n",
    "input_ids = torch.cat(input_ids, dim=0)\n",
    "attention_masks = torch.cat(attention_masks, dim=0)\n",
    "labels = torch.tensor(labels)\n",
    "female = torch.tensor(female)\n",
    "male = torch.tensor(male)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "z-2y3_EaZaq4",
    "outputId": "2a88442b-7637-46c6-df01-c0d6ee67b2bf"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4,500 training samples\n",
      "  500 validation samples\n"
     ]
    }
   ],
   "source": [
    "from torch.utils.data import TensorDataset, random_split\n",
    "\n",
    "# Combine the training inputs into a TensorDataset.\n",
    "dataset = TensorDataset(input_ids, attention_masks, labels)\n",
    "\n",
    "# Create a 90-10 train-validation split.\n",
    "\n",
    "# Calculate the number of samples to include in each set.\n",
    "train_size = int(0.9 * len(dataset))\n",
    "val_size = len(dataset) - train_size\n",
    "\n",
    "# Divide the dataset by randomly selecting samples.\n",
    "train_dataset, val_dataset = random_split(dataset, [train_size, val_size])\n",
    "\n",
    "print('{:>5,} training samples'.format(train_size))\n",
    "print('{:>5,} validation samples'.format(val_size))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "WyZCsEY6Zaq4"
   },
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader, RandomSampler, SequentialSampler\n",
    "\n",
    "# The DataLoader needs to know our batch size for training, so we specify it \n",
    "# here. For fine-tuning BERT on a specific task, the authors recommend a batch \n",
    "# size of 16 or 32.\n",
    "batch_size = 16\n",
    "\n",
    "# Create the DataLoaders for our training and validation sets.\n",
    "# We'll take training samples in random order. \n",
    "train_dataloader = DataLoader(\n",
    "            train_dataset,  # The training samples.\n",
    "            sampler = RandomSampler(train_dataset), # Select batches randomly\n",
    "            batch_size = batch_size # Trains with this batch size.\n",
    "        )\n",
    "\n",
    "# For validation the order doesn't matter, so we'll just read them sequentially.\n",
    "validation_dataloader = DataLoader(\n",
    "            val_dataset, # The validation samples.\n",
    "            sampler = SequentialSampler(val_dataset), # Pull out batches sequentially.\n",
    "            batch_size = batch_size # Evaluate with this batch size\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "zo5q4EOYZaq4",
    "outputId": "2f15b7fe-f9aa-40bb-d240-e8ce0dbc2227"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForSequenceClassification: ['cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias']\n",
      "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "BertForSequenceClassification(\n",
       "  (bert): BertModel(\n",
       "    (embeddings): BertEmbeddings(\n",
       "      (word_embeddings): Embedding(30522, 768, padding_idx=0)\n",
       "      (position_embeddings): Embedding(512, 768)\n",
       "      (token_type_embeddings): Embedding(2, 768)\n",
       "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (encoder): BertEncoder(\n",
       "      (layer): ModuleList(\n",
       "        (0): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (1): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (2): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (3): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (4): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (5): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (6): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (7): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (8): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (9): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (10): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (11): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (pooler): BertPooler(\n",
       "      (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "      (activation): Tanh()\n",
       "    )\n",
       "  )\n",
       "  (dropout): Dropout(p=0.1, inplace=False)\n",
       "  (classifier): Linear(in_features=768, out_features=2, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 9,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from transformers import BertForSequenceClassification, AdamW, BertConfig\n",
    "\n",
    "# Load BertForSequenceClassification, the pretrained BERT model with a single \n",
    "# linear classification layer on top. \n",
    "model = BertForSequenceClassification.from_pretrained(\n",
    "    \"bert-base-uncased\", # Use the 12-layer BERT model, with an uncased vocab.\n",
    "    num_labels = 2, # The number of output labels--2 for binary classification.\n",
    "                    # You can increase this for multi-class tasks.   \n",
    "    output_attentions = False, # Whether the model returns attentions weights.\n",
    "    output_hidden_states = False, # Whether the model returns all hidden-states.\n",
    ")\n",
    "\n",
    "# # Tell pytorch to run this model on the GPU.\n",
    "model.cuda()\n",
    "#model.cpu()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "DcRnw83qZaq4"
   },
   "outputs": [],
   "source": [
    "# Note: AdamW is a class from the huggingface library (as opposed to pytorch) \n",
    "# I believe the 'W' stands for 'Weight Decay fix\"\n",
    "optimizer = AdamW(model.parameters(),\n",
    "                  lr = 2e-5, # args.learning_rate - default is 5e-5, our notebook had 2e-5\n",
    "                  eps = 1e-8 # args.adam_epsilon  - default is 1e-8.\n",
    "                )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "qdGUUYF6Zaq4"
   },
   "outputs": [],
   "source": [
    "from transformers import get_linear_schedule_with_warmup\n",
    "\n",
    "# Number of training epochs. The BERT authors recommend between 2 and 4. \n",
    "# We chose to run for 4, but we'll see later that this may be over-fitting the\n",
    "# training data.\n",
    "epochs = 2\n",
    "\n",
    "# Total number of training steps is [number of batches] x [number of epochs]. \n",
    "# (Note that this is not the same as the number of training samples).\n",
    "total_steps = len(train_dataloader) * epochs\n",
    "\n",
    "# Create the learning rate scheduler.\n",
    "scheduler = get_linear_schedule_with_warmup(optimizer, \n",
    "                                            num_warmup_steps = 0, # Default value in run_glue.py\n",
    "                                            num_training_steps = total_steps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "NYV8P1STZaq4"
   },
   "outputs": [],
   "source": [
    "# Function to calculate the accuracy of our predictions vs labels\n",
    "def flat_accuracy(preds, labels):\n",
    "    pred_flat = np.argmax(preds, axis=1).flatten()\n",
    "    labels_flat = labels.flatten()\n",
    "    return np.sum(pred_flat == labels_flat) / len(labels_flat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "1zbbwmVMZaq4"
   },
   "outputs": [],
   "source": [
    "import time\n",
    "import datetime\n",
    "\n",
    "def format_time(elapsed):\n",
    "    '''\n",
    "    Takes a time in seconds and returns a string hh:mm:ss\n",
    "    '''\n",
    "    # Round to the nearest second.\n",
    "    elapsed_rounded = int(round((elapsed)))\n",
    "    \n",
    "    # Format as hh:mm:ss\n",
    "    return str(datetime.timedelta(seconds=elapsed_rounded))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "zBq9WULYZaq4",
    "outputId": "ebfe9a69-1ab7-4c5a-ba9a-6664dde65153"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======== Epoch 1 / 2 ========\n",
      "Training...\n",
      "  Batch    40  of    282.    Elapsed: 0:00:23.\n",
      "  Batch    80  of    282.    Elapsed: 0:00:46.\n",
      "  Batch   120  of    282.    Elapsed: 0:01:09.\n",
      "  Batch   160  of    282.    Elapsed: 0:01:33.\n",
      "  Batch   200  of    282.    Elapsed: 0:01:56.\n",
      "  Batch   240  of    282.    Elapsed: 0:02:19.\n",
      "  Batch   280  of    282.    Elapsed: 0:02:42.\n",
      "\n",
      "  Average training loss: 0.35\n",
      "  Training epcoh took: 0:02:43\n",
      "\n",
      "Running Validation...\n",
      "  Accuracy: 0.93\n",
      "  Validation Loss: 0.19\n",
      "  Validation took: 0:00:06\n",
      "\n",
      "======== Epoch 2 / 2 ========\n",
      "Training...\n",
      "  Batch    40  of    282.    Elapsed: 0:00:23.\n",
      "  Batch    80  of    282.    Elapsed: 0:00:46.\n",
      "  Batch   120  of    282.    Elapsed: 0:01:09.\n",
      "  Batch   160  of    282.    Elapsed: 0:01:32.\n",
      "  Batch   200  of    282.    Elapsed: 0:01:55.\n",
      "  Batch   240  of    282.    Elapsed: 0:02:18.\n",
      "  Batch   280  of    282.    Elapsed: 0:02:41.\n",
      "\n",
      "  Average training loss: 0.15\n",
      "  Training epcoh took: 0:02:42\n",
      "\n",
      "Running Validation...\n",
      "  Accuracy: 0.96\n",
      "  Validation Loss: 0.14\n",
      "  Validation took: 0:00:06\n",
      "\n",
      "Training complete!\n",
      "Total training took 0:05:37 (h:mm:ss)\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "import numpy as np\n",
    "\n",
    "# This training code is based on the `run_glue.py` script here:\n",
    "# https://github.com/huggingface/transformers/blob/5bfcd0485ece086ebcbed2d008813037968a9e58/examples/run_glue.py#L128\n",
    "\n",
    "# Set the seed value all over the place to make this reproducible.\n",
    "seed_val = 42\n",
    "\n",
    "random.seed(seed_val)\n",
    "np.random.seed(seed_val)\n",
    "torch.manual_seed(seed_val)\n",
    "torch.cuda.manual_seed_all(seed_val)\n",
    "\n",
    "# We'll store a number of quantities such as training and validation loss, \n",
    "# validation accuracy, and timings.\n",
    "training_stats = []\n",
    "\n",
    "# Measure the total training time for the whole run.\n",
    "total_t0 = time.time()\n",
    "\n",
    "# For each epoch...\n",
    "for epoch_i in range(0, epochs):\n",
    "    \n",
    "    # ========================================\n",
    "    #               Training\n",
    "    # ========================================\n",
    "    \n",
    "    # Perform one full pass over the training set.\n",
    "\n",
    "    print(\"\")\n",
    "    print('======== Epoch {:} / {:} ========'.format(epoch_i + 1, epochs))\n",
    "    print('Training...')\n",
    "\n",
    "    # Measure how long the training epoch takes.\n",
    "    t0 = time.time()\n",
    "\n",
    "    # Reset the total loss for this epoch.\n",
    "    total_train_loss = 0\n",
    "\n",
    "    # Put the model into training mode. Don't be misled--the call to \n",
    "    # `train` just changes the *mode*, it doesn't *perform* the training.\n",
    "    # `dropout` and `batchnorm` layers behave differently during training\n",
    "    # vs. test (source: https://stackoverflow.com/questions/51433378/what-does-model-train-do-in-pytorch)\n",
    "    model.train()\n",
    "\n",
    "    # For each batch of training data...\n",
    "    for step, batch in enumerate(train_dataloader):\n",
    "\n",
    "        # Progress update every 40 batches.\n",
    "        if step % 40 == 0 and not step == 0:\n",
    "            # Calculate elapsed time in minutes.\n",
    "            elapsed = format_time(time.time() - t0)\n",
    "            \n",
    "            # Report progress.\n",
    "            print('  Batch {:>5,}  of  {:>5,}.    Elapsed: {:}.'.format(step, len(train_dataloader), elapsed))\n",
    "\n",
    "        # Unpack this training batch from our dataloader. \n",
    "        #\n",
    "        # As we unpack the batch, we'll also copy each tensor to the GPU using the \n",
    "        # `to` method.\n",
    "        #\n",
    "        # `batch` contains three pytorch tensors:\n",
    "        #   [0]: input ids \n",
    "        #   [1]: attention masks\n",
    "        #   [2]: labels \n",
    "        b_input_ids = batch[0].to(device)\n",
    "        b_input_mask = batch[1].to(device)\n",
    "        b_labels = batch[2].to(device)\n",
    "\n",
    "        # Always clear any previously calculated gradients before performing a\n",
    "        # backward pass. PyTorch doesn't do this automatically because \n",
    "        # accumulating the gradients is \"convenient while training RNNs\". \n",
    "        # (source: https://stackoverflow.com/questions/48001598/why-do-we-need-to-call-zero-grad-in-pytorch)\n",
    "        model.zero_grad()        \n",
    "\n",
    "        # Perform a forward pass (evaluate the model on this training batch).\n",
    "        # The documentation for this `model` function is here: \n",
    "        # https://huggingface.co/transformers/v2.2.0/model_doc/bert.html#transformers.BertForSequenceClassification\n",
    "        # It returns different numbers of parameters depending on what arguments\n",
    "        # arge given and what flags are set. For our useage here, it returns\n",
    "        # the loss (because we provided labels) and the \"logits\"--the model\n",
    "        # outputs prior to activation.\n",
    "        loss, logits = model(b_input_ids, \n",
    "                             token_type_ids=None, \n",
    "                             attention_mask=b_input_mask, \n",
    "                             labels=b_labels)\n",
    "\n",
    "        # Accumulate the training loss over all of the batches so that we can\n",
    "        # calculate the average loss at the end. `loss` is a Tensor containing a\n",
    "        # single value; the `.item()` function just returns the Python value \n",
    "        # from the tensor.\n",
    "        total_train_loss += loss.item()\n",
    "\n",
    "        # Perform a backward pass to calculate the gradients.\n",
    "        loss.backward()\n",
    "\n",
    "        # Clip the norm of the gradients to 1.0.\n",
    "        # This is to help prevent the \"exploding gradients\" problem.\n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
    "\n",
    "        # Update parameters and take a step using the computed gradient.\n",
    "        # The optimizer dictates the \"update rule\"--how the parameters are\n",
    "        # modified based on their gradients, the learning rate, etc.\n",
    "        optimizer.step()\n",
    "\n",
    "        # Update the learning rate.\n",
    "        scheduler.step()\n",
    "\n",
    "    # Calculate the average loss over all of the batches.\n",
    "    avg_train_loss = total_train_loss / len(train_dataloader)            \n",
    "    \n",
    "    # Measure how long this epoch took.\n",
    "    training_time = format_time(time.time() - t0)\n",
    "\n",
    "    print(\"\")\n",
    "    print(\"  Average training loss: {0:.2f}\".format(avg_train_loss))\n",
    "    print(\"  Training epcoh took: {:}\".format(training_time))\n",
    "        \n",
    "    # ========================================\n",
    "    #               Validation\n",
    "    # ========================================\n",
    "    # After the completion of each training epoch, measure our performance on\n",
    "    # our validation set.\n",
    "\n",
    "    print(\"\")\n",
    "    print(\"Running Validation...\")\n",
    "\n",
    "    t0 = time.time()\n",
    "\n",
    "    # Put the model in evaluation mode--the dropout layers behave differently\n",
    "    # during evaluation.\n",
    "    model.eval()\n",
    "\n",
    "    # Tracking variables \n",
    "    total_eval_accuracy = 0\n",
    "    total_eval_loss = 0\n",
    "    nb_eval_steps = 0\n",
    "\n",
    "    # Evaluate data for one epoch\n",
    "    for batch in validation_dataloader:\n",
    "        \n",
    "        # Unpack this training batch from our dataloader. \n",
    "        #\n",
    "        # As we unpack the batch, we'll also copy each tensor to the GPU using \n",
    "        # the `to` method.\n",
    "        #\n",
    "        # `batch` contains three pytorch tensors:\n",
    "        #   [0]: input ids \n",
    "        #   [1]: attention masks\n",
    "        #   [2]: labels \n",
    "        b_input_ids = batch[0].to(device)\n",
    "        b_input_mask = batch[1].to(device)\n",
    "        b_labels = batch[2].to(device)\n",
    "        \n",
    "        # Tell pytorch not to bother with constructing the compute graph during\n",
    "        # the forward pass, since this is only needed for backprop (training).\n",
    "        with torch.no_grad():        \n",
    "\n",
    "            # Forward pass, calculate logit predictions.\n",
    "            # token_type_ids is the same as the \"segment ids\", which \n",
    "            # differentiates sentence 1 and 2 in 2-sentence tasks.\n",
    "            # The documentation for this `model` function is here: \n",
    "            # https://huggingface.co/transformers/v2.2.0/model_doc/bert.html#transformers.BertForSequenceClassification\n",
    "            # Get the \"logits\" output by the model. The \"logits\" are the output\n",
    "            # values prior to applying an activation function like the softmax.\n",
    "            (loss, logits) = model(b_input_ids, \n",
    "                                   token_type_ids=None, \n",
    "                                   attention_mask=b_input_mask,\n",
    "                                   labels=b_labels)\n",
    "            \n",
    "        # Accumulate the validation loss.\n",
    "        total_eval_loss += loss.item()\n",
    "\n",
    "        # Move logits and labels to CPU\n",
    "        logits = logits.detach().cpu().numpy()\n",
    "        label_ids = b_labels.to('cpu').numpy()\n",
    "\n",
    "        # Calculate the accuracy for this batch of test sentences, and\n",
    "        # accumulate it over all batches.\n",
    "        total_eval_accuracy += flat_accuracy(logits, label_ids)\n",
    "        \n",
    "\n",
    "    # Report the final accuracy for this validation run.\n",
    "    avg_val_accuracy = total_eval_accuracy / len(validation_dataloader)\n",
    "    print(\"  Accuracy: {0:.2f}\".format(avg_val_accuracy))\n",
    "\n",
    "    # Calculate the average loss over all of the batches.\n",
    "    avg_val_loss = total_eval_loss / len(validation_dataloader)\n",
    "    \n",
    "    # Measure how long the validation run took.\n",
    "    validation_time = format_time(time.time() - t0)\n",
    "    \n",
    "    print(\"  Validation Loss: {0:.2f}\".format(avg_val_loss))\n",
    "    print(\"  Validation took: {:}\".format(validation_time))\n",
    "\n",
    "    # Record all statistics from this epoch.\n",
    "    training_stats.append(\n",
    "        {\n",
    "            'epoch': epoch_i + 1,\n",
    "            'Training Loss': avg_train_loss,\n",
    "            'Valid. Loss': avg_val_loss,\n",
    "            'Valid. Accur.': avg_val_accuracy,\n",
    "            'Training Time': training_time,\n",
    "            'Validation Time': validation_time\n",
    "        }\n",
    "    )\n",
    "\n",
    "print(\"\")\n",
    "print(\"Training complete!\")\n",
    "\n",
    "print(\"Total training took {:} (h:mm:ss)\".format(format_time(time.time()-total_t0)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 136
    },
    "id": "C19KLyEDZaq4",
    "outputId": "ca16c4ed-7c13-4a4f-8151-33a6afd2dfa1"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Valid. Loss</th>\n",
       "      <th>Valid. Accur.</th>\n",
       "      <th>Training Time</th>\n",
       "      <th>Validation Time</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>epoch</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.35</td>\n",
       "      <td>0.19</td>\n",
       "      <td>0.93</td>\n",
       "      <td>0:02:43</td>\n",
       "      <td>0:00:06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.15</td>\n",
       "      <td>0.14</td>\n",
       "      <td>0.96</td>\n",
       "      <td>0:02:42</td>\n",
       "      <td>0:00:06</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Training Loss  Valid. Loss  Valid. Accur. Training Time Validation Time\n",
       "epoch                                                                         \n",
       "1               0.35         0.19           0.93       0:02:43         0:00:06\n",
       "2               0.15         0.14           0.96       0:02:42         0:00:06"
      ]
     },
     "execution_count": 15,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Display floats with two decimal places.\n",
    "pd.set_option('precision', 2)\n",
    "\n",
    "# Create a DataFrame from our training statistics.\n",
    "df_stats = pd.DataFrame(data=training_stats)\n",
    "\n",
    "# Use the 'epoch' as the row index.\n",
    "df_stats = df_stats.set_index('epoch')\n",
    "\n",
    "# A hack to force the column headers to wrap.\n",
    "#df = df.style.set_table_styles([dict(selector=\"th\",props=[('max-width', '70px')])])\n",
    "\n",
    "# Display the table.\n",
    "df_stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "X_HOGZyVZaq5",
    "outputId": "237a87a2-cc9a-43e5-8674-0ca6c2390c3c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of test sentences: 500\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/transformers/tokenization_utils_base.py:2022: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
      "  FutureWarning,\n"
     ]
    }
   ],
   "source": [
    "# create test set\n",
    "#df = toxicity[5000:5500]\n",
    "df = pd.concat([toxic[2500:2750], nontoxic[2500:2750]])\n",
    "\n",
    "print('Number of test sentences: {:,}\\n'.format(df.shape[0]))\n",
    "\n",
    "comments = df.comment.values\n",
    "labels = df.toxicity.values\n",
    "female = df.female_binary.values\n",
    "male = df.male_binary.values\n",
    "\n",
    "# Tokenize all of the sentences and map the tokens to thier word IDs.\n",
    "input_ids = []\n",
    "attention_masks = []\n",
    "\n",
    "# For every sentence...\n",
    "for cmt in comments:\n",
    "    # `encode_plus` will:\n",
    "    #   (1) Tokenize the sentence.\n",
    "    #   (2) Prepend the `[CLS]` token to the start.\n",
    "    #   (3) Append the `[SEP]` token to the end.\n",
    "    #   (4) Map tokens to their IDs.\n",
    "    #   (5) Pad or truncate the sentence to `max_length`\n",
    "    #   (6) Create attention masks for [PAD] tokens.\n",
    "    encoded_dict = tokenizer.encode_plus(\n",
    "                        cmt,                      # Sentence to encode.\n",
    "                        add_special_tokens = True, # Add '[CLS]' and '[SEP]'\n",
    "                        max_length = 100,           # Pad & truncate all sentences.\n",
    "                        pad_to_max_length = True,\n",
    "                        return_attention_mask = True,   # Construct attn. masks.\n",
    "                        return_tensors = 'pt',     # Return pytorch tensors.\n",
    "                   )\n",
    "    \n",
    "    # Add the encoded sentence to the list.    \n",
    "    input_ids.append(encoded_dict['input_ids'])\n",
    "    \n",
    "    # And its attention mask (simply differentiates padding from non-padding).\n",
    "    attention_masks.append(encoded_dict['attention_mask'])\n",
    "\n",
    "# Convert the lists into tensors.\n",
    "input_ids = torch.cat(input_ids, dim=0)\n",
    "attention_masks = torch.cat(attention_masks, dim=0)\n",
    "labels = torch.tensor(labels)\n",
    "female = torch.tensor(female)\n",
    "male = torch.tensor(male)\n",
    "\n",
    "# Set the batch size.  \n",
    "batch_size = 16\n",
    "\n",
    "# Create the DataLoader.\n",
    "prediction_data = TensorDataset(input_ids, attention_masks, labels)\n",
    "prediction_sampler = SequentialSampler(prediction_data)\n",
    "prediction_dataloader = DataLoader(prediction_data, sampler=prediction_sampler, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "IrnbYzU929sI",
    "outputId": "b6547906-e85a-4f68-85d3-ca0badb0a146"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicting labels for 500 test sentences...\n",
      "    DONE.\n"
     ]
    }
   ],
   "source": [
    "# Prediction on test set\n",
    "\n",
    "print('Predicting labels for {:,} test sentences...'.format(len(input_ids)))\n",
    "\n",
    "# Put model in evaluation mode\n",
    "model.eval()\n",
    "\n",
    "# Tracking variables \n",
    "predictions , true_labels = [], []\n",
    "\n",
    "# Predict \n",
    "for batch in prediction_dataloader:\n",
    "  # Add batch to GPU\n",
    "  batch = tuple(t.to(device) for t in batch)\n",
    "  \n",
    "  # Unpack the inputs from our dataloader\n",
    "  b_input_ids, b_input_mask, b_labels = batch\n",
    "  \n",
    "  # Telling the model not to compute or store gradients, saving memory and \n",
    "  # speeding up prediction\n",
    "  with torch.no_grad():\n",
    "      # Forward pass, calculate logit predictions\n",
    "      outputs = model(b_input_ids, token_type_ids=None, \n",
    "                      attention_mask=b_input_mask)\n",
    "\n",
    "  logits = outputs[0]\n",
    "\n",
    "  # Move logits and labels to CPU\n",
    "  logits = logits.detach().cpu().numpy()\n",
    "  label_ids = b_labels.to('cpu').numpy()\n",
    "  \n",
    "  # Store predictions and true labels\n",
    "  predictions.append(logits)\n",
    "  true_labels.append(label_ids)\n",
    "\n",
    "print('    DONE.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "9ABuErRj4AWr",
    "outputId": "4a0a287f-ef18-4166-f79f-05107522e83a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Positive samples: 250 of 500 (50.00%)\n",
      "Positive samples: 2500 of 5000 (50.00%)\n"
     ]
    }
   ],
   "source": [
    "print('Positive samples: %d of %d (%.2f%%)' % (df.toxicity.sum(), len(df.toxicity), (df.toxicity.sum() / len(df.toxicity) * 100.0)))\n",
    "print('Positive samples: %d of %d (%.2f%%)' % (small_toxicity.toxicity.sum(), len(small_toxicity.toxicity), (small_toxicity.toxicity.sum() / len(small_toxicity.toxicity) * 100.0)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 724
    },
    "id": "c-mlRtEL6e2b",
    "outputId": "b0ef9f83-756a-4dcd-d5e4-bda281d6d003"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total MCC: 0.244\n",
      "Total F1: 0.695\n",
      "True Positives:  238\n",
      "True Negatives:  53\n",
      "False Positives:  197\n",
      "False Negatives:  12\n",
      "Calculating Matthews Corr. Coef. and F1 score for each batch...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/_classification.py:900: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  mcc = cov_ytyp / np.sqrt(cov_ytyt * cov_ypyp)\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light",
      "tags": []
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light",
      "tags": []
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.metrics import f1_score, matthews_corrcoef, confusion_matrix\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Combine the results across all batches. \n",
    "flat_predictions = np.concatenate(predictions, axis=0)\n",
    "\n",
    "# For each sample, pick the label (0 or 1) with the higher score.\n",
    "flat_predictions = np.argmax(flat_predictions, axis=1).flatten()\n",
    "\n",
    "# Combine the correct labels for each batch into a single list.\n",
    "flat_true_labels = np.concatenate(true_labels, axis=0)\n",
    "\n",
    "# Calculate the MCC\n",
    "mcc = matthews_corrcoef(flat_true_labels, flat_predictions)\n",
    "f1 = f1_score(flat_true_labels, flat_predictions)\n",
    "\n",
    "print('Total MCC: %.3f' % mcc)\n",
    "print('Total F1: %.3f' % f1)\n",
    "\n",
    "tn, fp, fn, tp = confusion_matrix(flat_true_labels, flat_predictions).ravel()\n",
    "\n",
    "print(\"True Positives: \",tp)\n",
    "print(\"True Negatives: \",tn)\n",
    "print(\"False Positives: \",fp)\n",
    "print(\"False Negatives: \",fn)\n",
    "\n",
    "matthews_set = []\n",
    "f1_set = []\n",
    "\n",
    "# Evaluate each test batch using Matthew's correlation coefficient\n",
    "print('Calculating Matthews Corr. Coef. and F1 score for each batch...')\n",
    "\n",
    "# For each input batch...\n",
    "for i in range(len(true_labels)):\n",
    "  \n",
    "  # The predictions for this batch are a 2-column ndarray (one column for \"0\" \n",
    "  # and one column for \"1\"). Pick the label with the highest value and turn this\n",
    "  # in to a list of 0s and 1s.\n",
    "  pred_labels_i = np.argmax(predictions[i], axis=1).flatten()\n",
    "  \n",
    "  # Calculate and store the coef for this batch.  \n",
    "  matthews = matthews_corrcoef(true_labels[i], pred_labels_i)                \n",
    "  matthews_set.append(matthews)\n",
    "  score = f1_score(true_labels[i], pred_labels_i)\n",
    "  f1_set.append(score)\n",
    "\n",
    "# Create a barplot showing the MCC score for each batch of test samples.\n",
    "ax = sns.barplot(x=list(range(len(matthews_set))), y=matthews_set, ci=None)\n",
    "\n",
    "plt.title('MCC Score per Batch')\n",
    "plt.ylabel('MCC Score (-1 to +1)')\n",
    "plt.xlabel('Batch #')\n",
    "\n",
    "plt.show()\n",
    "\n",
    "# Create a barplot showing the f1 score for each batch of test samples.\n",
    "ax = sns.barplot(x=list(range(len(f1_set))), y=f1_set, ci=None)\n",
    "\n",
    "plt.title('f1 Score per Batch')\n",
    "plt.ylabel('f1 Score (0 to +1)')\n",
    "plt.xlabel('Batch #')\n",
    "\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "BERT Classifier.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
