{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7ak_Ca3w_rNy"
   },
   "source": [
    "## BERT classifier v9: Removing toxic words from training data to see which model picks up on context/semantics\n",
    "Trained on balanced data for female annotators in toxic/nontoxic classes with all toxic words removed from training data, label = toxicity, tested toxicity predictions for toxic comments annotated by men/women.\n",
    "\n",
    "Using BERT code from: https://mccormickml.com/2019/07/22/BERT-fine-tuning/\n",
    "\n",
    "Adapted BERT for sentiment analysis using code from: https://curiousily.com/posts/sentiment-analysis-with-bert-and-hugging-face-using-pytorch-and-python/\n",
    "\n",
    "After training the model will be saved in bert_female_notoxic_state.bin and can be reused for future runs\n",
    "\n",
    "Using offensive words list from: https://www.cs.cmu.edu/~biglou/resources/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Before running, check values of:\n",
    "* file paths\n",
    "* MAX_LEN\n",
    "* batch_size\n",
    "* size\n",
    "* epochs\n",
    "* pretrained\n",
    "* saved_test_set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install required libraries\n",
    "#!conda install -y tensorflow\n",
    "#!conda install -y pytorch torchvision -c pytorch\n",
    "#!pip install transformers\n",
    "#!pip install transformers==3.5.1\n",
    "#!pip install -U seaborn\n",
    "#!pip install wordcloud"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "RBWkIenb_xH-",
    "outputId": "fb551ee7-1634-45cd-8656-8b8d82be77c2"
   },
   "outputs": [],
   "source": [
    "# Import libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from collections import defaultdict\n",
    "import random\n",
    "import math\n",
    "import nltk\n",
    "import datetime\n",
    "import time\n",
    "import string\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.utils.data import TensorDataset, random_split\n",
    "from torch.utils.data import DataLoader, RandomSampler, SequentialSampler\n",
    "from transformers import BertTokenizer\n",
    "from transformers import BertForSequenceClassification, AdamW, BertConfig\n",
    "from transformers import logging\n",
    "from transformers import get_linear_schedule_with_warmup\n",
    "from sklearn.metrics import f1_score, confusion_matrix, accuracy_score\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import plotly.graph_objects as go\n",
    "import pickle\n",
    "from wordcloud import WordCloud\n",
    "\n",
    "# In order to use notebook in Google Colab\n",
    "# from google.colab import drive\n",
    "# drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Choose whether to use pretrained model\n",
    "pretrained = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 262
    },
    "id": "NrVW-FsUABeB",
    "outputId": "9027af8e-a87c-4318-ca90-dd1a5901c514"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>comment</th>\n",
       "      <th>year</th>\n",
       "      <th>logged_in</th>\n",
       "      <th>ns</th>\n",
       "      <th>sample</th>\n",
       "      <th>split</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rev_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2232.0</th>\n",
       "      <td>This:NEWLINE_TOKEN:One can make an analogy in ...</td>\n",
       "      <td>2002</td>\n",
       "      <td>True</td>\n",
       "      <td>article</td>\n",
       "      <td>random</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4216.0</th>\n",
       "      <td>`NEWLINE_TOKENNEWLINE_TOKEN:Clarification for ...</td>\n",
       "      <td>2002</td>\n",
       "      <td>True</td>\n",
       "      <td>user</td>\n",
       "      <td>random</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8953.0</th>\n",
       "      <td>Elected or Electoral? JHK</td>\n",
       "      <td>2002</td>\n",
       "      <td>False</td>\n",
       "      <td>article</td>\n",
       "      <td>random</td>\n",
       "      <td>test</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26547.0</th>\n",
       "      <td>`This is such a fun entry.   DevotchkaNEWLINE_...</td>\n",
       "      <td>2002</td>\n",
       "      <td>True</td>\n",
       "      <td>article</td>\n",
       "      <td>random</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28959.0</th>\n",
       "      <td>Please relate the ozone hole to increases in c...</td>\n",
       "      <td>2002</td>\n",
       "      <td>True</td>\n",
       "      <td>article</td>\n",
       "      <td>random</td>\n",
       "      <td>test</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   comment  year  logged_in  \\\n",
       "rev_id                                                                        \n",
       "2232.0   This:NEWLINE_TOKEN:One can make an analogy in ...  2002       True   \n",
       "4216.0   `NEWLINE_TOKENNEWLINE_TOKEN:Clarification for ...  2002       True   \n",
       "8953.0                           Elected or Electoral? JHK  2002      False   \n",
       "26547.0  `This is such a fun entry.   DevotchkaNEWLINE_...  2002       True   \n",
       "28959.0  Please relate the ozone hole to increases in c...  2002       True   \n",
       "\n",
       "              ns  sample  split  \n",
       "rev_id                           \n",
       "2232.0   article  random  train  \n",
       "4216.0      user  random  train  \n",
       "8953.0   article  random   test  \n",
       "26547.0  article  random  train  \n",
       "28959.0  article  random   test  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>rev_id</th>\n",
       "      <th>worker_id</th>\n",
       "      <th>toxicity</th>\n",
       "      <th>toxicity_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2232.0</td>\n",
       "      <td>723</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2232.0</td>\n",
       "      <td>4000</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2232.0</td>\n",
       "      <td>3989</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2232.0</td>\n",
       "      <td>3341</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2232.0</td>\n",
       "      <td>1574</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   rev_id  worker_id  toxicity  toxicity_score\n",
       "0  2232.0        723         0             0.0\n",
       "1  2232.0       4000         0             0.0\n",
       "2  2232.0       3989         0             1.0\n",
       "3  2232.0       3341         0             0.0\n",
       "4  2232.0       1574         0             1.0"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>worker_id</th>\n",
       "      <th>gender</th>\n",
       "      <th>english_first_language</th>\n",
       "      <th>age_group</th>\n",
       "      <th>education</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>85</td>\n",
       "      <td>female</td>\n",
       "      <td>0</td>\n",
       "      <td>18-30</td>\n",
       "      <td>bachelors</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1617</td>\n",
       "      <td>female</td>\n",
       "      <td>0</td>\n",
       "      <td>45-60</td>\n",
       "      <td>bachelors</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1394</td>\n",
       "      <td>female</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>bachelors</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>311</td>\n",
       "      <td>male</td>\n",
       "      <td>0</td>\n",
       "      <td>30-45</td>\n",
       "      <td>bachelors</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1980</td>\n",
       "      <td>male</td>\n",
       "      <td>0</td>\n",
       "      <td>45-60</td>\n",
       "      <td>masters</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   worker_id  gender  english_first_language age_group  education\n",
       "0         85  female                       0     18-30  bachelors\n",
       "1       1617  female                       0     45-60  bachelors\n",
       "2       1394  female                       0       NaN  bachelors\n",
       "3        311    male                       0     30-45  bachelors\n",
       "4       1980    male                       0     45-60    masters"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Read files and create dataframe (may need to change path)\n",
    "toxicity_comments = pd.read_csv('../toxicity_annotated_comments.tsv', sep = '\\t', index_col = 0)\n",
    "toxicity_annotations = pd.read_csv('../toxicity_annotations.tsv',  sep = '\\t')\n",
    "toxicity_demographics = pd.read_csv('../toxicity_worker_demographics.tsv', sep = '\\t')\n",
    "    \n",
    "# Take a look at data\n",
    "display (toxicity_comments.head(5))\n",
    "display (toxicity_annotations.head(5))\n",
    "display (toxicity_demographics.head(5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 262
    },
    "id": "NrVW-FsUABeB",
    "outputId": "9027af8e-a87c-4318-ca90-dd1a5901c514"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>rev_id</th>\n",
       "      <th>comment</th>\n",
       "      <th>year</th>\n",
       "      <th>logged_in</th>\n",
       "      <th>ns</th>\n",
       "      <th>sample</th>\n",
       "      <th>split</th>\n",
       "      <th>worker_id</th>\n",
       "      <th>toxicity</th>\n",
       "      <th>toxicity_score</th>\n",
       "      <th>gender</th>\n",
       "      <th>english_first_language</th>\n",
       "      <th>age_group</th>\n",
       "      <th>education</th>\n",
       "      <th>female_binary</th>\n",
       "      <th>male_binary</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3467</th>\n",
       "      <td>2232.0</td>\n",
       "      <td>This: :One can make an analogy in mathematical...</td>\n",
       "      <td>2002</td>\n",
       "      <td>True</td>\n",
       "      <td>article</td>\n",
       "      <td>random</td>\n",
       "      <td>train</td>\n",
       "      <td>405</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>male</td>\n",
       "      <td>0.0</td>\n",
       "      <td>30-45</td>\n",
       "      <td>masters</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3039</th>\n",
       "      <td>2232.0</td>\n",
       "      <td>This: :One can make an analogy in mathematical...</td>\n",
       "      <td>2002</td>\n",
       "      <td>True</td>\n",
       "      <td>article</td>\n",
       "      <td>random</td>\n",
       "      <td>train</td>\n",
       "      <td>680</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>male</td>\n",
       "      <td>0.0</td>\n",
       "      <td>18-30</td>\n",
       "      <td>masters</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2232.0</td>\n",
       "      <td>This: :One can make an analogy in mathematical...</td>\n",
       "      <td>2002</td>\n",
       "      <td>True</td>\n",
       "      <td>article</td>\n",
       "      <td>random</td>\n",
       "      <td>train</td>\n",
       "      <td>723</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>female</td>\n",
       "      <td>0.0</td>\n",
       "      <td>30-45</td>\n",
       "      <td>bachelors</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2600</th>\n",
       "      <td>2232.0</td>\n",
       "      <td>This: :One can make an analogy in mathematical...</td>\n",
       "      <td>2002</td>\n",
       "      <td>True</td>\n",
       "      <td>article</td>\n",
       "      <td>random</td>\n",
       "      <td>train</td>\n",
       "      <td>772</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>male</td>\n",
       "      <td>0.0</td>\n",
       "      <td>18-30</td>\n",
       "      <td>bachelors</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2169</th>\n",
       "      <td>2232.0</td>\n",
       "      <td>This: :One can make an analogy in mathematical...</td>\n",
       "      <td>2002</td>\n",
       "      <td>True</td>\n",
       "      <td>article</td>\n",
       "      <td>random</td>\n",
       "      <td>train</td>\n",
       "      <td>1508</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>female</td>\n",
       "      <td>1.0</td>\n",
       "      <td>45-60</td>\n",
       "      <td>hs</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      rev_id                                            comment  year  \\\n",
       "3467  2232.0  This: :One can make an analogy in mathematical...  2002   \n",
       "3039  2232.0  This: :One can make an analogy in mathematical...  2002   \n",
       "0     2232.0  This: :One can make an analogy in mathematical...  2002   \n",
       "2600  2232.0  This: :One can make an analogy in mathematical...  2002   \n",
       "2169  2232.0  This: :One can make an analogy in mathematical...  2002   \n",
       "\n",
       "      logged_in       ns  sample  split  worker_id  toxicity  toxicity_score  \\\n",
       "3467       True  article  random  train        405         0             1.0   \n",
       "3039       True  article  random  train        680         0             0.0   \n",
       "0          True  article  random  train        723         0             0.0   \n",
       "2600       True  article  random  train        772         0             1.0   \n",
       "2169       True  article  random  train       1508         0             1.0   \n",
       "\n",
       "      gender  english_first_language age_group  education  female_binary  \\\n",
       "3467    male                     0.0     30-45    masters              0   \n",
       "3039    male                     0.0     18-30    masters              0   \n",
       "0     female                     0.0     30-45  bachelors              1   \n",
       "2600    male                     0.0     18-30  bachelors              0   \n",
       "2169  female                     1.0     45-60         hs              1   \n",
       "\n",
       "      male_binary  \n",
       "3467            1  \n",
       "3039            1  \n",
       "0               0  \n",
       "2600            1  \n",
       "2169            0  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Merge into single DataFrame\n",
    "toxicity = toxicity_comments.merge(toxicity_annotations, how ='outer', on=\"rev_id\")\n",
    "toxicity = toxicity.merge(toxicity_demographics, how ='outer', on=\"worker_id\").sort_values(by=['rev_id','worker_id'])\n",
    "\n",
    "# Remove newline and tab tokens from comments\n",
    "toxicity['comment'] = toxicity['comment'].apply(lambda x: x.replace(\"NEWLINE_TOKEN\", \" \"))\n",
    "toxicity['comment'] = toxicity['comment'].apply(lambda x: x.replace(\"TAB_TOKEN\", \" \"))\n",
    "\n",
    "# Remove annotators with 'other' as gender (too few to include in results)\n",
    "toxicity = toxicity[toxicity['gender']!='other']\n",
    "\n",
    "# Add binary gender columns\n",
    "toxicity = pd.concat([toxicity, pd.get_dummies(toxicity.gender).rename(columns = \"{}_binary\".format)], axis = 1)\n",
    "\n",
    "# Look at data with new columns\n",
    "display (toxicity.head(5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 262
    },
    "id": "NrVW-FsUABeB",
    "outputId": "9027af8e-a87c-4318-ca90-dd1a5901c514"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "smallest: 14076\n",
      "test size: 5630\n",
      "train size: 45044\n"
     ]
    }
   ],
   "source": [
    "# Separate comments into categories\n",
    "very_toxic = toxicity[toxicity.toxicity_score == -2.0]\n",
    "toxic = toxicity[toxicity.toxicity_score == -1.0]\n",
    "nontoxic = toxicity[toxicity.toxicity == 0]\n",
    "\n",
    "# Filter for female annotated data\n",
    "female_toxic = toxic[toxic.female_binary == 1]\n",
    "female_very_toxic = very_toxic[very_toxic.female_binary == 1]\n",
    "female_nontoxic = nontoxic[nontoxic.female_binary == 1]\n",
    "\n",
    "# Find smallest toxic dataset\n",
    "size = min(female_toxic.shape[0],female_very_toxic.shape[0])\n",
    "print(\"smallest:\",size)\n",
    "\n",
    "# Manually choose size if necessary\n",
    "# size = 2000\n",
    "\n",
    "# Split into train and test sets\n",
    "test_size = math.floor(size*0.2)\n",
    "train_size = math.ceil(size*0.8)\n",
    "\n",
    "# Create toxic test dataset and drop from dataframes so not also chosen for training\n",
    "female_toxic_test = female_toxic.sample(n=test_size)\n",
    "female_toxic = female_toxic.drop(female_toxic_test.index)\n",
    "female_vtoxic_test = female_very_toxic.sample(n=test_size)\n",
    "female_very_toxic = female_very_toxic.drop(female_vtoxic_test.index)\n",
    "female_test_data = pd.concat([female_toxic_test,female_vtoxic_test])\n",
    "female_test_data = female_test_data.sample(frac=1)\n",
    "print(\"test size:\",female_test_data.shape[0])\n",
    "\n",
    "# Training data composed of equal proportions of female toxic/nontoxic\n",
    "female_data = pd.concat([female_toxic.sample(train_size),female_very_toxic.sample(train_size),female_nontoxic.sample(train_size*2)])\n",
    "female_data = female_data.sample(frac=1)\n",
    "print(\"train size:\",female_data.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>rev_id</th>\n",
       "      <th>comment</th>\n",
       "      <th>year</th>\n",
       "      <th>logged_in</th>\n",
       "      <th>ns</th>\n",
       "      <th>sample</th>\n",
       "      <th>split</th>\n",
       "      <th>worker_id</th>\n",
       "      <th>toxicity</th>\n",
       "      <th>toxicity_score</th>\n",
       "      <th>gender</th>\n",
       "      <th>english_first_language</th>\n",
       "      <th>age_group</th>\n",
       "      <th>education</th>\n",
       "      <th>female_binary</th>\n",
       "      <th>male_binary</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>911946</th>\n",
       "      <td>476128240.0</td>\n",
       "      <td>`  ==Exodus== I noticed that you had made some...</td>\n",
       "      <td>2012</td>\n",
       "      <td>True</td>\n",
       "      <td>user</td>\n",
       "      <td>random</td>\n",
       "      <td>dev</td>\n",
       "      <td>1000</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>female</td>\n",
       "      <td>1.0</td>\n",
       "      <td>18-30</td>\n",
       "      <td>bachelors</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1246791</th>\n",
       "      <td>172557723.0</td>\n",
       "      <td>`   Please do not vandalize pages, as you did ...</td>\n",
       "      <td>2007</td>\n",
       "      <td>True</td>\n",
       "      <td>user</td>\n",
       "      <td>random</td>\n",
       "      <td>dev</td>\n",
       "      <td>3042</td>\n",
       "      <td>1</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>female</td>\n",
       "      <td>0.0</td>\n",
       "      <td>18-30</td>\n",
       "      <td>some</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>115124</th>\n",
       "      <td>368881786.0</td>\n",
       "      <td>Svenska journalistklubben is what is claimed, ...</td>\n",
       "      <td>2010</td>\n",
       "      <td>True</td>\n",
       "      <td>user</td>\n",
       "      <td>blocked</td>\n",
       "      <td>train</td>\n",
       "      <td>1419</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>female</td>\n",
       "      <td>0.0</td>\n",
       "      <td>18-30</td>\n",
       "      <td>hs</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>672771</th>\n",
       "      <td>299367944.0</td>\n",
       "      <td>==Hey you cunt armchair lawyer== Do you lik...</td>\n",
       "      <td>2009</td>\n",
       "      <td>False</td>\n",
       "      <td>user</td>\n",
       "      <td>blocked</td>\n",
       "      <td>dev</td>\n",
       "      <td>3876</td>\n",
       "      <td>1</td>\n",
       "      <td>-2.0</td>\n",
       "      <td>female</td>\n",
       "      <td>1.0</td>\n",
       "      <td>30-45</td>\n",
       "      <td>professional</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1590005</th>\n",
       "      <td>194193392.0</td>\n",
       "      <td>I have reverted your edit to Coretta Scott Kin...</td>\n",
       "      <td>2008</td>\n",
       "      <td>True</td>\n",
       "      <td>user</td>\n",
       "      <td>random</td>\n",
       "      <td>dev</td>\n",
       "      <td>1759</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>female</td>\n",
       "      <td>0.0</td>\n",
       "      <td>30-45</td>\n",
       "      <td>bachelors</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              rev_id                                            comment  year  \\\n",
       "911946   476128240.0  `  ==Exodus== I noticed that you had made some...  2012   \n",
       "1246791  172557723.0  `   Please do not vandalize pages, as you did ...  2007   \n",
       "115124   368881786.0  Svenska journalistklubben is what is claimed, ...  2010   \n",
       "672771   299367944.0     ==Hey you cunt armchair lawyer== Do you lik...  2009   \n",
       "1590005  194193392.0  I have reverted your edit to Coretta Scott Kin...  2008   \n",
       "\n",
       "         logged_in    ns   sample  split  worker_id  toxicity  toxicity_score  \\\n",
       "911946        True  user   random    dev       1000         0             0.0   \n",
       "1246791       True  user   random    dev       3042         1            -1.0   \n",
       "115124        True  user  blocked  train       1419         0             1.0   \n",
       "672771       False  user  blocked    dev       3876         1            -2.0   \n",
       "1590005       True  user   random    dev       1759         0             1.0   \n",
       "\n",
       "         gender  english_first_language age_group     education  \\\n",
       "911946   female                     1.0     18-30     bachelors   \n",
       "1246791  female                     0.0     18-30          some   \n",
       "115124   female                     0.0     18-30            hs   \n",
       "672771   female                     1.0     30-45  professional   \n",
       "1590005  female                     0.0     30-45     bachelors   \n",
       "\n",
       "         female_binary  male_binary  \n",
       "911946               1            0  \n",
       "1246791              1            0  \n",
       "115124               1            0  \n",
       "672771               1            0  \n",
       "1590005              1            0  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Take a look at training data\n",
    "display (female_data.head(5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "HM4vJigyDP3j",
    "outputId": "cc473f51-5d50-4a89-be40-d5ed9ad4bac8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 1 GPU(s) available.\n",
      "We will use the GPU: GeForce RTX 2070\n"
     ]
    }
   ],
   "source": [
    "# Try to use gpu\n",
    "if torch.cuda.is_available():      \n",
    "    device = torch.device(\"cuda\")\n",
    "    print('There are %d GPU(s) available.' % torch.cuda.device_count())\n",
    "    print('We will use the GPU:', torch.cuda.get_device_name(0))\n",
    "\n",
    "else:\n",
    "    print('No GPU available, using the CPU instead.')\n",
    "    device = torch.device(\"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Removing punctuation and converting capital letters to lowercase\n",
    "female_data['comment'] = female_data['comment'].str.translate(str.maketrans('', '', string.punctuation))\n",
    "female_data['comment'] = female_data['comment'].str.lower()\n",
    "female_test_data['comment'] = female_test_data['comment'].str.translate(str.maketrans('', '', string.punctuation))\n",
    "female_test_data['comment'] = female_test_data['comment'].str.lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "O5Q5ntvhDWxN"
   },
   "outputs": [],
   "source": [
    "# Extract relevant information from training data (comment and toxicity of comment)\n",
    "comments = female_data.comment.values\n",
    "labels = female_data.toxicity.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Count number of offensive words in comment\n",
    "\n",
    "# List of offensive words taken from: https://www.cs.cmu.edu/~biglou/resources/\n",
    "file = open('bad-words.txt','r')\n",
    "offensive_words = file.read().splitlines()\n",
    "offensive_words = [word.replace(\" \",\"\") for word in offensive_words]\n",
    "file.close()\n",
    "\n",
    "# Removing acceptable words from offensive words list\n",
    "acceptable = ['','adult','africa','alla','allah','african','arab','arabs','asian','american','angry','australian','baptist','bible','bigger','black','blacks','burn','canadian','catholic','cemetery','catholics',\"children's\",'chinese','christian','church','cigarette','cocaine','cocktail','color','ecstacy','ethiopian','european','faith','fear','filipina','filipino','fire','funeral','german','gin','girls','heroin','israel','israeli',\"israel's\",'italiano','japanese','jew','jewish','joint','kid','latin','lsd','lucifer','marijuana','meth','mexican','mormon','muslim','narcotic','nigerian','nigerians','palestinian','poverty','pot','protestant','rabbi','vatican','welfare','whites',\"women's\"]\n",
    "for word in acceptable:\n",
    "    offensive_words.remove(word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove offensive words from comment\n",
    "def clean_comment(comment):\n",
    "    words = nltk.word_tokenize(comment)\n",
    "    new_comment = []\n",
    "    for word in words:\n",
    "        if word not in offensive_words:\n",
    "            new_comment.append(word)\n",
    "    return \" \".join(new_comment)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Removing offensive words from comments\n",
    "new_comments = []\n",
    "for comment in comments:\n",
    "    new_comment = clean_comment(comment)\n",
    "    new_comments.append(new_comment)\n",
    "comments = new_comments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 687,
     "referenced_widgets": [
      "9a413a00269e406f910a554babc8ddac",
      "050fad76094442ccabc0a9dd1841b1e7",
      "4ef1d475bfb44fb5b4e8f77843e9c13d",
      "c27bc61cdcfe419eab175f61768cb692",
      "a679570eb7834b98b460e7235fab57be",
      "7245dba34af84f019e9aa7b4167655c2",
      "2f72600eb7d241d38861be5e6cac560d",
      "b0aa11e7b5f44d7a9c094b3860f1fe1f"
     ]
    },
    "id": "UhlZR6pXD1Jl",
    "outputId": "3f2ca88e-54f7-4b79-9176-6d4f3781a8d4"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading BERT tokenizer...\n"
     ]
    }
   ],
   "source": [
    "# Load the BERT tokenizer.\n",
    "print('Loading BERT tokenizer...')\n",
    "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased', do_lower_case=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plot the distribution of sequence lengths to optimize the maximum sequence length used.  Large sequence lengths use a lot of GPU memory.\n",
    "\n",
    "plot_dist = True\n",
    "\n",
    "if plot_dist:\n",
    "\n",
    "    token_lens = []\n",
    "\n",
    "    for txt in comments:\n",
    "      tokens = tokenizer.encode(txt, max_length=512, truncation=True)\n",
    "      token_lens.append(len(tokens))\n",
    "\n",
    "    sns.histplot(token_lens)\n",
    "    plt.xlim([0, 256]);\n",
    "    plt.xlabel('Token count');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "f3gKFb5wD7eS",
    "outputId": "b6e81334-2d1c-4be1-981d-0f130a9c505d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original:  exodus i noticed that you had made some earlier edits to the exodus but had them reverted i recently had the same issue it would seem that two users are enforcing their own view of what mainstream scholarly opinion is on the article the reason your edits and mine were reverted is not that they were wrong or that they didnt represent mainstream opinion but that these two users are enforcing a pov on the article i assure you your edits and mine were closer to mainstream scholarly opinion than the reversions were if you are willing we can work together on the article to bring some balance\n",
      "Token IDs: tensor([  101, 16388,  1045,  4384,  2008,  2017,  2018,  2081,  2070,  3041,\n",
      "        10086,  2015,  2000,  1996, 16388,  2021,  2018,  2068, 16407,  1045,\n",
      "         3728,  2018,  1996,  2168,  3277,  2009,  2052,  4025,  2008,  2048,\n",
      "         5198,  2024, 27455,  2037,  2219,  3193,  1997,  2054,  7731, 12683,\n",
      "         5448,  2003,  2006,  1996,  3720,  1996,  3114,  2115, 10086,  2015,\n",
      "         1998,  3067,  2020, 16407,  2003,  2025,  2008,  2027,  2020,  3308,\n",
      "         2030,  2008,  2027,  2134,  2102,  5050,  7731,  5448,  2021,  2008,\n",
      "         2122,  2048,  5198,  2024, 27455,  1037, 13433,  2615,  2006,  1996,\n",
      "         3720,  1045, 14306,  2017,  2115, 10086,  2015,  1998,  3067,  2020,\n",
      "         3553,  2000,  7731, 12683,  5448,  2084,  1996,  7065,  2545,   102])\n"
     ]
    }
   ],
   "source": [
    "# Limit the length of the sequence in tokens to control memory usage\n",
    "MAX_LEN=100\n",
    "\n",
    "# Tokenize all of the sentences and map the tokens to their word IDs.\n",
    "input_ids = []\n",
    "attention_masks = []\n",
    "\n",
    "# For every sentence...\n",
    "for cmt in comments:\n",
    "    # `encode_plus` will:\n",
    "    #   (1) Tokenize the sentence.\n",
    "    #   (2) Prepend the `[CLS]` token to the start.\n",
    "    #   (3) Append the `[SEP]` token to the end.\n",
    "    #   (4) Map tokens to their IDs.\n",
    "    #   (5) Pad or truncate the sentence to `max_length`\n",
    "    #   (6) Create attention masks for [PAD] tokens.\n",
    "    encoded_dict = tokenizer.encode_plus(\n",
    "                        cmt,                      # Sentence to encode.\n",
    "                        add_special_tokens = True, # Add '[CLS]' and '[SEP]'\n",
    "                        max_length = MAX_LEN,           # Pad & truncate all sentences.\n",
    "                        padding='max_length',\n",
    "                        truncation=True,\n",
    "                        return_attention_mask = True,   # Construct attn. masks.\n",
    "                        return_tensors = 'pt',     # Return pytorch tensors.\n",
    "                   )\n",
    "    \n",
    "    # Add the encoded sentence to the list.    \n",
    "    input_ids.append(encoded_dict['input_ids'])\n",
    "    \n",
    "    # And its attention mask (simply differentiates padding from non-padding).\n",
    "    attention_masks.append(encoded_dict['attention_mask'])\n",
    "\n",
    "# Convert the lists into tensors.\n",
    "input_ids = torch.cat(input_ids, dim=0)\n",
    "attention_masks = torch.cat(attention_masks, dim=0)\n",
    "labels = torch.tensor(labels)\n",
    "\n",
    "# # Print sentence 0, now as a list of IDs.\n",
    "print('Original: ', comments[0])\n",
    "print('Token IDs:', input_ids[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "vocab size: 30522\n"
     ]
    }
   ],
   "source": [
    "# Examining tokenization\n",
    "print(\"vocab size:\",tokenizer.vocab_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "gaaSOCAIEZq-",
    "outputId": "c6a08f0b-1fac-4b56-fe06-9ecb9eeb13c3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "40,539 training samples\n",
      "4,505 validation samples\n"
     ]
    }
   ],
   "source": [
    "# Combine the training inputs into a TensorDataset.\n",
    "dataset = TensorDataset(input_ids, attention_masks, labels)\n",
    "\n",
    "# Create a 90-10 train-validation split.\n",
    "\n",
    "# Calculate the number of samples to include in each set.\n",
    "train_size = int(0.9 * len(dataset))\n",
    "val_size = len(dataset) - train_size\n",
    "\n",
    "# Divide the dataset by randomly selecting samples.\n",
    "train_dataset, val_dataset = random_split(dataset, [train_size, val_size])\n",
    "\n",
    "print('{:>5,} training samples'.format(train_size))\n",
    "print('{:>5,} validation samples'.format(val_size))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "id": "LHf1KGY_GvSj"
   },
   "outputs": [],
   "source": [
    "# The DataLoader needs to know our batch size for training, so we specify it \n",
    "# here. For fine-tuning BERT on a specific task, the authors recommend a batch \n",
    "# size of 16 or 32.\n",
    "batch_size = 8\n",
    "\n",
    "# Create the DataLoaders for our training and validation sets.\n",
    "# We'll take training samples in random order. \n",
    "train_dataloader = DataLoader(\n",
    "            train_dataset,  # The training samples.\n",
    "            sampler = RandomSampler(train_dataset), # Select batches randomly\n",
    "            batch_size = batch_size # Trains with this batch size.\n",
    "        )\n",
    "\n",
    "# For validation the order doesn't matter, so we'll just read them sequentially.\n",
    "validation_dataloader = DataLoader(\n",
    "            val_dataset, # The validation samples.\n",
    "            sampler = SequentialSampler(val_dataset), # Pull out batches sequentially.\n",
    "            batch_size = batch_size # Evaluate with this batch size\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000,
     "referenced_widgets": [
      "73f18bedea76480fb9981b5d526cbc2d",
      "5523466dab5342c1976c15d4495362a0",
      "e5186ba30dbd4973a6983d88ba06ee17",
      "7b11996e92974efaaa6db91f5ac2e59f",
      "2d24a0780c6e46e3b5d2c348c788d383",
      "cf76c66b89b749e4a79a179e56bd8b78",
      "13892e698d894bb7b7555e3c725f7bff",
      "7035649df34f421b936faded0d3ee5b6",
      "ef0f5c28845d44b6ada41f72ec2dd982",
      "3a643aebf84147d2baec20687a8d467e",
      "312fbca9a0d34423bf15e7bb52755bf1",
      "82a19fe3427542d38429d1b8ccaa931d",
      "ce6d4c02eb45429cb45832f86228b98e",
      "3cef259bc6c348139134a71ad635082f",
      "4d6dfec252104ceeb314babbf507bf6c",
      "6c549a6980514e7fbc05d2f3bded708a"
     ]
    },
    "id": "2Z5LPc0pG265",
    "outputId": "e3cc73dc-c3c4-42e1-8602-4d854a210917"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BertForSequenceClassification(\n",
       "  (bert): BertModel(\n",
       "    (embeddings): BertEmbeddings(\n",
       "      (word_embeddings): Embedding(30522, 768, padding_idx=0)\n",
       "      (position_embeddings): Embedding(512, 768)\n",
       "      (token_type_embeddings): Embedding(2, 768)\n",
       "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (encoder): BertEncoder(\n",
       "      (layer): ModuleList(\n",
       "        (0): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (1): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (2): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (3): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (4): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (5): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (6): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (7): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (8): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (9): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (10): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (11): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (pooler): BertPooler(\n",
       "      (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "      (activation): Tanh()\n",
       "    )\n",
       "  )\n",
       "  (dropout): Dropout(p=0.1, inplace=False)\n",
       "  (classifier): Linear(in_features=768, out_features=2, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logging.set_verbosity_error() # set to warning to show warnings\n",
    "\n",
    "# Load BertForSequenceClassification, the pretrained BERT model with a single \n",
    "# linear classification layer on top. \n",
    "model = BertForSequenceClassification.from_pretrained(\n",
    "    \"bert-base-uncased\", # Use the 12-layer BERT model, with an uncased vocab.\n",
    "    num_labels = 2, # The number of output labels--2 for binary classification.\n",
    "                    # You can increase this for multi-class tasks.   \n",
    "    output_attentions = False, # Whether the model returns attentions weights.\n",
    "    output_hidden_states = False, # Whether the model returns all hidden-states.\n",
    ")\n",
    "\n",
    "# Tell pytorch to run this model on the GPU.\n",
    "model.cuda()\n",
    "#model.cpu()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "id": "AksknLguH3My"
   },
   "outputs": [],
   "source": [
    "# Note: AdamW is a class from the huggingface library (as opposed to pytorch) \n",
    "# I believe the 'W' stands for 'Weight Decay fix\"\n",
    "optimizer = AdamW(model.parameters(),\n",
    "                  lr = 2e-5, # args.learning_rate - default is 5e-5, our notebook had 2e-5\n",
    "                  eps = 1e-8 # args.adam_epsilon  - default is 1e-8.\n",
    "                )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "id": "ioeJ5LI8H5QS"
   },
   "outputs": [],
   "source": [
    "# Number of training epochs. The BERT authors recommend between 2 and 4. \n",
    "# We chose to run for 4, but we'll see later that this may be over-fitting the\n",
    "# training data.\n",
    "epochs = 2\n",
    "\n",
    "# Total number of training steps is [number of batches] x [number of epochs]. \n",
    "# (Note that this is not the same as the number of training samples).\n",
    "total_steps = len(train_dataloader) * epochs\n",
    "\n",
    "# Create the learning rate scheduler.\n",
    "scheduler = get_linear_schedule_with_warmup(optimizer, \n",
    "                                            num_warmup_steps = 0, # Default value in run_glue.py\n",
    "                                            num_training_steps = total_steps)\n",
    "\n",
    "# Defining loss function\n",
    "loss_fn = nn.CrossEntropyLoss().to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def format_time(elapsed):\n",
    "    '''\n",
    "    Takes a time in seconds and returns a string hh:mm:ss\n",
    "    '''\n",
    "    # Round to the nearest second.\n",
    "    elapsed_rounded = int(round((elapsed)))\n",
    "    \n",
    "    # Format as hh:mm:ss\n",
    "    return str(datetime.timedelta(seconds=elapsed_rounded))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining training epoch of BERT model\n",
    "def train_epoch(\n",
    "  model, \n",
    "  data_loader, \n",
    "  loss_fn, \n",
    "  optimizer, \n",
    "  device, \n",
    "  scheduler, \n",
    "  n_examples\n",
    "):\n",
    "    \n",
    "  # Measure how long the training epoch takes.\n",
    "  t0 = time.time()\n",
    "    \n",
    "  # Put the model into training mode\n",
    "  model = model.train()\n",
    "\n",
    "  losses = []\n",
    "  correct_predictions = 0\n",
    "  \n",
    "  # For each batch of training data...\n",
    "  for step, batch in enumerate(data_loader):\n",
    "    \n",
    "    # Progress update every few batches.\n",
    "    if step % 200 == 0 and not step == 0:\n",
    "        # Calculate elapsed time in minutes.\n",
    "        elapsed = format_time(time.time() - t0)\n",
    "              \n",
    "        # Report progress.\n",
    "        print('  Batch {:>5,}  of  {:>5,}.    Elapsed: {:}.'.format(step, len(data_loader), elapsed))\n",
    "    \n",
    "    # Unpack this training batch from our dataloader. \n",
    "    # As we unpack the batch, we'll also copy each tensor to the GPU using the `to` method.\n",
    "    input_ids = batch[0].to(device)\n",
    "    attention_mask = batch[1].to(device)\n",
    "    targets = batch[2].type(torch.LongTensor).to(device)\n",
    "    \n",
    "    outputs = model(\n",
    "      input_ids=input_ids,\n",
    "      attention_mask=attention_mask\n",
    "    )\n",
    "\n",
    "    _, preds = torch.max(outputs[0], dim=1)\n",
    "    loss = loss_fn(outputs[0], targets)\n",
    "\n",
    "    correct_predictions += torch.sum(preds == targets)\n",
    "    \n",
    "    # Accumulate the training loss over all of the batches so that we can calculate the average loss at the end\n",
    "    losses.append(loss.item())\n",
    "\n",
    "    # Perform a backward pass to calculate the gradients.\n",
    "    loss.backward()\n",
    "    \n",
    "    # Clip the norm of the gradients to 1.0.\n",
    "    # This is to help prevent the \"exploding gradients\" problem.\n",
    "    nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)\n",
    "    \n",
    "    # Update parameters and take a step using the computed gradient.\n",
    "    optimizer.step()\n",
    "    \n",
    "    # Update the learning rate.\n",
    "    scheduler.step()\n",
    "    optimizer.zero_grad()\n",
    "\n",
    "  return correct_predictions.double() / n_examples, np.mean(losses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def eval_model(model, data_loader, loss_fn, device, n_examples):\n",
    "  # Put the model in evaluation mode--the dropout layers behave differently during evaluation.\n",
    "  model = model.eval()\n",
    "\n",
    "  losses = []\n",
    "  correct_predictions = 0\n",
    "\n",
    "  # Tell pytorch not to bother with constructing the compute graph during the forward pass, since this is only needed for backprop (training).\n",
    "  with torch.no_grad():\n",
    "    for batch in data_loader:\n",
    "        \n",
    "      # Unpack this validation batch from our dataloader. \n",
    "      # As we unpack the batch, we'll also copy each tensor to the GPU using the `to` method.\n",
    "      input_ids = batch[0].to(device)\n",
    "      attention_mask = batch[1].to(device)\n",
    "      targets = batch[2].type(torch.LongTensor).to(device)\n",
    "\n",
    "      outputs = model(\n",
    "        input_ids=input_ids,\n",
    "        attention_mask=attention_mask\n",
    "      )\n",
    "      _, preds = torch.max(outputs[0], dim=1)\n",
    "\n",
    "      loss = loss_fn(outputs[0], targets)\n",
    "\n",
    "      correct_predictions += torch.sum(preds == targets)\n",
    "    \n",
    "      # Accumulate the validation loss\n",
    "      losses.append(loss.item())\n",
    "\n",
    "  return correct_predictions.double() / n_examples, np.mean(losses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 127 ms, sys: 76 ms, total: 203 ms\n",
      "Wall time: 204 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "history = defaultdict(list)\n",
    "best_accuracy = 0\n",
    "\n",
    "if pretrained:\n",
    "    model.load_state_dict(torch.load('bert_female_notoxic_state.bin'))\n",
    "    model = model.to(device)\n",
    "else:\n",
    "    # Performing training and validation for each epoch\n",
    "    # Report loss and accuracy\n",
    "    for epoch in range(epochs):\n",
    "\n",
    "        print(f'Epoch {epoch + 1}/{epochs}')\n",
    "        print('-' * 10)\n",
    "\n",
    "        train_acc, train_loss = train_epoch(\n",
    "        model,\n",
    "        train_dataloader,    \n",
    "        loss_fn, \n",
    "        optimizer, \n",
    "        device, \n",
    "        scheduler, \n",
    "        train_size\n",
    "        )\n",
    "\n",
    "        print(f'Train loss {train_loss} accuracy {train_acc}')\n",
    "\n",
    "        val_acc, val_loss = eval_model(\n",
    "        model,\n",
    "        validation_dataloader,\n",
    "        loss_fn, \n",
    "        device, \n",
    "        val_size\n",
    "        )\n",
    "\n",
    "        print(f'Val   loss {val_loss} accuracy {val_acc}')\n",
    "        print()\n",
    "\n",
    "        history['train_acc'].append(train_acc)\n",
    "        history['train_loss'].append(train_loss)\n",
    "        history['val_acc'].append(val_acc)\n",
    "        history['val_loss'].append(val_loss)\n",
    "\n",
    "        # Save the model if it has the best accuracy so far\n",
    "        if val_acc > best_accuracy:\n",
    "            torch.save(model.state_dict(), 'bert_female_notoxic_state.bin')\n",
    "            best_accuracy = val_acc\n",
    "\n",
    "    # Plot the performance of the model over all epochs\n",
    "    plt.figure(0)\n",
    "    plt.plot(history['train_acc'], label='train accuracy')\n",
    "    plt.plot(history['val_acc'], label='validation accuracy')\n",
    "\n",
    "    plt.title('Training history')\n",
    "    plt.ylabel('Accuracy')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.legend()\n",
    "    plt.ylim([0, 1]);\n",
    "    \n",
    "    plt.figure(1)\n",
    "    plt.plot(history['train_loss'], label='train loss')\n",
    "    plt.plot(history['val_loss'], label='validation loss')\n",
    "\n",
    "    plt.title('Training history')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.legend()\n",
    "    plt.ylim([0, 1]);\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 835
    },
    "id": "PCXAxB6tIXY5",
    "outputId": "989a2a82-18af-461e-d910-a7ca561c1bdf"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using female toxic test data without offensive words\n",
      "Number of test sentences: 5,630\n",
      "\n",
      "Predicting labels for 5,630 test sentences...\n",
      "    DONE.\n",
      "Total F1: 0.867\n",
      "Accuracy: 0.76\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXwAAAEGCAYAAABmXi5tAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjMuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8vihELAAAACXBIWXMAAAsTAAALEwEAmpwYAAAp2klEQVR4nO3deZxO5f/H8ddnFsvYIiZFlrJUlmTN104iEVlCtKBQtC8/RZLSJkoiVAqVLCHSolCRCtmypBVl3xtmzHr9/rhvYzAzBnPPdt7Px8PDfZZrOeP4zHVf55zPMeccIiKS8wVldgdERCRjKOCLiHiEAr6IiEco4IuIeIQCvoiIR4RkdgdSciwO3T4kInKW8oRgKW3TCF9ExCMU8EVEPEIBX0TEIxTwRUQ8QgFfRMQjFPBFRDxCAV9ExCMU8EVEPEIBX0TEIxTwRUQ8QgFfRMQjFPBFRDxCAV9ExCMU8EVEPEIBX0TEIxTwRUQ8QgFfRMQjFPBFRDxCAV9ExCMU8EVEPEIBX0TEIxTwRUQ8QgFfRMQjFPBFRDxCAV9ExCMU8EVEPEIBX0TEIxTwRUQ8QgFfRMQjFPBFRDxCAV9ExCMU8EVEPEIBX0TEIxTwRUQ8QgFfRMQjFPBFRDxCAV9ExCMU8EVEPCIkszsgJzt06CC9e94JwL59+wgKDqJI4SIAfPDRDEJz5TrvNnrdeRuRkUeZOn0WABvW/8LIV17mnfemnHfdkrNdU+VKypevkLj86ugxlChRMtl9r615DT+uXH1e7T315ABWrlxOgfwFsKAgnhw0mKurXXNedXqZAn4Wc8EFhZk+6xMA3hwzmrCwMO7o0Stxe1xcHCEh5//PdmD/AZYu+Zb6DRqdd13iHblz50k8PzPKw488TvMWLVn2/VKefWYwM2fPy9D2cxIF/GzgqScHULBQIX7dtJErr6pEvnz5TvpF0L5ta0aPHUeJEiX5dN4nfPj+FOJiY6lc9WoGPvU0wcHBp9V5R89evDXuzdMCfnx8PKNefYWVy5cTExtD567d6HRLFxISEnjhuaGsXLmCEiVL4hISaHdzB5q3aJkhPwPJmiKPHuWB++7lv//+Iy4ujv73P0CTptedtM/evXt4/JGHOHrkCHHx8QwaPITqNWqy7PulvDlmNDExMVx66aUMfe4FwvLlS7GtGjVr8c+2bQBMfu9d5sz+GID2HTrS/fY7iYyM5PFHHmT3rl3EJyTQu++9tLyhVeAOPhtSwM8mtm7dwoR33iM4OJg3x4xOdp+//vyTLz//nEnvTyU0NJRhQ4fw2afzaNO23Wn7Xn11NRZ9/RXLf/qRfEn+k83+eCb58xfgw+kfExMTwx3du1D3f/XYtGEDO3Zs5+M58ziwfz/tbmpFu5s7BOhoJauKjj7GLe3bAnBJyZK8MnIUr74+hvz583Pw4AFu69qZxk2aYWaJZT6b/yn/q1efu/vcQ3x8PMeORXHw4AHeGv8m499+l7CwMCa+PYHJk96l7739U2z7228WUa58BTZuWM8nc2bx/tTp4Bzdut5CjVq12f7PPxQrFs4bb04AICIiIrA/jGxIAT+buP76lsmO1JP66ccf2LRxPd06dwTgWPQxilx4YYr7393nHt4a/yYPPvxo4rofln3Pb79t5usFXwIQcSSCbVu3snrVzzRv0ZKgoCCKFitGrdp10uGoJLs5dUonNjaW118byaqfVxBkQezZs5v9+/ZRtFixxH0qV67C04OeJC4ujiZNr+OKK69k5YrF/PXnH9zZvWtiPVWrVUu2zZEjXuat8W9SuEgRhjw7jOU//kDTZtcRFhYGQLPrmrPq55XUq9+AEa+8xKsjhtOocROq16gZuB9ENqWAn03kzZs38XNwcDAJCQmJyzHR0QA4HG3a3swDDz2SpjrrXFuXsaNHsW7t2sR1zjkGPDmIevUbnLTvku++OY/eS0712afzOHjwAFOnzyI0NJQbmjclOib6pH1q1KzFxMnvs+Tbbxn4xOPc2aMXBQoW5Nq69XjplZFnbOP4HP5xP/2wLNn9ypQpy0fTZ7FkybeMenUEdf9XL9VvDF6k2zKzoUtKlGDTpo0AbNq4ge3b/wWgTp26fL3gS/bv3w/A4UOH2LFje6p13dXnHt6b+Hbi8v/q1WfGtKnExsYCsGXL30RGRnJN9Rp8/dUCEhIS2L9vHyuXLw/EoUk2c+RIBEWKXEhoaCjLf/ox2fNtx47tFClyIR063cLN7TuwaeMGql5djTWrV7Ft61YAoqKi2LLl7zS1WaNmLRYv+pqoqCgiIyNZtPBrqteoyZ49u8mTNy+t27Tljh69+NX/f0RO0Ag/G7queQvmzf2EW9q3pVLlKpQuUwaAy8uVo9/9D3LP3T1JcAmEhITy5KDBXHJJiRTratCwEYWLFElcbt+xEzt2bKdLp/Y45yhcuDCvjR7Ldc1b8NOPP9ChbWtKlylDlapVyV+gQKAPVbK4Vq3bcH+/e+h6S3sqXnElZS+77LR9Vi5fznvvvkNISAhhYWE898JLFClShKHDXmDAYw8TExsDQP/7HqRMmbJnbPPKqypxU9v2dOvSCfBdtL3yyqv4fukSXh3xMkEWREhICAMHD0nXY80JzDmX2X1I1rE4smbHPCzy6FHC8uXj0KGDdOvSiUlTpp40VysimS9PCJbSNo3wJc3u69eXiP/+IzY2lt597lWwF8lmNMIXEclBUhvh66KtiIhHKODncN8v+Y6bbmxB65bNeeetCZndHZGT6PzMWAr4OVh8fDzPDxvK2HFvM3vufL747FP+/OOPzO6WCKDzMzMENOCbWT4zC0qyHGRmYYFsU05Y/8s6Lr20NCUvvZTQXLlo2epGvlm8MLO7JQLo/MwMgR7hLwSSBvgw4OsAtyl+e3bvpvjFxROXwy+6iN27d2dij0RO0PmZ8QId8PM4544cX/B/TnGEb2a9zWylma3UfN75c8nc6JQ0qZVIZtL5mfECfR/+UTOr7pxbBWBmNYColHZ2zk0AJoBuy0wPF11UnF07dyUu79m9m/Dw8EzskcgJOj8zXqBH+A8CM8xsiZktAaYBymaUQSpVrsK2bVv4999/iI2J4YvP5tOoSdPM7pYIoPMzMwR0hO+cW2FmVwAVAQN+dc7FBrJNOSEkJIQnBg7mnt53kZAQT7ubO1CuXPnM7pYIoPMzMwTkSVsza+qcW2Rm7ZPb7pybdaY6NKUjInL2MiOXTiNgEdAmmW0OOGPAFxGR9KVcOiIiOUim5dIxsylmVijJcmkz05MV5+FMj6I753jx+edo3bI5HW9uw6aNG85Y9tURw+l4cxsGPvF44rp5c+fwwZRJgT0YyVF0bmZ9gb5LZynwk5m1MrO7ga+A1wLcZo6VlkfRly75jm1btzDv8wUMHvIszw0dkmrZiIgI1q5ZzczZ80iIj+f33zZz7Ngx5s6ZzS1dbs34g5RsSedm9hDQgO+cGw/cBXwCDAUaOufmBbLNnCwtj6IvXrSQNje1w8yoenU1IiL+Y+/ePSmWDQoyYmNjcc5xLDqakJAQ3pv4Nrd2v43Q0NBMOlLJbnRuZg+BntK5DZgI3A68B3xmZlcHss2cLC2Pou/Zs5uLip/Y56KLirNn9+4Uy+bLl5/rml9P5w7tKFGiJPkLFGDD+vU0aXpd4A9Icgydm9lDoJ+07QDUd87tAaaa2Wx8gf+aALebI6XpUfRkLsKbWaple/S6mx697gZgyOCB3Hvf/cyaOYMfli2lfIWK9O57bzr0XnIynZvZQ6CndNoBh8yssplVBlYDdQLZZk6WlkfRwy8qzu5dJ/bZvXsXxcLD01R206aNAJQuXYZ5c+cwfOQo/vjjd7Zu3RKAo5GcROdm9hDoKZ1GwO/AGGAs8BtwbSDbzMnS8ih64yZNmTd3Ds451q1dQ/78BShWLDxNZceMHsW9/e8nLi6OhPh4AIIsiGNRxzLsGCV70rmZPQR6SmckcL1zbjOAmVUApgI1AtxujpTSo+jTp00F4JbOXWnQsBFLv/uW1jc0J0+evAx97vlUyx63aOHXVK5chfDwiwCoWu0aOrRrQ4UKFah4xRUZf7CSrejczB4C+uCVma1zzlU907rk6MErEZGzlxmpFY5baWbvAFP8y92AnwPcpoiIJCPQI/zcQD+gPr5smd8BY5xzMWcqqxG+iMjZS22EH+iA/4BzbtSZ1iVHAV9E5OxlWi4d4I5k1t0Z4DZFRCQZAZnDN7OuwK1AWTObm2RTAWB/INoUEZHUBeqi7TJgJ1AUGJFkfQSwLkBtiohIKpQPX0QkB8nMfPjtzex3MztsZv+ZWYSZ/RfINkVEJHmBvkvnD6CNc27T2ZbVCF9E5Oxl5l06u88l2IuISPrLiCdtpwFzgOjjK51zeom5iEgGC3TALwhEAtcnWecABXwRkQymu3RERHKQzLxLp6SZzTazPWa228w+NrOSgWxTRESSl+KUjplVT62gc25VGup/F/gQ6ORf7u5f1zytHRQRkfSR4pSOmS1OpZxzzjVNZfvxOtY456qdaV1yNKUjInL2zikfvnOuSTq0vc/MuuN7yxVAV5RLR0QkU5xxDt/MwsxskJlN8C+XN7PWaay/J3ALsAtfbp2O/nUiIpLBzniXjv8++p+B251zlc0sL/BDWqZlzoemdEREzt75vuLwcudcZ3/KY5xzUWaWYoUAZjY4lc3OOfdsGtoVEZF0lJaAH+Mf1TsAM7ucJE/NpuBoMuvyAb2ACwEFfBGRDJaWKZ3mwCDgKmABUA+40zn3TZoaMCsAPIAv2E8HRjjn9pypnKZ0RETO3nm/09bMLgSuxfci8h+dc/vSUKYI8DDQDZgEjHLOHUxrpxXwRUTO3vnO4QM0Aurjm9YJBWantrOZDQfaAxOAKs65I2lsR0REAiQtUzpjgXKcuJe+M/Cnc65fKmUS8M3zx8FJI3XDd9G24Jk6phG+iMjZO68pHTPbAFR2/h3NLAj4xTlXKV17eQoFfBGRs3e+ydM2A6WSLF+KXkQuIpLtpJY8bR6+6ZhCwCYzW+5frgMsy5juiYhIekntou0rGdYLEREJOL0ARUQkBzmvOXwzu9bMVpjZETOLMbN4M/svfbsoIiKBlpaLtm/gS2v8O5AXuMu/TkREspE0PXjlnPvDzIKdc/HAu2ami7YiItlMWgJ+pJnlAtaY2cv48trnC2y3REQkvaVlSuc2/3798WXBvBRf2gQREclGzukuHTOb5pzrHID+JNJdOiIiZ+98n7RNTt1zLCciIpnkXAO+iIhkM6mlVqie0iZ8KZIDauGvZ3xHikim6Hjb0MzugkiKolanfNd8anfpjEhl26/n3BsREckUKQZ851yTjOyIiIgElubwRUQ8QgFfRMQjFPBFRDwiLdkyzcy6m9lg/3IpM6sd+K6JiEh6SssIfyy+B626+pcjgDEB65GIiAREWpKn1XHOVTez1QDOuYP+ZGoiIpKNpGWEH2tmwfjeZ4uZFQMSAtorERFJd2kJ+K8Ds4FwMxsGLAWeD2ivREQk3Z1xSsc594GZ/Qw0w5dWoZ1zblPAeyYiIunqjAHfzEoBkcC8pOucc9sC2TEREUlfabloOx/f/L0BeYCywGagUgD7JSIi6SwtUzpVki77s2j2CViPREQkIM76SVvn3CqgVgD6IiIiAZSWOfyHkywGAdWBvQHrkYiIBERa5vALJPkch29O/+PAdEdERAIl1YDvf+Aqv3PusQzqj4iIBEiKc/hmFuKci8c3hSMiItlcaiP85fiC/RozmwvMAI4e3+icmxXgvomISDpKyxx+EWA/0JQT9+M7QAFfRCQbSS3gh/vv0FnPiUB/nAtor0REJN2lFvCDgfycHOiPU8AXEclmUgv4O51zQzOsJyIiElCpPWmb3MheRESyqdQCfrMM64WIiARcigHfOXcgIzsiIiKBddbJ00REJHtSwBcR8QgFfBERj1DAFxHxCAV8ERGPUMAXEfEIBXwREY9QwBcR8QgFfBERj1DAFxHxCAV8ERGPSMsbrySDPNKpEReXuixxuef/PU+R8IuT3XdAt+t58YMF59Xe1NHD2LxuJYPGTiMkNBdH/jvEq4/fzVPjZpxXvZKzFSmUj8/G3wfARRcWJCEhgb0HjwDQoPtwYuPiz7uNL996gOJFC3IsJpajkdH0GfIBv2/dc971ep0CfhYSmis3j454N0PbDAoK4qeF86nX8uYMbVeyrwOHj3JtlxcBGNinFUcjo3ltysLE7cHBQcTHJ5x3Oz0GTmLVxm30bF+P5x+6mU4Pjj/vOr1OAT8Li46KZOJLTxB5JIL4+Hhadb2LyrUbnLTPfwf3MXnEEI5FHSUhPp6OvR/hsquuZvOa5XwxbSJxsTEULV6CLv2eIHfesNPaaHhjJ777dDrXNm9z2rZFcz5k7bLFxMXGUKVOQ1p26QXAghnvseq7r7igaDj5ChSi5OUVadK2a2B+CJItTHimOwf/i+TqiiVZ8+s/RByNPukXwcoZT9L+/nFs23mALq1q0a9rI0JDQ1jxyxYeeGEaCQkpv0Rv6ao/6N+tMQDPP9iO6+tdhXPw0ttfMHPBKooXLciUl3pSIF8eQoKDeOD5aXy/+s+MOOxsRwE/C4mNieaVR3oAUCT8Yu54dCg9Hn+ePGH5OPLfIUY90ZdKtepjduLdNKuWfE3FarVp3vF2EuLjiYmJ5sh/h/hq5mT6Pv0qufPkZeHsD/hm3jRa3NLjtDYLF7uIsldW5edvv+SqmvUS129es5x9O//lwZcm4Jxj4osD+HPDGnLlzsO6H7/l4VcmkpAQz8hHe1Hy8oqB/+FIlleuVDit+o4mIcExsE+rZPepWPYiOl5fnSY9RhIXl8BrT9xCl1a1+PDT5SnWe2PDymz4fQftmlWjasWS1O78AkUvyM/S9x9j6ao/6HxDTb5atomX3/mSoCAjLE+uQB1itqeAn4WcOqUTHxfH/A8m8NfGNVhQEIcP7CXi0AEKFr4wcZ9LL7+Cj8a+SHx8HFVqN6BE2fJs2LCa3f9uYfTAe/31xFK6QuUU223W/jYmvjiAK2v8L3Hd5rUr2Lx2BSMe7QlA9LEo9u78l+hjkVSuVZ9cuXMDUKnm/5KtU7xn1terUx2pAzSpXZHqV5Vi6fuPA5A3dyh7DxxJdt93h91BVHQs23bs5+GXZnB/96ZM/2IlCQmOPQciWPLzH9SoVJqVG7Yy/unuhIYEM2/xWtb9tj3djy2nUMDPwn7+bgFH/zvEw8PfITgkhGf7diIuNuakfS6vVI3+z77Bxp+X8cHrz9GkbVfC8hWgQtWa3PbwkDS1U+ziklxSpjxrvl+UuM45R7P23fnf9W1P2vfbedPO97Akh4qMik78HBcfT1DQiW+ieXKFAmBmvD/vJwaPnnvG+o7P4R+X9JttUt+v+pPmd71Gy/qVeOe5O3h18tepfmPwMt2WmYUdizxK/kIXEBwSwu+/rOLg3l2n7XNgzy7yF7qAus1vok6zG/n3r98oXeEq/t78C3t3/gtATPQx9uzYdlrZpJp3uJ1v5n6UuHxFtdosXzSf6KhIAA7t30vE4YOUvbIqG1Z+T2xMNNFRkWxc9UM6HrHkFFt3HKDalZcCUO2KkpQp4ftWunj5Zm6+rhrFCucHoHDBMEpdXDhNdS5d9Qcdr69BUJBRtHB+6tcox8r1Wyh1cWH2HIjg3dnLmDRnGddccWlgDioH0Ag/C6vesDnvvDCAkY/fRYky5QgvUfq0ff7csJrFn0wlOCSEXHnycut9A8lfqDBd+z/J+68+k/iN4IZb7yb8klIptlW8VFlKXlaBf//6DYCK1Wqz+9+tjHryHgBy58lLtweeolS5K6lUqz6vPNKDwsWKc+nlV5AnLF8Ajl6yszkL19CtdW1+/GgAP2/YmnhL5a9/7eKZMZ8y783+BJkRGxfPQy9OZ9vOg2es85NFa6lTtSzLpz2BczDwtTns3h9BtzZ1eOj2ZsTGxXM0MppeT00J9OFlW+Zc6nNumWX++j1Zs2NCdFQkufOGERN9jDee6s8tfR+j5GXeuXDb8bahmd0FkRRFrX4j+bkvNMKXczB93HB2/7uFuJgYajZp6algL5KdKeDLWbvtoaczuwsicg4U8LOpj8a8wMaVy8hfqDCPvzYZgM+nvs365UuwoKDEefxCRYqyee0K5r8/jri4OEJCQmhz+72Ur1LjpPreeWEA+3fvSKxL5HwFBRnff/A4O/YcpsMD4xh87420blSVBOfYeyCC3k+/z869hwF4tOf13Nm2LvEJCTzy8ky+/mETAKEhwbw64BYa1ixPQkICQ8Z8ypyFazLxqLI3BfxsqlbjG6h/Q3s+fH1Y4rombbtyQ9e7APhu/kwWzHiPTn0eJV+BQvR64iUKFSnKzm1/Mf7ZRxjy1uzEcut+/JZcefJm+DFIztb/1iZs/ns3BfLlAeDVSQsZOnY+APd2bcQTvW/g/mEfccVlxenUojrVOw7j4mKF+Gxcf6q0G0pCguP/7mrB3gMRVG03FDOjSKHTnxaXtNNtmdnU5ZWqEZa/4Enrkt4tExMdxfErNyUvq0ChIkUBKH5pWeJiYhLv3omOiuTbedNo3vH2DOm3eEOJ8AtoWb8S785elrgu4uixxM9heXNz/IaR1o2rMuPLVcTExrF1x37+/GcftSqXAeCOtnUZPtGXJNA5x/5DRzPuIHKggI3wzawf8IFz7pB/uTDQ1Tk3NlBtCnz2wQRWfvslecLyce8zo07bvu7HbyhRtjwhob7Hzz//6G0a3dSFXLnzZHRXJQcb/lgHBo6aQ/6wk8+rIf3a0K11bQ4fiaJl79cBKFGsED/9siVxn+17DnJJeCEK5fd963y6X2sa1CjP3//u5aEXZ7DnQESGHUdOE8gR/t3Hgz2Ac+4gcHdqBcyst5mtNLOVX8zQXPK5aNWtN4MnfEz1hs1Z+vmsk7bt2vY3n04ZR6e+jwGw/e/f2bdzO1XrNMyMrkoOdUODyuw5EMHqTf+ctm3ImHmUv+EpPvp8JX07+8+7ZJ6gdQ5CQoIoWbwwP6z5i//d+hI/rdvCCw8pq+v5CGTAD7Ikz0KbWTCQalYj59wE51xN51zNlp00xXA+qtdvzrofv01cPrR/D+++/CS33j+QosVLALBl83r+/Wszz/btxOiB/di78x/GDL4vs7osOUTdapfRulEVfp3/DJNf7EHjWhWY+NzJ/5+nf76Cds2qAbB9zyFKFj/xtG2J8MLs3HuY/YeOcjQqmk8WrQVg1lerEp/elXMTyID/JTDdzJqZWVNgKvBFANvzvL07ToyoNqxcSngJ35O1UUcjeGvY47Tq1oeyV1RN3Kdey5sZ8vYcnho3g/uGjaHYxZfSb+joDO+35CyDR8+lXMunuOLGp7l9wLt8s+I3eg6azOWliiXuc2Ojqvy2ZTcA879ZR6cW1ckVGkLpSy6kXKlirFi/BYDPvltPw5rlAWhcuyK//rUzw48nJwnkXTr/B/QB7gEMWAC8HcD2PGXKyCH8sWE1RyMO88zd7WnRuSebVv3I3h3bMDMKFytOxz6PArD081ns37Wdr2ZO4quZkwDoM3gkBQqlLYeJSHp47v62lC8dTkKCY9vOA9w/zJe7adNfu/h4wWpWfzyQuPgEHnxxemLWzUGj5vDOc3cw/NEO7Dt4hD5D3s/MQ8j2lFpB5CwptYJkZRmaWsHMpjvnbjGzX4DTgrZzrmoyxUREJMACMaXzgP/v1gGoW0REzlG6B3zn3PGrKvmccxuTbjOzxsDW9G5TRETOLJAXbaeb2RTgZSCP/++aQN0AtpnjHNy3mw9fH0bEoQOYGXWb30TD1p1SzJtzqmf7diJ33jCCgoIICg7m4Zd9183nThrDxpXLCA4J4cLiJeja/wny5ivA37+uY+b4EYSE5qL7Q09T7OKSRB2NYPKIp+n91IgU3zok3lO+dDhTXuqZuFy2xIU8++Z83vjwG+7p0oi+nRsSF5/AF0vWM3DUJ8nWcWq+HYCqFUowemAXcucO9V3EfX4aKzdspe7VlzHqyc7ExMZx+xPv8tc/+yiUPy9TXurJTf3GZMgxZ3eBDPh1gJeAZUAB4AOgXqol5DTBwcG0vbMfJS+ryLGoSF59rBcVrq6ZYt6c5Nz7zCjyF7zgpHUVr67Fjd37EBwcwrwpb/L1rPdpc9s9fDN3Gnc+9hwH9u5i2ZdzaHtnfxbMmESzDrcp2MtJft+6h2u7vAj4AvefXw5j7uK1NKxZntaNq1DrlheIiY1LfLtVck7NtwMw7MF2DJvwOQu+30iL+lcx7MF2tLh7FA/c1pSuj71N6YsvpHenBgwYOZsnerfk5YlfBvxYc4pA3ocfC0QBefGN8P92ziUEsL0cqWDhoon55vPkDSO8ZBkOH9iXYt6ctKpYrTbBwb7f96UrVOLw/r0ABAeHEBsTTWz0MYKDQ9i3azuHD+ylXKVr0uV4JGdqUrsif/+7l207D9K7UwNeefcrYmLjANh7MPmXlCeXbwd8T9kW9P8CKJQ/b2JGzdi4ePLmDiUsbyixcfGULVmUS8IvYOnPfwTwyHKWQI7wVwCfALWAC4HxZtbROdcxgG3maAf27GT7379RuvxVwJnz5oDvxc/jhz7snw5qS93rbzptn+UL51OtXlMAmrXvzvRxwwnNlZtuDwxi7qQx3NDlrsAdlOQInVrUYPoXPwNQrnQ49a65nGf6teFYTCxPjJzNzxtPf6dySvl2HntlJvPG9OOFh24mKMhocucI3/4TFzBmUFeiomPpNWgyLzx8M8+M/TTwB5eDBDLg93LOrfR/3gW0NbPbAthejhYdFcl7wwfRrsf9iaP7Vt1606pbb76eNYWln8+iZZdep5W7b9hYChUpSsThg4x75iHCS5Ti8krVErd/NXMyQcHB1Gh4PQAlypbnwRfHA/DnhjUUKlwUh2PyiKcJCgmm7R39KXBBkcAfsGQboSHB3NioCoNHzwUgJDiIwgXDaHj7K9SsVJr3X+7Jla2HnFQmab6dBjXKn7Std6cGPD5iFnMWrqFD82t48+lu3Nj3Ddb9tp1Gd/iCf73ql7Nz72EMY8qLPYiNi2fAyNlKrHYGgZzSWWtm95vZTP+f/sBHAWwvx4qPi+O94YOo3qA5Va9tdNr2U/PmJHX8Qm6BQoWpUqch2/7YlLhtxeLP2fjzMro/OPi0+XnnHF99PJnmne5kwfT3aNG5JzUatmDJ/JnpeGSSE7SofxVrfv0nMdhu332IOQt9+W9WbthKQoKj6Cnz+Knl2+nWuk7iS04+/mo1NSuVPq3NAXe15IUJnzOwzw08O+4zpn62gnu7Ng7cQeYQgQz4bwI1gLH+P8c/y1lwzjFt7IuElyxD45u6JK5PKW9OUtHHojgWFZn4+be1Kyhe6jIANq3+iUVzPqDXgBeSTY28YvHnXFW9LmH5CxATfQwLMoLMiIk5dtq+4m23tKyZOJ0DMO+bdTSuXQGAcqXCyRUawr5T5vFTyrcDsHPv4cRRf+PaFfhj296TynZvU4cvlmzgUEQUYXlykZDgSEhwhOUJDeRh5giBeNI2xDkXB9Ryzl2dZNMiM1ub3u3ldH//+gsrv/2Si0tdxiuP9ACg1a29+Wnh/GTz5hw+sI9pY1+i96DhHDl0kIkvPwlAQnw81Rs058pr6gAw6+1XiY+NZdzQhwHfhdvjd/nERB9jxTdf0HfwSAAat+nMe8OfIiQkhO56n60kkTdPKE3rXEH/56Ymrps05wfGD+nGyhlPEhMbz12DpwBwcbFCjB18Kzff92aqdfZ79kOGP9aRkJAgoqPjTqo7b55QurepQ+t73wDg9fcXMfWVu4iJjeOOJ95L/wPMYdI9l46ZrXLOVTezVUAn59yf/vWXATOdc9XTUo9y6UhWpVw6kpVlaC4dSLxD8FFgsZn95V8uA/QIQHsiIpIGgQj4xczsYf/n8UAwcBTfvfjXAIsD0KaIiJxBIAJ+MJAfTnoW6Pgl+gIBaE9ERNIgEAF/p3NOk5wiIllMIG7LVMIVEZEsKBABv1kA6hQRkfOU7gHfOXcgvesUEZHzF8gnbUVEJAtRwBcR8QgFfBERj1DAFxHxCAV8ERGPUMAXEfEIBXwREY9QwBcR8QgFfBERj1DAFxHxCAV8ERGPUMAXEfEIBXwREY9QwBcR8QgFfBERj1DAFxHxCAV8ERGPUMAXEfEIBXwREY9QwBcR8QgFfBERj1DAFxHxCAV8ERGPUMAXEfEIBXwREY9QwBcR8QgFfBERj1DAFxHxCAV8ERGPUMAXEfEIBXwREY8w51xm90EygJn1ds5NyOx+iJxK52bG0QjfO3pndgdEUqBzM4Mo4IuIeIQCvoiIRyjge4fmSCWr0rmZQXTRVkTEIzTCFxHxCAV8ERGPUMDPgszMmdmIJMuPmtmQc6yrjJndeh59GWpm151refEeM7vQzNb4/+wys+1JlnOlofwlZjYzI/rqNZrDz4LM7BiwE6jlnNtnZo8C+Z1zQ86hrsbAo8651unaSZE08A9UjjjnXsnsvohG+FlVHL47Fx46dYOZlTazhWa2zv93Kf/698zsdTNbZmZ/mVlHf5EXgQb+0dVDZpbHzN41s1/MbLWZNfGX/8TMbvd/7mNmHySpt6P/cy1//WvNbLmZFQj8j0JyAjNr5j/ffjGziWaW238+rfOfk/nMbIOZVfZ/K13vLxdsZq/4y60zs/sy+1iys5DM7oCkaAywzsxePmX9G8Bk59wkM+sJvA6082+7GKgPXAHMBWYCA0gywjezRwCcc1XM7ApggZlVwPe04/dm9jfwCHBt0kb9X8WnAZ2dcyvMrCAQlc7HLDlTHuA9oJlz7jczmwzc45x7zczmAs8BeYH3nXPrzaxMkrK9gbLANc65ODMrksF9z1E0ws+inHP/AZOB+0/ZVBf40P95Cr4Af9wc51yCc24jcFEKVdf3l8M59yuwFajgnNsNDAYWA4845w6cUq4isNM5t+J4/5xzced0cOI1wcDfzrnf/MuTgIb+z0OB5kBN4NTBDcB1wLjj51oy56WcBQX8rO01oBeQL5V9kl6EiU7y2VLYP6X1AFWA/cAlKZTTBR85F0dT2VYEyA8UwPdN4FQ679KRAn4W5h/NTMcX9I9bBnTxf+4GLD1DNRH4/jMd952/HP6pnFLAZjOrDdwAXAM8amZlT6nnV+ASM6vlL1vAzDQlKGmRByhjZuX8y7cB3/o/TwCeAj4AXkqm7AKg7/FzTVM650cBP+sbARRNsnw/0MPM1uH7j/PAGcqvA+L8F1ofAsYCwWb2C745+Tv9+70F9HTO7cA3hz/RzBK/DTjnYoDOwGgzWwt8RfIjMpFTHQN6ADP8510CMM5/k0Ccc+5DfDcX1DKzpqeUfRvYhu961lrgnG8xFt2WKSLiGRrhi4h4hAK+iIhHKOCLiHiEAr6IiEco4IuIeIQCvmRpZhbvzwO03sxmmFnYedSVNC/Q22Z2VSr7Njaz/51DG1vMrGha16dQx51m9kZ6tCuSlAK+ZHVRzrlqzrnKQAzQN+lGMws+l0qdc3f5U1CkpDFw1gFfJCtTwJfsZAlQzj/6XmxmHwK/+DMqDjezFf6Min0AzOcNM9toZvOB8OMVmdk3ZlbT/7mlma3yP5y20J+8qy/wkP/bRQMzK2ZmH/vbWGFm9fxlLzSzBf5MkONJPXXFScystj/76Gr/3xWTbL7UzL4ws81m9nSSMt39mUrXmNn4c/2FJ96kR+MlW/A/Wn8D8IV/VW2gsnPubzPrDRx2ztUys9z4sn4uwJcmoiK+HEEXARuBiafUWwzfU8YN/XUVcc4dMLNxJMnj7v/l8qpzbqn5UlJ/CVwJPA0sdc4NNbMb8WV3TKtf/e3Gme8lM88DHZIeHxAJrPD/wjqK72nnes65WDMbiy9NxuSzaFM8TAFfsrq8ZrbG/3kJ8A6+qZblzrm//euvB6raiXcAFALK48vIONU5Fw/sMLNFydR/LfDd8bpSycZ4HXBVkmwTBc33PoCGQHt/2flmdvAsjq0QMMnMyuNLEBaaZNtXzrn9AGY2C1+W0zigBr5fAOBLKbznLNoTj1PAl6wuyjlXLekKf7BLmoHRgPucc1+esl8rzpxpMa3ZGIOAus65k94B4O/LueYneRZY7Jy72T+N9E2SbafW6fx9neSce+Ic2xOP0xy+5ARfAveYWSj4soCaWT58mUG7+Of4LwaaJFP2B6DR8eygSbIxnppldAHQ//iCmVXzf0yaffQGoPBZ9LsQsN3/+c5TtjU3syJmlhffC26+BxYCHc0s/Hhfzaz0WbQnHqeALznB2/jm51eZ79V44/F9e50N/A78ArzJiZS8iZxze/HNu8/yZ2Oc5t80D7j5+EVbfFlKa/ovCm/kxN1CzwANzWwVvqmlban0c52Z/ev/MxLfCz9eMLPv8b0kJKml+F5Uswb42Dm30n9X0SB8bylbhy9j6cVp+xGJKFumiIhnaIQvIuIRCvgiIh6hgC8i4hEK+CIiHqGALyLiEQr4IiIeoYAvIuIR/w/7XOu05t+CaQAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Evaluating test set\n",
    "\n",
    "# Initialising\n",
    "accuracies = []\n",
    "\n",
    "# Get previous test data if pretrained\n",
    "if pretrained:\n",
    "    with open(\"female_notoxic_test.data\", 'rb') as file:\n",
    "        df = pickle.load(file)\n",
    "    file.close()\n",
    "else:\n",
    "    df = female_test_data\n",
    "    with open(\"female_notoxic_test.data\", 'wb') as file:\n",
    "        pickle.dump(df,file)\n",
    "    file.close()\n",
    "    \n",
    "df = df.sample(frac=1)\n",
    "print('Using female toxic test data without offensive words')\n",
    "print('Number of test sentences: {:,}\\n'.format(df.shape[0]))\n",
    "\n",
    "# Extract necessary information\n",
    "comments = df.comment.values\n",
    "labels = df.toxicity.values\n",
    "\n",
    "# Removing offensive words from comments\n",
    "new_comments = []\n",
    "for comment in comments:\n",
    "    new_comment = clean_comment(comment)\n",
    "    new_comments.append(new_comment)\n",
    "comments = new_comments\n",
    "\n",
    "# Tokenize all of the sentences and map the tokens to their word IDs.\n",
    "input_ids = []\n",
    "attention_masks = []\n",
    "\n",
    "# For every sentence...\n",
    "for cmt in comments:\n",
    "    # `encode_plus` will:\n",
    "    #   (1) Tokenize the sentence.\n",
    "    #   (2) Prepend the `[CLS]` token to the start.\n",
    "    #   (3) Append the `[SEP]` token to the end.\n",
    "    #   (4) Map tokens to their IDs.\n",
    "    #   (5) Pad or truncate the sentence to `max_length`\n",
    "    #   (6) Create attention masks for [PAD] tokens.\n",
    "    encoded_dict = tokenizer.encode_plus(\n",
    "                        cmt,                      # Sentence to encode.\n",
    "                        add_special_tokens = True, # Add '[CLS]' and '[SEP]'\n",
    "                        max_length = MAX_LEN,           # Pad & truncate all sentences.\n",
    "                        padding='max_length',\n",
    "                        truncation=True,\n",
    "                        return_attention_mask = True,   # Construct attn. masks.\n",
    "                        return_tensors = 'pt',     # Return pytorch tensors.\n",
    "                )\n",
    "      \n",
    "    # Add the encoded sentence to the list.    \n",
    "    input_ids.append(encoded_dict['input_ids'])\n",
    "      \n",
    "    # And its attention mask (simply differentiates padding from non-padding).\n",
    "    attention_masks.append(encoded_dict['attention_mask'])\n",
    "\n",
    "# Convert the lists into tensors.\n",
    "input_ids = torch.cat(input_ids, dim=0)\n",
    "attention_masks = torch.cat(attention_masks, dim=0)\n",
    "labels = torch.tensor(labels)\n",
    "\n",
    "# Set the batch size.  \n",
    "batch_size = 8\n",
    "\n",
    "# Create the DataLoader.\n",
    "prediction_data = TensorDataset(input_ids, attention_masks, labels)\n",
    "prediction_sampler = SequentialSampler(prediction_data)\n",
    "prediction_dataloader = DataLoader(prediction_data, sampler=prediction_sampler, batch_size=batch_size)\n",
    "\n",
    "# Prediction on test set\n",
    "\n",
    "print('Predicting labels for {:,} test sentences...'.format(len(input_ids)))\n",
    "\n",
    "# Put model in evaluation mode\n",
    "model.eval()\n",
    "\n",
    "# Tracking variables \n",
    "predictions , true_labels = [], []\n",
    "\n",
    "# Predict \n",
    "for batch in prediction_dataloader:\n",
    "    # Add batch to GPU\n",
    "    batch = tuple(t.to(device) for t in batch)\n",
    "    \n",
    "    # Unpack the inputs from our dataloader\n",
    "    b_input_ids, b_input_mask, b_labels = batch\n",
    "    \n",
    "    # Telling the model not to compute or store gradients, saving memory and \n",
    "    # speeding up prediction\n",
    "    with torch.no_grad():\n",
    "        # Forward pass, calculate logit predictions\n",
    "        outputs = model(b_input_ids, token_type_ids=None, \n",
    "                        attention_mask=b_input_mask)\n",
    "\n",
    "    logits = outputs[0]\n",
    "    \n",
    "\n",
    "    # Move logits and labels to CPU\n",
    "    logits = logits.detach().cpu().numpy()\n",
    "    label_ids = b_labels.to('cpu').numpy()\n",
    "    \n",
    "    # Store predictions and true labels\n",
    "    predictions.append(logits)\n",
    "    true_labels.append(label_ids)\n",
    "\n",
    "print('    DONE.')\n",
    "  \n",
    "# Combine the results across all batches. \n",
    "flat_pred = np.concatenate(predictions, axis=0)\n",
    "# For each sample, pick the label (0 or 1) with the higher score.\n",
    "flat_predictions = np.argmax(flat_pred, axis=1).flatten()\n",
    "\n",
    "# Combine the correct labels for each batch into a single list.\n",
    "flat_true_labels = np.concatenate(true_labels, axis=0)\n",
    "\n",
    "# Return metrics\n",
    "f1 = f1_score(flat_true_labels, flat_predictions)\n",
    "print('Total F1: %.3f' % f1)\n",
    "acc = accuracy_score(flat_true_labels,flat_predictions)\n",
    "print('Accuracy: %.2f' % acc)\n",
    "accuracies.append(acc)\n",
    "\n",
    "# Print Confusion matrix\n",
    "cf_matrix = confusion_matrix(flat_true_labels, flat_predictions)\n",
    "group_names = ['True Neg','False Pos','False Neg','True Pos']\n",
    "group_counts = ['{0:0.0f}'.format(value) for value in\n",
    "                cf_matrix.flatten()]\n",
    "group_percentages = ['{0:.2%}'.format(value) for value in\n",
    "                    cf_matrix.flatten()/np.sum(cf_matrix)]\n",
    "labels = [f'{v1}\\n{v2}\\n{v3}' for v1, v2, v3 in\n",
    "        zip(group_names,group_counts,group_percentages)]\n",
    "matrix = pd.DataFrame(np.array([cf_matrix[0],cf_matrix[1]]), columns = ['Nontoxic','Toxic'], index=['Nontoxic','Toxic'])\n",
    "matrix = matrix.rename_axis(\"True Label\")\n",
    "matrix = matrix.rename_axis(\"Predicted Label\",axis=\"columns\")\n",
    "try:\n",
    "    labels = np.asarray(labels).reshape(2,2)\n",
    "    sns.heatmap(matrix, annot=labels, fmt='',cbar = False, cmap='Blues')\n",
    "    plt.show()\n",
    "except ValueError:\n",
    "    print(\"could not display\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using female toxic test data with offensive words\n",
      "Number of test sentences: 5,630\n",
      "\n",
      "Predicting labels for 5,630 test sentences...\n",
      "    DONE.\n",
      "Total F1: 0.887\n",
      "Accuracy: 0.80\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Evaluating test set\n",
    "\n",
    "# Initialising\n",
    "accuracies = []\n",
    "    \n",
    "print('Using female toxic test data with offensive words')\n",
    "print('Number of test sentences: {:,}\\n'.format(df.shape[0]))\n",
    "\n",
    "# Extract necessary information\n",
    "comments = df.comment.values\n",
    "labels = df.toxicity.values\n",
    "\n",
    "# Tokenize all of the sentences and map the tokens to their word IDs.\n",
    "input_ids = []\n",
    "attention_masks = []\n",
    "\n",
    "# For every sentence...\n",
    "for cmt in comments:\n",
    "    # `encode_plus` will:\n",
    "    #   (1) Tokenize the sentence.\n",
    "    #   (2) Prepend the `[CLS]` token to the start.\n",
    "    #   (3) Append the `[SEP]` token to the end.\n",
    "    #   (4) Map tokens to their IDs.\n",
    "    #   (5) Pad or truncate the sentence to `max_length`\n",
    "    #   (6) Create attention masks for [PAD] tokens.\n",
    "    encoded_dict = tokenizer.encode_plus(\n",
    "                        cmt,                      # Sentence to encode.\n",
    "                        add_special_tokens = True, # Add '[CLS]' and '[SEP]'\n",
    "                        max_length = MAX_LEN,           # Pad & truncate all sentences.\n",
    "                        padding='max_length',\n",
    "                        truncation=True,\n",
    "                        return_attention_mask = True,   # Construct attn. masks.\n",
    "                        return_tensors = 'pt',     # Return pytorch tensors.\n",
    "                )\n",
    "      \n",
    "    # Add the encoded sentence to the list.    \n",
    "    input_ids.append(encoded_dict['input_ids'])\n",
    "      \n",
    "    # And its attention mask (simply differentiates padding from non-padding).\n",
    "    attention_masks.append(encoded_dict['attention_mask'])\n",
    "\n",
    "# Convert the lists into tensors.\n",
    "input_ids = torch.cat(input_ids, dim=0)\n",
    "attention_masks = torch.cat(attention_masks, dim=0)\n",
    "labels = torch.tensor(labels)\n",
    "\n",
    "# Set the batch size.  \n",
    "batch_size = 8\n",
    "\n",
    "# Create the DataLoader.\n",
    "prediction_data = TensorDataset(input_ids, attention_masks, labels)\n",
    "prediction_sampler = SequentialSampler(prediction_data)\n",
    "prediction_dataloader = DataLoader(prediction_data, sampler=prediction_sampler, batch_size=batch_size)\n",
    "\n",
    "# Prediction on test set\n",
    "\n",
    "print('Predicting labels for {:,} test sentences...'.format(len(input_ids)))\n",
    "\n",
    "# Put model in evaluation mode\n",
    "model.eval()\n",
    "\n",
    "# Tracking variables \n",
    "predictions , true_labels = [], []\n",
    "\n",
    "# Predict \n",
    "for batch in prediction_dataloader:\n",
    "    # Add batch to GPU\n",
    "    batch = tuple(t.to(device) for t in batch)\n",
    "    \n",
    "    # Unpack the inputs from our dataloader\n",
    "    b_input_ids, b_input_mask, b_labels = batch\n",
    "    \n",
    "    # Telling the model not to compute or store gradients, saving memory and \n",
    "    # speeding up prediction\n",
    "    with torch.no_grad():\n",
    "        # Forward pass, calculate logit predictions\n",
    "        outputs = model(b_input_ids, token_type_ids=None, \n",
    "                        attention_mask=b_input_mask)\n",
    "\n",
    "    logits = outputs[0]\n",
    "    \n",
    "\n",
    "    # Move logits and labels to CPU\n",
    "    logits = logits.detach().cpu().numpy()\n",
    "    label_ids = b_labels.to('cpu').numpy()\n",
    "    \n",
    "    # Store predictions and true labels\n",
    "    predictions.append(logits)\n",
    "    true_labels.append(label_ids)\n",
    "\n",
    "print('    DONE.')\n",
    "  \n",
    "# Combine the results across all batches. \n",
    "flat_pred = np.concatenate(predictions, axis=0)\n",
    "# For each sample, pick the label (0 or 1) with the higher score.\n",
    "flat_predictions = np.argmax(flat_pred, axis=1).flatten()\n",
    "\n",
    "# Combine the correct labels for each batch into a single list.\n",
    "flat_true_labels = np.concatenate(true_labels, axis=0)\n",
    "\n",
    "# Return metrics\n",
    "f1 = f1_score(flat_true_labels, flat_predictions)\n",
    "print('Total F1: %.3f' % f1)\n",
    "acc = accuracy_score(flat_true_labels,flat_predictions)\n",
    "print('Accuracy: %.2f' % acc)\n",
    "accuracies.append(acc)\n",
    "\n",
    "# Print Confusion matrix\n",
    "cf_matrix = confusion_matrix(flat_true_labels, flat_predictions)\n",
    "group_names = ['True Neg','False Pos','False Neg','True Pos']\n",
    "group_counts = ['{0:0.0f}'.format(value) for value in\n",
    "                cf_matrix.flatten()]\n",
    "group_percentages = ['{0:.2%}'.format(value) for value in\n",
    "                    cf_matrix.flatten()/np.sum(cf_matrix)]\n",
    "labels = [f'{v1}\\n{v2}\\n{v3}' for v1, v2, v3 in\n",
    "        zip(group_names,group_counts,group_percentages)]\n",
    "matrix = pd.DataFrame(np.array([cf_matrix[0],cf_matrix[1]]), columns = ['Nontoxic','Toxic'], index=['Nontoxic','Toxic'])\n",
    "matrix = matrix.rename_axis(\"True Label\")\n",
    "matrix = matrix.rename_axis(\"Predicted Label\",axis=\"columns\")\n",
    "try:\n",
    "    labels = np.asarray(labels).reshape(2,2)\n",
    "    sns.heatmap(matrix, annot=labels, fmt='',cbar = False, cmap='Blues')\n",
    "    plt.show()\n",
    "except ValueError:\n",
    "    print(\"could not display\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating and evaluating female toxic test set\n",
    "\n",
    "# Choose whether to use saved data\n",
    "saved_test_set = True\n",
    "    \n",
    "if saved_test_set:\n",
    "    with open(\"male_notoxic_test.data\", 'rb') as file:\n",
    "        df = pickle.load(file)\n",
    "    file.close()\n",
    "else:\n",
    "    # Create balanced test data (between toxic and very toxic)\n",
    "    male_toxic = toxic[toxic.male_binary == 1]\n",
    "    male_very_toxic = very_toxic[very_toxic.male_binary == 1]\n",
    "    test_size = min(test_size, male_toxic.shape[0],male_very_toxic.shape[0])\n",
    "    male_toxic_test = male_toxic.sample(n=test_size)\n",
    "    male_vtoxic_test = male_very_toxic.sample(n=test_size)\n",
    "    df = pd.concat([male_toxic_test,male_vtoxic_test])\n",
    "    \n",
    "    # Removing punctuation and converting capital letters to lowercase\n",
    "    df['comment'] = df['comment'].str.translate(str.maketrans('', '', string.punctuation))\n",
    "    df['comment'] = df['comment'].str.lower()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using male toxic test data without offensive words\n",
      "Number of test sentences: 8,744\n",
      "\n",
      "Predicting labels for 8,744 test sentences...\n",
      "    DONE.\n",
      "Total F1: 0.898\n",
      "Accuracy: 0.81\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXwAAAEGCAYAAABmXi5tAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjMuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8vihELAAAACXBIWXMAAAsTAAALEwEAmpwYAAApeklEQVR4nO3deZxO5f/H8ddnFsa+LxWhrEXJWiF7SWStiDYkJUvrN0sSSoukpCKtKlEhWkUbqexLtuIXCtlpmH3m+v1x38ZgNsw923k/Hw8P91muc11nHJ+57utc53PMOYeIiOR+QVndABERyRwK+CIiHqGALyLiEQr4IiIeoYAvIuIRIVndgJRExaHpQyIiZygsBEtpm3r4IiIeoYAvIuIRCvgiIh6hgC8i4hEK+CIiHqGALyLiEQr4IiIeoYAvIuIRCvgiIh6hgC8i4hEK+CIiHqGALyLiEQr4IiIeoYAvIuIRCvgiIh6hgC8i4hEK+CIiHqGALyLiEQr4IiIeoYAvIuIRCvgiIh6hgC8i4hEK+CIiHqGALyLiEQr4IiIeoYAvIuIRCvgiIh6hgC8i4hEK+CIiHqGALyLiEQr4IiIeoYAvIuIRCvgiIh6hgC8i4hEK+CIiHqGALyLiEQr4IiIeoYAvIuIRIVndADnZ4cOH6NvrTgD2799PUHAQxYsVB+CDjz4mNE+ec66j9523ERFxjOkzZwGw/vd1jB/3HG++M+2cjy252xW1alClStXE5RcnTuKCC8olu++V9a7g1+Wrzqm+x4c+xvLlSylUsBAWFMTQ4SO4vPYV53RML1PAz2aKFi3GzFmfAfDapInkz5+fO+7qnbg9Li6OkJBz/2c7eOAgixf9SOMmTc/5WOIdefOGJV6fmeXBhx6l9XVtWPLzYkY/OYJPZs/L1PpzEwX8HODxoY9RuEgRNm3cQI1LLqVAgQIn/SLo3KEdE199nQsuKMfn8z7jw/enERcbS83LLmfY408QHBx82jHv6NWbN15/7bSAHx8fz0svjmP50qXExMZwS/ce3HRzNxISEhg7ZhTLly/jgnLlcAkJdOzUhdbXtcmUn4FkTxHHjjFowH38999/xMXFcf/AQTRv0eqkffbt28ujDz3AsaNHiYuPZ/iIkdSpW48lPy/mtUkTiYmJoXz58owaM5b8BQqkWFfdevX5e8cOAN57523mzP4UgM5dutLz9juJiIjg0YcGs+fff4lPSKBvv/toc33bwJ18DqSAn0Ns376NKW++Q3BwMK9NmpjsPv+3dSvffPUV774/ndDQUJ4aNZIvP59H+w4dT9v38str892Cb1n6268USPKfbPann1CwYCE+nPkpMTEx3NGzG1dd3YiN69eza9dOPp0zj4MHDtDxxrZ07NQlQGcr2VV0dBQ3d+4AwPnlyjFu/Eu8+PIkChYsyKFDB7mt+y00a94SM0ss8+UXn3N1o8bcfc+9xMfHExUVyaFDB3lj8mtMnvo2+fPn562pU3jv3bfpd9/9Kdb94w/fUblKVTas/53P5szi/ekzwTl6dL+ZuvUbsPPvvylVqjSvvDYFgPDw8MD+MHIgBfwc4tpr2yTbU0/qt19/YeOG3+lxS1cAoqKjKF6iRIr7333Pvbwx+TUGP/hw4rpflvzMH39sZsH8bwAIPxrOju3bWbVyBa2va0NQUBAlS5WifoOGGXBWktOcOqQTGxvLyxPGs3LFMoIsiL1793Bg/35KliqVuE/NmrV4YvhQ4uLiaN6iFdVr1GD5su/5v61buLNn98TjXFa7drJ1jn/hOd6Y/BrFihdn5OinWPrrL7Ro2Yr8+fMD0LJVa1auWE6jxk14YdyzvPjC8zRt1pw6desF7geRQyng5xD58uVL/BwcHExCQkLickx0NAAOR/sOnRj0wEPpOmbDK6/i1YkvsXbNmsR1zjkeGzqcRo2bnLTvop9+OIfWS2715efzOHToINNnziI0NJTrW7cgOib6pH3q1qvPW++9z6Iff2TYkEe5867eFCpcmCuvasSz48anWcfxMfzjfvtlSbL7VaxYiY9mzmLRoh956cUXuOrqRql+Y/AiTcvMgc6/4AI2btwAwMYN69m58x8AGja8igXzv+HAgQMAHDl8mF27dqZ6rD733Ms7b01NXL66UWM+njGd2NhYALZt+4uIiAiuqFOXBd/OJyEhgQP797N86dJAnJrkMEePhlO8eAlCQ0NZ+tuvyV5vu3btpHjxEnS56WY6de7Cxg3ruezy2qxetZId27cDEBkZybZtf6Wrzrr16vP9dwuIjIwkIiKC7xYuoE7deuzdu4ewfPlo174Dd9zVm03+/yNygnr4OVCr1tcxb+5n3Ny5A5fWrEWFihUBuLhyZfoPHMy9d/ciwSUQEhLK0OEjOP/8C1I8VpNrmlKsePHE5c5db2LXrp10u6kzzjmKFSvGhImv0qr1dfz26y906dCOChUrUuuyyyhYqFCgT1Wyubbt2jOw/710v7kz1arXoNJFF522z/KlS3nn7TcJCQkhf/78jBn7LMWLF2fUU2N57JEHiYmNAeD+AYOpWLFSmnXWuORSbuzQmR7dbgJ8N21r1LiEnxcv4sUXniPIgggJCWHYiJEZeq65gTnnsroNyYqKI3s2zMMijh0jf4ECHD58iB7dbuLdadNPGqsVkawXFoKltE09fEm3Af37Ef7ff8TGxtL3nvsU7EVyGPXwRURykdR6+LppKyLiEQr4udzPi37ixhuuo12b1rz5xpSsbo7ISXR9Zi4F/FwsPj6ep58axauvT2X23C/4+svP2bplS1Y3SwTQ9ZkVAhrwzayAmQUlWQ4ys/yBrFNO+H3dWsqXr0C58uUJzZOHNm1v4IfvF2Z1s0QAXZ9ZIdA9/IVA0gCfH1gQ4DrFb++ePZQ9r2zicukyZdizZ08WtkjkBF2fmS/QAT/MOXf0+IL/c4o9fDPra2bLzWy5xvPOnUtmolPSpFYiWUnXZ+YL9Dz8Y2ZWxzm3EsDM6gKRKe3snJsCTAFNy8wIZcqU5d/d/yYu792zh9KlS2dhi0RO0PWZ+QLdwx8MfGxmi8xsETADUDajTHJpzVrs2LGNf/75m9iYGL7+8guaNm+R1c0SAXR9ZoWA9vCdc8vMrDpQDTBgk3MuNpB1ygkhISEMGTaCe/v2ISEhno6dulC5cpWsbpYIoOszKwTkSVsza+Gc+87MOie33Tk3K61jaEhHROTMZUUunabAd0D7ZLY5IM2ALyIiGUu5dEREcpEsy6VjZtPMrEiS5QpmpicrzkFaj6I753jm6TG0a9Oarp3as3HD+jTLvvjC83Tt1J5hQx5NXDdv7hw+mPZuYE9GchVdm9lfoGfpLAZ+M7O2ZnY38C0wIcB15lrpeRR98aKf2LF9G/O+ms+IkaMZM2pkqmXDw8NZs3oVn8yeR0J8PH/+sZmoqCjmzpnNzd1uzfyTlBxJ12bOENCA75ybDPQBPgNGAdc45+YFss7cLD2Pon//3ULa39gRM+Oyy2sTHv4f+/btTbFsUJARGxuLc46o6GhCQkJ4562p3NrzNkJDQ7PoTCWn0bWZMwR6SOc24C3gduAd4EszuzyQdeZm6XkUfe/ePZQpe2KfMmXKsnfPnhTLFihQkFatr+WWLh254IJyFCxUiPW//07zFq0Cf0KSa+jazBkC/aRtF6Cxc24vMN3MZuML/FcEuN5cKV2PoidzE97MUi17V++7uav33QCMHDGM+wYMZNYnH/PLksVUqVqNvv3uy4DWS26mazNnCPSQTkfgsJnVNLOawCqgYSDrzM3S8yh66TJl2fPviX327PmXUqVLp6vsxo0bAKhQoSLz5s7h+fEvsWXLn2zfvi0AZyO5ia7NnCHQQzpNgT+BScCrwB/AlYGsMzdLz6PozZq3YN7cOTjnWLtmNQULFqJUqdLpKjtp4kvcd/9A4uLiSIiPByDIgoiKjMq0c5ScSddmzhDoIZ3xwLXOuc0AZlYVmA7UDXC9uVJKj6LPnDEdgJtv6U6Ta5qy+KcfaXd9a8LC8jFqzNOplj3uu4ULqFmzFqVLlwHgstpX0KVje6pWrUq16tUz/2QlR9G1mTME9MErM1vrnLssrXXJ0YNXIiJnLitSKxy33MzeBKb5l3sAKwJcp4iIJCPQPfy8QH+gMb5smT8Bk5xzMWmVVQ9fROTMpdbDD3TAH+SceymtdclRwBcROXNZlksHuCOZdXcGuE4REUlGQMbwzaw7cCtQyczmJtlUCDgQiDpFRCR1gbppuwTYDZQEXkiyPhxYG6A6RUQkFcqHLyKSi2RlPvzOZvanmR0xs//MLNzM/gtknSIikrxAz9LZArR3zm0807Lq4YuInLmsnKWz52yCvYiIZLzMeNJ2BjAHiD6+0jmnl5iLiGSyQAf8wkAEcG2SdQ5QwBcRyWSapSMikotk5SydcmY228z2mtkeM/vUzMoFsk4REUleikM6ZlYntYLOuZXpOP7bwIfATf7lnv51rdPbQBERyRgpDumY2feplHPOuRapbD9+jNXOudpprUuOhnRERM7cWeXDd841z4C695tZT3xvuQLojnLpiIhkiTTH8M0sv5kNN7Mp/uUqZtYuncfvBdwM/Isvt05X/zoREclkac7S8c+jXwHc7pyraWb5gF/SMyxzLjSkIyJy5s71FYcXO+du8ac8xjkXaWYpHhDAzEakstk550ano14REclA6Qn4Mf5evQMws4tJ8tRsCo4ls64A0BsoASjgi4hksvQM6bQGhgOXAPOBRsCdzrkf0lWBWSFgEL5gPxN4wTm3N61yGtIRETlz5/xOWzMrAVyJ70Xkvzrn9qejTHHgQaAH8C7wknPuUHobrYAvInLmznUMH6Ap0BjfsE4oMDu1nc3seaAzMAWo5Zw7ms56REQkQNIzpPMqUJkTc+lvAbY65/qnUiYB3zh/HJzUUzd8N20Lp9Uw9fBFRM7cOQ3pmNl6oKbz72hmQcA659ylGdrKUyjgi4icuXNNnrYZuDDJcnn0InIRkRwnteRp8/ANxxQBNprZUv9yQ2BJ5jRPREQySmo3bcdlWitERCTg9AIUEZFc5JzG8M3sSjNbZmZHzSzGzOLN7L+MbaKIiARaem7avoIvrfGfQD6gj3+diIjkIOl68Mo5t8XMgp1z8cDbZqabtiIiOUx6An6EmeUBVpvZc/jy2hcIbLNERCSjpWdI5zb/fvfjy4JZHl/aBBERyUHOapaOmc1wzt0SgPYk0iwdEZEzd65P2ibnqrMsJyIiWeRsA76IiOQwqaVWqJPSJnwpkgNq3d9HAl2FyFm5pvOwrG6CSIoiV6U8az61WTovpLJt01m3RkREskSKAd851zwzGyIiIoGlMXwREY9QwBcR8QgFfBERj0hPtkwzs55mNsK/fKGZNQh800REJCOlp4f/Kr4Hrbr7l8OBSQFrkYiIBER6kqc1dM7VMbNVAM65Q/5kaiIikoOkp4cfa2bB+N5ni5mVAhIC2ioREclw6Qn4LwOzgdJm9hSwGHg6oK0SEZEMl+aQjnPuAzNbAbTEl1aho3NuY8BbJiIiGSrNgG9mFwIRwLyk65xzOwLZMBERyVjpuWn7Bb7xewPCgErAZuDSALZLREQyWHqGdGolXfZn0bwnYC0SEZGAOOMnbZ1zK4H6AWiLiIgEUHrG8B9MshgE1AH2BaxFIiISEOkZwy+U5HMcvjH9TwPTHBERCZRUA77/gauCzrlHMqk9IiISICmO4ZtZiHMuHt8QjoiI5HCp9fCX4gv2q81sLvAxcOz4RufcrAC3TUREMlB6xvCLAweAFpyYj+8ABXwRkRwktYBf2j9D53dOBPrjXEBbJSIiGS61gB8MFOTkQH+cAr6ISA6TWsDf7ZwblWktERGRgErtSdvkevYiIpJDpRbwW2ZaK0REJOBSDPjOuYOZ2RAREQmsM06eJiIiOZMCvoiIRyjgi4h4hAK+iIhHKOCLiHiEAr6IiEco4IuIeIQCvoiIRyjgi4h4hAK+iIhHKOCLiHhEet54JZnktrZXUr7ixYnLD4x4nlJlz092394dm/LmnB/Pqb7J457k91VLGf/2bELz5CH8yGEeH3AHE9777JyOK7lb8SIF+HLyAADKlChMQkIC+w4dBaBJz+eJjYs/5zq+eWMQZUsWJiomlmMR0dwz8gP+3L73nI/rdQr42UiePHl5+tUPMrXOoKAgfpw/l1btumZqvZJzHTxyjCu7PQPAsHvaciwimgnTFiZuDw4OIj4+4ZzruWvYu6zcsINenRvx9AOduGnw5HM+ptcp4GdjUZERjH/yYY6FhxMfH8dNd/Sj7lVNT9rn0IH9vDJ2KJERx0iIj+fOAf+jes0rWLfiVz6dNoXY2FjKnHcBfR8aQVi+/KfVcV3Hbnw9ezrNr+942rbPP57Gbz8tIC42lnqNmtHltr4AzP7gTZZ8/zUlSpWhYOGiVKpSnRu69gzIz0ByhilP9uTQfxFcXq0cqzf9Tfix6JN+ESz/eCidB77Ojt0H6da2Pv27NyU0NIRl67YxaOwMEhJSfone4pVbuL9HMwCeHtyRaxtdgnPw7NSv+WT+SsqWLMy0Z3tRqEAYIcFBDHp6Bj+v2poZp53jKOBnIzEx0Qy9rwcApcqez8BhYxn8+HPkL1CQ8COHeWJwL+pceQ1mJ95N88sP33BZ3Svp0L0XCfHxREdHEX7kMHOmv8Vjz0wiLCwf82a+y1ezPqRTjz6n1VmydFmqXlqbxQu/ok7DJonr1634lT27/mbUy+/gnGP8yIfYtG4lefKGsezn73hq0jTi4+MZfv/tVKpSPfA/HMn2Kl9Ymrb9JpKQ4Bh2T9tk96lWqQxdr61D87vGExeXwIQhN9OtbX0+/Hxpise94ZqarP9zFx1b1uayauVocMtYShYtyOL3H2Hxyi3ccn09vl2ykefe/IagICN/WJ5AnWKOp4CfjZw6pBMXF8fH77zGpnWrsCDj0IF9HDl0gKLFSybuc1HVGkwZP4a4uDjqXd2MChdXZdVvi9i54y9GPdgn8ThVqtdMsd4bu93J+JEPU7tBo8R161b+xroVvzGsv6/nHhUZyb87/yYqMoK6VzUlT94wAK5o2DhDfwaSc81asCrVnjpA8wbVqHPJhSx+/1EA8uUNZd/Bo8nu+/ZTdxAZHcuOXQd48NmPGdizBTO/Xk5CgmPvwXAWrdhC3UsrsHz9diY/0ZPQkGDmfb+GtX/szPBzyy0U8LOxJd99zX9HDjH6lfcICQlh8O0diI2JOWmf6rXq8Pi4yaxe+jOvPf8EN3TtSYGChal5RUPuHzImXfWUPb88FS6qwm8/LUhc55yj/S130PKGzift+9WsD8/9xCRXioiMTvwcFx9PUNCJb6JheUIBMDPen/cbIybOTfN4x8fwj0v6zTapn1dupXWfCbRpfClvjrmDF99bkOo3Bi/TtMxsLCLiKIWLFiMkJIQNa5azf+/u0/bZv2c3hYsWo/n1HWl23Y1s27KZytVr8ueGNfy7628AoqOi2P3P9lTr6tDtLr785MS3i8vqXslP8+cRFRkBwMH9ezly+CBVL63Nyl8XERMTTVRkBKuX/pyBZyy5xfZdB6ldozwAtauXo+IFJQD4fulmOrWqTaliBQEoVjg/F55XLF3HXLxyC12vrUtQkFGyWEEa163M8t+3ceF5xdh7MJy3Zy/h3TlLuKJ6+cCcVC6gHn421qh5G1544kEeH3A7F15UlfPLVzxtnw1rV/DlJ+8THBJC3rB89HtkJIWLFqPvQyOYNHY4cbGxAHS9ox/nlauQYl3lKl5MxcrV2LZlMwC16l7Jzr+3MfKB3gCEheXj3kdHcXG1S6hzZROG3tuDkmXO46KqNchfoGDGn7zkaHMWrqZHuwb8+tFjrFi/PXFK5ab/+5cnJ33OvNfuJ8iM2Lh4HnhmJjt2H0rzmJ99t4aGl1Vi6YwhOAfDJsxhz4FwerRvyAO3tyQ2Lp5jEdH0fnxaoE8vxzLnUh9zyyrL/jqSPRsmREVGEJYvP9FRUYx5pC+9Bg711I3bazoPy+omiKQoctUryY99oR6+nIU3X3qanTv+IjYmhiatbvBUsBfJyRTw5Yz1fyx9N4NFJHtRwM+hpowfzerfFlO4aDGemfxR4vr5n81g/tyPCQ4OpnaDRnTvM5B1K39jxluTiIuLJSQklO59BnBp7foAzHznVRYv+JJjR8PPOVWDCECVCqWZ9myvxOVKF5Rg9GtfsGvvEYb1a0v1SmVoctu4xBk4LRpWZ/TAG8kTGkJMbBxDJ8zhx2V/APDZK/dRtlRhQoKD+XnVVgan8ZCWpE5j+DnUpnUryRuWn8njRiYG/A1rlvPZ9Ld5eNSLhObJw5HDBylStDjbtmymSLHiFCtRir+3beW5YQOZ+MEXAGzZuI4Spc/j4d5dFPDTSWP46RcUZGz95ima3v48+cLykJDgeGV4d4a8ODsx4F9erRx7D4aze98RLrn4POa92p+LrxsOQKECYYQfiwJg+rg+zPp2FR9/syLLzicn0Bh+LlS9Vh32/bvrpHULPv+U9jffQWge35OGRYoWB6Bi5WqJ+5SrcBGxMdHExsQQmicPlWvUyrxGi+c0b1CNv/7Zl+osnDWb/0n8vGHrbvLmCU3s7R8P9iEhQYSGBJNdO6g5RcDm4ZtZfzMrmmS5mJndF6j6BP7duYPN61fzxKC7GPPIPWzdvOG0fZYt/o4KF1dL/KUgEkg3XVeXmV+nv0feqVVt1mz+m5jYuMR1cyf1Z8fCZzgaEc2sBasC0UzPCOSDV3c75w4fX3DOHQLuTq2AmfU1s+Vmtnz29HcC2LTcKSE+nmPh/zFywlt07zOQV54eclKP6J9tW/norVfoNXBIFrZSvCI0JJgbmtZi1rfpC9I1LirLmIEduH/MRyetv7H/JCq1HkrePCE0q18thdKSHoEM+EGW5FloMwsGUu1WOuemOOfqOefqdep+ZwCbljsVK1maeo2aY2ZcXO1SLCiI8COHATiwbw8TRj9Kv4dHUub8clnbUPGE6xpfwupNf7P3YHia+15Quigzxvelz+PT+Ouf/adtj46J4/Mf19G+mYYgz0UgA/43wEwza2lmLYDpwNcBrM/z6l3dlA1rlgOw+5/txMXGUqhIUY4dDeeFEQ9w8139qXrp5VncSvGKm9vUS9dwTpGC+Zg1sR8jJs7llzX/l7i+QL48lC1ZGPDl2G/T6BI2b9sTsPZ6QcBm6ZhZEHAP0BIwYD4w1TmXrtfhaJZO6l4ZO5yNa1dw9L/DFC5Wgi4976Zxy7ZMGT+aHf/3B8Ehodx690AurV2fOR++ybwZ71LmghM5Rv739ESKFC3O9Kkvs+SH+Rw+sI+iJUrR7LobE/PeS/I0Sydt+cJC+fOrMVzS/gn+O+q78Xpj88sY/7+bKFmsIIfDI1m7eSc39p/E//pcxyO9rmXLjn2J5dvf+wpmxqyX+5EnNITg4CB+XPYHj4z7NENerpKbpTZLR9MyRc6QAr5kZ5k6LdPMZjrnbjazdcBpQds5d1lG1ykiImkLxDz8Qf6/2wXg2CIicpYyPOA7544nbS/gnDtpIriZNQNST8wuIiIBEchZOjPN7H/mk8/MJgJjA1hfrjRl/Gjuu+U6HrunW+K67Vv/4InBvRh6Xw8eH3A7WzevT7bs4Ns78Fi/7on7neqLT96nZ5sGiVM3/1i/hiH9buXxAXckvjzl2NFwnh06QE84SrIG9GjOik+Gsfzjobw79k7y5gmhc6srWPHJMI6teJk6l1yYavmgIOOX6f/j05f6nbT+3m5NWTP7cVZ8MoynBnUA4KrLL2LpjCEsfv8RLirve81nkYL5mDupf2BOLhcKZGqFhsCzwBKgEPAB0CjVEnKaa1rfQOv2NzF53MjEddPfnEjnHn24vP7VrF76M9OnTmT4868nW37Ys69RqEjR09Yf2LeH31f+RonSZRPXffnpBwx6/Bn27dnNws8/pUffwcz58E1u7HZXiq+XE+86v1QR7uvelCu6PEVUdCzvP9uLm66ry7Lft9HtoTd4ZXj3NI9x/63N2fzXHgoVCEtcd029KrRrVov6N48lJjYu8e1Yg25rQfdHplLhvBL0vakJj42fzZC+bXjurW8Cdo65TSB7+LFAJJAPCAP+cs5pPtUZql6rDgULFT5pnQGREccAiDh2lGIlSiZTMnXvT36Rbn0GYJwI5MEhIcRERxMTHUVwSAh7dv3DoQP7qHFZnXM6B8m9QoKDyZc3lODgIPKF5WH3viNs/mtP4huuUnNB6aK0aXwpb89ectL6vjc1Ydzb3yamV9h3yPeS89i4ePLlDSV/vlBi4+KpVK4k55cuyuIVWzL+xHKpQPbwlwGfAfWBEsBkM+vqnOsawDo9oWe/B3lu2EA+fOMlnHM8MX5qsvuZwTNDB2BmtGjbiRZtOwGw4pefKFaiFBUuqnrS/jfecidvvjyWPHny0u+RkUyf+jJdb78n4OcjOdOufUeY8N5C/vhqNJHRMSz8ZRMLf92U7vLPP9KFYS/NoWD+sJPWV65QmkZXXMyT/dsTFRPLkPGzWbFhB8+/NZ9Jw7sTGR1L7+HvMfbBTjz56ucZfVq5WiADfm/n3HL/53+BDmZ2WwDr84yFn39Kj3seoEHjFvz607e88eIYhjwz6bT9RoyfSrESpThy+CDPDrmf88tXoFKVS5j70dv87+mJp+1f4eKqPDnhLcCXfrlo8ZI455j49FCCg0Po0XcQRYqVCPj5Sc5QtFA+2jWrRY12T3A4PIIPn+tNt7b1+ejLZWmWvb5JTfYeDGfVxr9pUrfKSdtCgoMoVjg/19w+jnqXVuD953pRo91I1v6xk6Z3vABAozoXs3vfEQxj2jN3ERsXz2PjZ6crjYOXBXJIZ42ZDTSzT/x/7gc+SrOUpGnRgi+o36g5AA2btGLrH6dnxQQoVqIU4EuTXPfqZmzdvIG9u/9h37+7GHpvDwbf3oGD+/cy/P7bOHzwRP4S5xxzpr9Np1t7M/uDqXS5rS+NWl7PN5/NCPzJSY7RomF1tu06wP5DR4mLS2DOd2u48vJK6Sp7Ve2LaNe0Fpu+eJL3nrmLZvWr8tYY38SCnXsOM2fhGgCWr99OQoKjpH8c/7jH+rRh7JSvGHbP9Yx+/Uumf7mM+7o3y9Dzy40C2cN/DQgFXvUv3+b/nGrGTElbsRKl2Lh2JZdcXpf1q5dR9vzyp+0TFRWJS0ggX/4CREVF8vvK3+jYow/lK1Xm1RknbnINvr0Doye+e9KN3UXffkHtBo0oUKgw0dFRmBlBZsRER2XG6UkO8fe/B2lQqxL5wkKJjIqleYNqiS81ScuIiXMZMXEuAE3qVmHw7S3pNfw9AOb9sJZmDaqyaMWfVL6wNHlCQ9jvH8cH6Nm+IV8vWs/h8Ejy+1+qkpDgyB8WmvEnmcsE4knbEOdcHFDfOZc0U9d3ZrYmo+vL7ZLmzBnQsx1det5N70FDmfb6eBLi4wjNk5feg3zpjg8d2MfUCU/xyOgJ/HfoIBNGPQJAfHw8Vze/jsvrXZVmfdFRUSxa8EXikM/1nW/lpTGPERISSv/HRgfuRCXHWfb7dmYvWMUvH/6PuPgE1mz6hzc//fmknDmzXu6XmDPnvFJFeHXErXQa8Fqqx313zi9MHtmD5R8PJSY2nj4jpiVuyxcWSs/2DWl33ysAvPz+d0wf14eY2DjuGPJOIE83V8jwXDpmttI5V8fMVgI3Oee2+tdfBHzinEvXlA/l0pHsSrl0JDvL7FccHq/sYeB7Mzue77QicFcA6hMRkXQIRMAvZWYP+j9PBoKBY/jm4l8BfB+AOkVEJA2BCPjBQEEg6deK47fYCwWgPhERSYdABPzdzrlRATiuiIicg0DMw1fSFRGRbCgQAb9lAI4pIiLnKMMDvnPuYEYfU0REzl0gUyuIiEg2ooAvIuIRCvgiIh6hgC8i4hEK+CIiHqGALyLiEQr4IiIeoYAvIuIRCvgiIh6hgC8i4hEK+CIiHqGALyLiEQr4IiIeoYAvIuIRCvgiIh6hgC8i4hEK+CIiHqGALyLiEQr4IiIeoYAvIuIRCvgiIh6hgC8i4hEK+CIiHqGALyLiEQr4IiIeoYAvIuIRCvgiIh6hgC8i4hEK+CIiHqGALyLiEQr4IiIeYc65rG6DZAIz6+ucm5LV7RA5la7NzKMevnf0zeoGiKRA12YmUcAXEfEIBXwREY9QwPcOjZFKdqVrM5Popq2IiEeohy8i4hEK+CIiHqGAnw2ZmTOzF5IsP2xmI8/yWBXN7NZzaMsoM2t1tuXFe8yshJmt9v/518x2JlnOk47y55vZJ5nRVq/RGH42ZGZRwG6gvnNuv5k9DBR0zo08i2M1Ax52zrXL0EaKpIO/o3LUOTcuq9si6uFnV3H4Zi48cOoGM6tgZgvNbK3/7wv9698xs5fNbImZ/Z+ZdfUXeQZo4u9dPWBmYWb2tpmtM7NVZtbcX/4zM7vd//keM/sgyXG7+j/X9x9/jZktNbNCgf9RSG5gZi3919s6M3vLzPL6r6e1/muygJmtN7Oa/m+lv/vLBZvZOH+5tWY2IKvPJScLyeoGSIomAWvN7LlT1r8CvOece9fMegEvAx39284DGgPVgbnAJ8BjJOnhm9lDAM65WmZWHZhvZlXxPe34s5n9BTwEXJm0Uv9X8RnALc65ZWZWGIjM4HOW3CkMeAdo6Zz7w8zeA+51zk0ws7nAGCAf8L5z7nczq5ikbF+gEnCFcy7OzIpncttzFfXwsynn3H/Ae8DAUzZdBXzo/zwNX4A/bo5zLsE5twEok8KhG/vL4ZzbBGwHqjrn9gAjgO+Bh5xzB08pVw3Y7Zxbdrx9zrm4szo58Zpg4C/n3B/+5XeBa/yfRwGtgXrAqZ0bgFbA68evtWSuSzkDCvjZ2wSgN1AglX2S3oSJTvLZUtg/pfUAtYADwPkplNMNHzkbx1LZVhwoCBTC903gVLruMpACfjbm783MxBf0j1sCdPN/7gEsTuMw4fj+Mx33k78c/qGcC4HNZtYAuB64AnjYzCqdcpxNwPlmVt9ftpCZaUhQ0iMMqGhmlf3LtwE/+j9PAR4HPgCeTabsfKDf8WtNQzrnRgE/+3sBKJlkeSBwl5mtxfcfZ1Aa5dcCcf4brQ8ArwLBZrYO35j8nf793gB6Oed24RvDf8vMEr8NOOdigFuAiWa2BviW5HtkIqeKAu4CPvZfdwnA6/5JAnHOuQ/xTS6ob2YtTik7FdiB737WGuCspxiLpmWKiHiGevgiIh6hgC8i4hEK+CIiHqGALyLiEQr4IiIeoYAv2ZqZxfvzAP1uZh+bWf5zOFbSvEBTzeySVPZtZmZXn0Ud28ysZHrXp3CMO83slYyoVyQpBXzJ7iKdc7WdczWBGKBf0o1mFnw2B3XO9fGnoEhJM+CMA75IdqaALznJIqCyv/f9vZl9CKzzZ1R83syW+TMq3gNgPq+Y2QYz+wIoffxAZvaDmdXzf25jZiv9D6ct9Cfv6gc84P920cTMSpnZp/46lplZI3/ZEmY2358JcjKpp644iZk18GcfXeX/u1qSzeXN7Gsz22xmTyQp09OfqXS1mU0+21944k16NF5yBP+j9dcDX/tXNQBqOuf+MrO+wBHnXH0zy4sv6+d8fGkiquHLEVQG2AC8dcpxS+F7yvga/7GKO+cOmtnrJMnj7v/l8qJzbrH5UlJ/A9QAngAWO+dGmdkN+LI7ptcmf71x5nvJzNNAl6TnB0QAy/y/sI7he9q5kXMu1sxexZcm470zqFM8TAFfsrt8Zrba/3kR8Ca+oZalzrm//OuvBS6zE+8AKAJUwZeRcbpzLh7YZWbfJXP8K4Gfjh8rlWyMrYBLkmSbKGy+9wFcA3T2l/3CzA6dwbkVAd41syr4EoSFJtn2rXPuAICZzcKX5TQOqIvvFwD4UgrvPYP6xOMU8CW7i3TO1U66wh/skmZgNGCAc+6bU/ZrS9qZFtObjTEIuMo5d9I7APxtOdv8JKOB751znfzDSD8k2XbqMZ2/re8654acZX3icRrDl9zgG+BeMwsFXxZQMyuALzNoN/8Y/3lA82TK/gI0PZ4dNEk2xlOzjM4H7j++YGa1/R+TZh+9Hih2Bu0uAuz0f77zlG2tzay4meXD94Kbn4GFQFczK328rWZW4QzqE49TwJfcYCq+8fmV5ns13mR8315nA38C64DXOJGSN5Fzbh++cfdZ/myMM/yb5gGdjt+0xZeltJ7/pvAGTswWehK4xsxW4hta2pFKO9ea2T/+P+PxvfBjrJn9jO8lIUktxveimtXAp8655f5ZRcPxvaVsLb6Mpeel70ckomyZIiKeoR6+iIhHKOCLiHiEAr6IiEco4IuIeIQCvoiIRyjgi4h4hAK+iIhH/D9TWbq/EUlSyQAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Evaluating test set\n",
    "\n",
    "# Initialising\n",
    "accuracies = []\n",
    "\n",
    "df = df.sample(frac=1)\n",
    "print('Using male toxic test data without offensive words')\n",
    "print('Number of test sentences: {:,}\\n'.format(df.shape[0]))\n",
    "\n",
    "# Extract necessary information\n",
    "comments = df.comment.values\n",
    "labels = df.toxicity.values\n",
    "\n",
    "# Removing offensive words from comments\n",
    "new_comments = []\n",
    "for comment in comments:\n",
    "    new_comment = clean_comment(comment)\n",
    "    new_comments.append(new_comment)\n",
    "comments = new_comments\n",
    "\n",
    "# Tokenize all of the sentences and map the tokens to their word IDs.\n",
    "input_ids = []\n",
    "attention_masks = []\n",
    "\n",
    "# For every sentence...\n",
    "for cmt in comments:\n",
    "    # `encode_plus` will:\n",
    "    #   (1) Tokenize the sentence.\n",
    "    #   (2) Prepend the `[CLS]` token to the start.\n",
    "    #   (3) Append the `[SEP]` token to the end.\n",
    "    #   (4) Map tokens to their IDs.\n",
    "    #   (5) Pad or truncate the sentence to `max_length`\n",
    "    #   (6) Create attention masks for [PAD] tokens.\n",
    "    encoded_dict = tokenizer.encode_plus(\n",
    "                        cmt,                      # Sentence to encode.\n",
    "                        add_special_tokens = True, # Add '[CLS]' and '[SEP]'\n",
    "                        max_length = MAX_LEN,           # Pad & truncate all sentences.\n",
    "                        padding='max_length',\n",
    "                        truncation=True,\n",
    "                        return_attention_mask = True,   # Construct attn. masks.\n",
    "                        return_tensors = 'pt',     # Return pytorch tensors.\n",
    "                )\n",
    "      \n",
    "    # Add the encoded sentence to the list.    \n",
    "    input_ids.append(encoded_dict['input_ids'])\n",
    "      \n",
    "    # And its attention mask (simply differentiates padding from non-padding).\n",
    "    attention_masks.append(encoded_dict['attention_mask'])\n",
    "\n",
    "# Convert the lists into tensors.\n",
    "input_ids = torch.cat(input_ids, dim=0)\n",
    "attention_masks = torch.cat(attention_masks, dim=0)\n",
    "labels = torch.tensor(labels)\n",
    "\n",
    "# Set the batch size.  \n",
    "batch_size = 8\n",
    "\n",
    "# Create the DataLoader.\n",
    "prediction_data = TensorDataset(input_ids, attention_masks, labels)\n",
    "prediction_sampler = SequentialSampler(prediction_data)\n",
    "prediction_dataloader = DataLoader(prediction_data, sampler=prediction_sampler, batch_size=batch_size)\n",
    "\n",
    "# Prediction on test set\n",
    "\n",
    "print('Predicting labels for {:,} test sentences...'.format(len(input_ids)))\n",
    "\n",
    "# Put model in evaluation mode\n",
    "model.eval()\n",
    "\n",
    "# Tracking variables \n",
    "predictions , true_labels = [], []\n",
    "\n",
    "# Predict \n",
    "for batch in prediction_dataloader:\n",
    "    # Add batch to GPU\n",
    "    batch = tuple(t.to(device) for t in batch)\n",
    "    \n",
    "    # Unpack the inputs from our dataloader\n",
    "    b_input_ids, b_input_mask, b_labels = batch\n",
    "    \n",
    "    # Telling the model not to compute or store gradients, saving memory and \n",
    "    # speeding up prediction\n",
    "    with torch.no_grad():\n",
    "        # Forward pass, calculate logit predictions\n",
    "        outputs = model(b_input_ids, token_type_ids=None, \n",
    "                        attention_mask=b_input_mask)\n",
    "\n",
    "    logits = outputs[0]\n",
    "    \n",
    "\n",
    "    # Move logits and labels to CPU\n",
    "    logits = logits.detach().cpu().numpy()\n",
    "    label_ids = b_labels.to('cpu').numpy()\n",
    "    \n",
    "    # Store predictions and true labels\n",
    "    predictions.append(logits)\n",
    "    true_labels.append(label_ids)\n",
    "\n",
    "print('    DONE.')\n",
    "  \n",
    "# Combine the results across all batches. \n",
    "flat_pred = np.concatenate(predictions, axis=0)\n",
    "# For each sample, pick the label (0 or 1) with the higher score.\n",
    "flat_predictions = np.argmax(flat_pred, axis=1).flatten()\n",
    "\n",
    "# Combine the correct labels for each batch into a single list.\n",
    "flat_true_labels = np.concatenate(true_labels, axis=0)\n",
    "\n",
    "# Return metrics\n",
    "f1 = f1_score(flat_true_labels, flat_predictions)\n",
    "print('Total F1: %.3f' % f1)\n",
    "acc = accuracy_score(flat_true_labels,flat_predictions)\n",
    "print('Accuracy: %.2f' % acc)\n",
    "accuracies.append(acc)\n",
    "\n",
    "# Print Confusion matrix\n",
    "cf_matrix = confusion_matrix(flat_true_labels, flat_predictions)\n",
    "group_names = ['True Neg','False Pos','False Neg','True Pos']\n",
    "group_counts = ['{0:0.0f}'.format(value) for value in\n",
    "                cf_matrix.flatten()]\n",
    "group_percentages = ['{0:.2%}'.format(value) for value in\n",
    "                    cf_matrix.flatten()/np.sum(cf_matrix)]\n",
    "labels = [f'{v1}\\n{v2}\\n{v3}' for v1, v2, v3 in\n",
    "        zip(group_names,group_counts,group_percentages)]\n",
    "matrix = pd.DataFrame(np.array([cf_matrix[0],cf_matrix[1]]), columns = ['Nontoxic','Toxic'], index=['Nontoxic','Toxic'])\n",
    "matrix = matrix.rename_axis(\"True Label\")\n",
    "matrix = matrix.rename_axis(\"Predicted Label\",axis=\"columns\")\n",
    "try:\n",
    "    labels = np.asarray(labels).reshape(2,2)\n",
    "    sns.heatmap(matrix, annot=labels, fmt='',cbar = False, cmap='Blues')\n",
    "    plt.show()\n",
    "except ValueError:\n",
    "    print(\"could not display\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using male toxic test data with offensive words\n",
      "Number of test sentences: 8,744\n",
      "\n",
      "Predicting labels for 8,744 test sentences...\n",
      "    DONE.\n",
      "Total F1: 0.917\n",
      "Accuracy: 0.85\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Evaluating test set\n",
    "\n",
    "# Initialising\n",
    "accuracies = []\n",
    "\n",
    "print('Using male toxic test data with offensive words')\n",
    "print('Number of test sentences: {:,}\\n'.format(df.shape[0]))\n",
    "\n",
    "# Extract necessary information\n",
    "comments = df.comment.values\n",
    "labels = df.toxicity.values\n",
    "\n",
    "# Tokenize all of the sentences and map the tokens to their word IDs.\n",
    "input_ids = []\n",
    "attention_masks = []\n",
    "\n",
    "# For every sentence...\n",
    "for cmt in comments:\n",
    "    # `encode_plus` will:\n",
    "    #   (1) Tokenize the sentence.\n",
    "    #   (2) Prepend the `[CLS]` token to the start.\n",
    "    #   (3) Append the `[SEP]` token to the end.\n",
    "    #   (4) Map tokens to their IDs.\n",
    "    #   (5) Pad or truncate the sentence to `max_length`\n",
    "    #   (6) Create attention masks for [PAD] tokens.\n",
    "    encoded_dict = tokenizer.encode_plus(\n",
    "                        cmt,                      # Sentence to encode.\n",
    "                        add_special_tokens = True, # Add '[CLS]' and '[SEP]'\n",
    "                        max_length = MAX_LEN,           # Pad & truncate all sentences.\n",
    "                        padding='max_length',\n",
    "                        truncation=True,\n",
    "                        return_attention_mask = True,   # Construct attn. masks.\n",
    "                        return_tensors = 'pt',     # Return pytorch tensors.\n",
    "                )\n",
    "      \n",
    "    # Add the encoded sentence to the list.    \n",
    "    input_ids.append(encoded_dict['input_ids'])\n",
    "      \n",
    "    # And its attention mask (simply differentiates padding from non-padding).\n",
    "    attention_masks.append(encoded_dict['attention_mask'])\n",
    "\n",
    "# Convert the lists into tensors.\n",
    "input_ids = torch.cat(input_ids, dim=0)\n",
    "attention_masks = torch.cat(attention_masks, dim=0)\n",
    "labels = torch.tensor(labels)\n",
    "\n",
    "# Set the batch size.  \n",
    "batch_size = 8\n",
    "\n",
    "# Create the DataLoader.\n",
    "prediction_data = TensorDataset(input_ids, attention_masks, labels)\n",
    "prediction_sampler = SequentialSampler(prediction_data)\n",
    "prediction_dataloader = DataLoader(prediction_data, sampler=prediction_sampler, batch_size=batch_size)\n",
    "\n",
    "# Prediction on test set\n",
    "\n",
    "print('Predicting labels for {:,} test sentences...'.format(len(input_ids)))\n",
    "\n",
    "# Put model in evaluation mode\n",
    "model.eval()\n",
    "\n",
    "# Tracking variables \n",
    "predictions , true_labels = [], []\n",
    "\n",
    "# Predict \n",
    "for batch in prediction_dataloader:\n",
    "    # Add batch to GPU\n",
    "    batch = tuple(t.to(device) for t in batch)\n",
    "    \n",
    "    # Unpack the inputs from our dataloader\n",
    "    b_input_ids, b_input_mask, b_labels = batch\n",
    "    \n",
    "    # Telling the model not to compute or store gradients, saving memory and \n",
    "    # speeding up prediction\n",
    "    with torch.no_grad():\n",
    "        # Forward pass, calculate logit predictions\n",
    "        outputs = model(b_input_ids, token_type_ids=None, \n",
    "                        attention_mask=b_input_mask)\n",
    "\n",
    "    logits = outputs[0]\n",
    "    \n",
    "\n",
    "    # Move logits and labels to CPU\n",
    "    logits = logits.detach().cpu().numpy()\n",
    "    label_ids = b_labels.to('cpu').numpy()\n",
    "    \n",
    "    # Store predictions and true labels\n",
    "    predictions.append(logits)\n",
    "    true_labels.append(label_ids)\n",
    "\n",
    "print('    DONE.')\n",
    "  \n",
    "# Combine the results across all batches. \n",
    "flat_pred = np.concatenate(predictions, axis=0)\n",
    "# For each sample, pick the label (0 or 1) with the higher score.\n",
    "flat_predictions = np.argmax(flat_pred, axis=1).flatten()\n",
    "\n",
    "# Combine the correct labels for each batch into a single list.\n",
    "flat_true_labels = np.concatenate(true_labels, axis=0)\n",
    "\n",
    "# Return metrics\n",
    "f1 = f1_score(flat_true_labels, flat_predictions)\n",
    "print('Total F1: %.3f' % f1)\n",
    "acc = accuracy_score(flat_true_labels,flat_predictions)\n",
    "print('Accuracy: %.2f' % acc)\n",
    "accuracies.append(acc)\n",
    "\n",
    "# Print Confusion matrix\n",
    "cf_matrix = confusion_matrix(flat_true_labels, flat_predictions)\n",
    "group_names = ['True Neg','False Pos','False Neg','True Pos']\n",
    "group_counts = ['{0:0.0f}'.format(value) for value in\n",
    "                cf_matrix.flatten()]\n",
    "group_percentages = ['{0:.2%}'.format(value) for value in\n",
    "                    cf_matrix.flatten()/np.sum(cf_matrix)]\n",
    "labels = [f'{v1}\\n{v2}\\n{v3}' for v1, v2, v3 in\n",
    "        zip(group_names,group_counts,group_percentages)]\n",
    "matrix = pd.DataFrame(np.array([cf_matrix[0],cf_matrix[1]]), columns = ['Nontoxic','Toxic'], index=['Nontoxic','Toxic'])\n",
    "matrix = matrix.rename_axis(\"True Label\")\n",
    "matrix = matrix.rename_axis(\"Predicted Label\",axis=\"columns\")\n",
    "try:\n",
    "    labels = np.asarray(labels).reshape(2,2)\n",
    "    sns.heatmap(matrix, annot=labels, fmt='',cbar = False, cmap='Blues')\n",
    "    plt.show()\n",
    "except ValueError:\n",
    "    print(\"could not display\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "Toxic_BERT.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "050fad76094442ccabc0a9dd1841b1e7": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "13892e698d894bb7b7555e3c725f7bff": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "2d24a0780c6e46e3b5d2c348c788d383": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": "initial"
     }
    },
    "2f72600eb7d241d38861be5e6cac560d": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "312fbca9a0d34423bf15e7bb52755bf1": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "Downloading: 100%",
      "description_tooltip": null,
      "layout": "IPY_MODEL_3cef259bc6c348139134a71ad635082f",
      "max": 440473133,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_ce6d4c02eb45429cb45832f86228b98e",
      "value": 440473133
     }
    },
    "3a643aebf84147d2baec20687a8d467e": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "3cef259bc6c348139134a71ad635082f": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "4d6dfec252104ceeb314babbf507bf6c": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "4ef1d475bfb44fb5b4e8f77843e9c13d": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "Downloading: 100%",
      "description_tooltip": null,
      "layout": "IPY_MODEL_7245dba34af84f019e9aa7b4167655c2",
      "max": 231508,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_a679570eb7834b98b460e7235fab57be",
      "value": 231508
     }
    },
    "5523466dab5342c1976c15d4495362a0": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "6c549a6980514e7fbc05d2f3bded708a": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "7035649df34f421b936faded0d3ee5b6": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "7245dba34af84f019e9aa7b4167655c2": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "73f18bedea76480fb9981b5d526cbc2d": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_e5186ba30dbd4973a6983d88ba06ee17",
       "IPY_MODEL_7b11996e92974efaaa6db91f5ac2e59f"
      ],
      "layout": "IPY_MODEL_5523466dab5342c1976c15d4495362a0"
     }
    },
    "7b11996e92974efaaa6db91f5ac2e59f": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_7035649df34f421b936faded0d3ee5b6",
      "placeholder": "",
      "style": "IPY_MODEL_13892e698d894bb7b7555e3c725f7bff",
      "value": " 433/433 [00:20&lt;00:00, 21.6B/s]"
     }
    },
    "82a19fe3427542d38429d1b8ccaa931d": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_6c549a6980514e7fbc05d2f3bded708a",
      "placeholder": "",
      "style": "IPY_MODEL_4d6dfec252104ceeb314babbf507bf6c",
      "value": " 440M/440M [00:05&lt;00:00, 74.0MB/s]"
     }
    },
    "9a413a00269e406f910a554babc8ddac": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_4ef1d475bfb44fb5b4e8f77843e9c13d",
       "IPY_MODEL_c27bc61cdcfe419eab175f61768cb692"
      ],
      "layout": "IPY_MODEL_050fad76094442ccabc0a9dd1841b1e7"
     }
    },
    "a679570eb7834b98b460e7235fab57be": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": "initial"
     }
    },
    "b0aa11e7b5f44d7a9c094b3860f1fe1f": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "c27bc61cdcfe419eab175f61768cb692": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_b0aa11e7b5f44d7a9c094b3860f1fe1f",
      "placeholder": "",
      "style": "IPY_MODEL_2f72600eb7d241d38861be5e6cac560d",
      "value": " 232k/232k [00:00&lt;00:00, 627kB/s]"
     }
    },
    "ce6d4c02eb45429cb45832f86228b98e": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": "initial"
     }
    },
    "cf76c66b89b749e4a79a179e56bd8b78": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "e5186ba30dbd4973a6983d88ba06ee17": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "Downloading: 100%",
      "description_tooltip": null,
      "layout": "IPY_MODEL_cf76c66b89b749e4a79a179e56bd8b78",
      "max": 433,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_2d24a0780c6e46e3b5d2c348c788d383",
      "value": 433
     }
    },
    "ef0f5c28845d44b6ada41f72ec2dd982": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_312fbca9a0d34423bf15e7bb52755bf1",
       "IPY_MODEL_82a19fe3427542d38429d1b8ccaa931d"
      ],
      "layout": "IPY_MODEL_3a643aebf84147d2baec20687a8d467e"
     }
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
