{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "eLrzqIEIZaq0"
   },
   "source": [
    "<h3> Original BERT classifier v1, not very balanced, trained and tested on toxic/non-toxic examples </h3>\n",
    "<p>Using code from: https://mccormickml.com/2019/07/22/BERT-fine-tuning/</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "foOutumNZaq1",
    "outputId": "e1313076-1c3e-42a8-bfb3-8762b3a9081e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
     ]
    }
   ],
   "source": [
    "# import libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "#!conda install -y tensorflow\n",
    "#!conda install -y pytorch torchvision -c pytorch\n",
    "#!pip install transformers\n",
    "import tensorflow as tf\n",
    "import torch\n",
    "\n",
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 279
    },
    "id": "FyJyM0PAcJf0",
    "outputId": "9f5ec30f-8219-446c-87f9-24d6efa4dd63"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>rev_id</th>\n",
       "      <th>comment</th>\n",
       "      <th>year</th>\n",
       "      <th>logged_in</th>\n",
       "      <th>ns</th>\n",
       "      <th>sample</th>\n",
       "      <th>split</th>\n",
       "      <th>worker_id</th>\n",
       "      <th>toxicity</th>\n",
       "      <th>toxicity_score</th>\n",
       "      <th>gender</th>\n",
       "      <th>english_first_language</th>\n",
       "      <th>age_group</th>\n",
       "      <th>education</th>\n",
       "      <th>female_binary</th>\n",
       "      <th>male_binary</th>\n",
       "      <th>other_binary</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3467</th>\n",
       "      <td>2232.0</td>\n",
       "      <td>This: :One can make an analogy in mathematical...</td>\n",
       "      <td>2002</td>\n",
       "      <td>True</td>\n",
       "      <td>article</td>\n",
       "      <td>random</td>\n",
       "      <td>train</td>\n",
       "      <td>405</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>male</td>\n",
       "      <td>0.0</td>\n",
       "      <td>30-45</td>\n",
       "      <td>masters</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3039</th>\n",
       "      <td>2232.0</td>\n",
       "      <td>This: :One can make an analogy in mathematical...</td>\n",
       "      <td>2002</td>\n",
       "      <td>True</td>\n",
       "      <td>article</td>\n",
       "      <td>random</td>\n",
       "      <td>train</td>\n",
       "      <td>680</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>male</td>\n",
       "      <td>0.0</td>\n",
       "      <td>18-30</td>\n",
       "      <td>masters</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2232.0</td>\n",
       "      <td>This: :One can make an analogy in mathematical...</td>\n",
       "      <td>2002</td>\n",
       "      <td>True</td>\n",
       "      <td>article</td>\n",
       "      <td>random</td>\n",
       "      <td>train</td>\n",
       "      <td>723</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>female</td>\n",
       "      <td>0.0</td>\n",
       "      <td>30-45</td>\n",
       "      <td>bachelors</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2600</th>\n",
       "      <td>2232.0</td>\n",
       "      <td>This: :One can make an analogy in mathematical...</td>\n",
       "      <td>2002</td>\n",
       "      <td>True</td>\n",
       "      <td>article</td>\n",
       "      <td>random</td>\n",
       "      <td>train</td>\n",
       "      <td>772</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>male</td>\n",
       "      <td>0.0</td>\n",
       "      <td>18-30</td>\n",
       "      <td>bachelors</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2169</th>\n",
       "      <td>2232.0</td>\n",
       "      <td>This: :One can make an analogy in mathematical...</td>\n",
       "      <td>2002</td>\n",
       "      <td>True</td>\n",
       "      <td>article</td>\n",
       "      <td>random</td>\n",
       "      <td>train</td>\n",
       "      <td>1508</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>female</td>\n",
       "      <td>1.0</td>\n",
       "      <td>45-60</td>\n",
       "      <td>hs</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      rev_id  ... other_binary\n",
       "3467  2232.0  ...            0\n",
       "3039  2232.0  ...            0\n",
       "0     2232.0  ...            0\n",
       "2600  2232.0  ...            0\n",
       "2169  2232.0  ...            0\n",
       "\n",
       "[5 rows x 17 columns]"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# read files and create dataframe\n",
    "toxicity_comments = pd.read_csv('/content/drive/MyDrive/Colab Notebooks/toxicity_annotated_comments.tsv', sep = '\\t', index_col = 0)\n",
    "toxicity_annotations = pd.read_csv('/content/drive/MyDrive/Colab Notebooks/toxicity_annotations.tsv',  sep = '\\t')\n",
    "toxicity_demographics = pd.read_csv('/content/drive/MyDrive/Colab Notebooks/toxicity_worker_demographics.tsv', sep = '\\t')\n",
    "\n",
    "toxicity = toxicity_comments.merge(toxicity_annotations, how ='outer', on=\"rev_id\")\n",
    "toxicity = toxicity.merge(toxicity_demographics, how ='outer', on=\"worker_id\").sort_values(by=['rev_id','worker_id'])\n",
    "\n",
    "# remove newline and tab tokens\n",
    "toxicity['comment'] = toxicity['comment'].apply(lambda x: x.replace(\"NEWLINE_TOKEN\", \" \"))\n",
    "toxicity['comment'] = toxicity['comment'].apply(lambda x: x.replace(\"TAB_TOKEN\", \" \"))\n",
    "\n",
    "# add binary gender columns\n",
    "toxicity = pd.concat([toxicity, pd.get_dummies(toxicity.gender).rename(columns = \"{}_binary\".format)], axis = 1)\n",
    "\n",
    "# limit size of dataset for testing purposes\n",
    "toxic = toxicity[toxicity.toxicity == 1]\n",
    "nontoxic = toxicity[toxicity.toxicity == 0]\n",
    "female_set = toxicity[toxicity.female_binary == 1]\n",
    "other = toxicity[toxicity.female_binary == 0]\n",
    "female_toxic = toxic[toxic.female_binary == 1]\n",
    "other_toxic = toxic[toxic.female_binary == 0]\n",
    "female_nontoxic = nontoxic[nontoxic.female_binary == 1]\n",
    "other_nontoxic = nontoxic[nontoxic.female_binary == 0]\n",
    "#small_toxicity = pd.concat([toxic[:2500], nontoxic[:2500]])\n",
    "#small_toxicity = pd.concat([female_set.sample(2500), other.sample(2500)])\n",
    "small_toxicity = pd.concat([female_toxic.sample(3000), other_toxic.sample(3000), female_nontoxic.sample(3000),other_nontoxic.sample(3000)])\n",
    "small_toxicity = small_toxicity.sample(frac=1)\n",
    "\n",
    "display (toxicity.head(5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "uMItNCQcZaq3",
    "outputId": "11180faf-df27-431c-c7aa-ec0b56ff1028"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 1 GPU(s) available.\n",
      "We will use the GPU: Tesla P100-PCIE-16GB\n"
     ]
    }
   ],
   "source": [
    "# try to use gpu\n",
    "if torch.cuda.is_available():      \n",
    "    device = torch.device(\"cuda\")\n",
    "    print('There are %d GPU(s) available.' % torch.cuda.device_count())\n",
    "    print('We will use the GPU:', torch.cuda.get_device_name(0))\n",
    "\n",
    "else:\n",
    "    print('No GPU available, using the CPU instead.')\n",
    "    device = torch.device(\"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "cbHVLmF0Zaq4"
   },
   "outputs": [],
   "source": [
    "# extract relevant information\n",
    "comments = small_toxicity.comment.values\n",
    "#toxicity = small_toxicity.toxicity.values\n",
    "scores = small_toxicity.toxicity_score.values\n",
    "labels = small_toxicity.female_binary.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Wy8-0FX4Zaq4",
    "outputId": "7616e131-5fee-40fa-b7d9-54124d7861ec"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: transformers in /usr/local/lib/python3.6/dist-packages (3.5.1)\n",
      "Requirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from transformers) (2.23.0)\n",
      "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from transformers) (1.18.5)\n",
      "Requirement already satisfied: sentencepiece==0.1.91 in /usr/local/lib/python3.6/dist-packages (from transformers) (0.1.91)\n",
      "Requirement already satisfied: protobuf in /usr/local/lib/python3.6/dist-packages (from transformers) (3.12.4)\n",
      "Requirement already satisfied: packaging in /usr/local/lib/python3.6/dist-packages (from transformers) (20.4)\n",
      "Requirement already satisfied: sacremoses in /usr/local/lib/python3.6/dist-packages (from transformers) (0.0.43)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.6/dist-packages (from transformers) (2019.12.20)\n",
      "Requirement already satisfied: dataclasses; python_version < \"3.7\" in /usr/local/lib/python3.6/dist-packages (from transformers) (0.8)\n",
      "Requirement already satisfied: filelock in /usr/local/lib/python3.6/dist-packages (from transformers) (3.0.12)\n",
      "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.6/dist-packages (from transformers) (4.41.1)\n",
      "Requirement already satisfied: tokenizers==0.9.3 in /usr/local/lib/python3.6/dist-packages (from transformers) (0.9.3)\n",
      "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (1.24.3)\n",
      "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (3.0.4)\n",
      "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (2.10)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (2020.11.8)\n",
      "Requirement already satisfied: six>=1.9 in /usr/local/lib/python3.6/dist-packages (from protobuf->transformers) (1.15.0)\n",
      "Requirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from protobuf->transformers) (50.3.2)\n",
      "Requirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.6/dist-packages (from packaging->transformers) (2.4.7)\n",
      "Requirement already satisfied: joblib in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (0.17.0)\n",
      "Requirement already satisfied: click in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (7.1.2)\n",
      "Loading BERT tokenizer...\n"
     ]
    }
   ],
   "source": [
    "! pip install transformers\n",
    "from transformers import BertTokenizer\n",
    "\n",
    "# Load the BERT tokenizer.\n",
    "print('Loading BERT tokenizer...')\n",
    "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased', do_lower_case=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "xt9loGrHZaq4",
    "outputId": "ec89065a-8214-479d-e81a-48d2983de3bd"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "/usr/local/lib/python3.6/dist-packages/transformers/tokenization_utils_base.py:2022: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
      "  FutureWarning,\n"
     ]
    }
   ],
   "source": [
    "# Tokenize all of the sentences and map the tokens to their word IDs.\n",
    "input_ids = []\n",
    "attention_masks = []\n",
    "\n",
    "# For every sentence...\n",
    "for i in range(len(comments)):\n",
    "    # `encode_plus` will:\n",
    "    #   (1) Tokenize the sentence.\n",
    "    #   (2) Prepend the `[CLS]` token to the start.\n",
    "    #   (3) Append the `[SEP]` token to the end.\n",
    "    #   (4) Map tokens to their IDs.\n",
    "    #   (5) Pad or truncate the sentence to `max_length`\n",
    "    #   (6) Create attention masks for [PAD] tokens.\n",
    "    cmt = str(scores[i])+\" \"+comments[i]\n",
    "    encoded_dict = tokenizer.encode_plus(\n",
    "                        cmt,                      # Sentence to encode.\n",
    "                        add_special_tokens = True, # Add '[CLS]' and '[SEP]'\n",
    "                        max_length = 250,           # Pad & truncate all sentences.\n",
    "                        pad_to_max_length = True,\n",
    "                        return_attention_mask = True,   # Construct attn. masks.\n",
    "                        return_tensors = 'pt',     # Return pytorch tensors.\n",
    "                   )\n",
    "    \n",
    "    # Add the encoded sentence to the list.    \n",
    "    input_ids.append(encoded_dict['input_ids'])\n",
    "    \n",
    "    # And its attention mask (simply differentiates padding from non-padding).\n",
    "    attention_masks.append(encoded_dict['attention_mask'])\n",
    "\n",
    "# Convert the lists into tensors.\n",
    "input_ids = torch.cat(input_ids, dim=0)\n",
    "attention_masks = torch.cat(attention_masks, dim=0)\n",
    "labels = torch.tensor(labels)\n",
    "\n",
    "# # Print sentence 0, now as a list of IDs.\n",
    "# print('Original: ', comments[0],scores[0])\n",
    "# print('Token IDs:', input_ids[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "z-2y3_EaZaq4",
    "outputId": "b735b376-478d-4fb5-c5e4-9bf46c0da065"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10,800 training samples\n",
      "1,200 validation samples\n"
     ]
    }
   ],
   "source": [
    "from torch.utils.data import TensorDataset, random_split\n",
    "\n",
    "# Combine the training inputs into a TensorDataset.\n",
    "dataset = TensorDataset(input_ids, attention_masks, labels)\n",
    "\n",
    "# Create a 90-10 train-validation split.\n",
    "\n",
    "# Calculate the number of samples to include in each set.\n",
    "train_size = int(0.9 * len(dataset))\n",
    "val_size = len(dataset) - train_size\n",
    "\n",
    "# Divide the dataset by randomly selecting samples.\n",
    "train_dataset, val_dataset = random_split(dataset, [train_size, val_size])\n",
    "\n",
    "print('{:>5,} training samples'.format(train_size))\n",
    "print('{:>5,} validation samples'.format(val_size))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "WyZCsEY6Zaq4"
   },
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader, RandomSampler, SequentialSampler\n",
    "\n",
    "# The DataLoader needs to know our batch size for training, so we specify it \n",
    "# here. For fine-tuning BERT on a specific task, the authors recommend a batch \n",
    "# size of 16 or 32.\n",
    "batch_size = 16\n",
    "\n",
    "# Create the DataLoaders for our training and validation sets.\n",
    "# We'll take training samples in random order. \n",
    "train_dataloader = DataLoader(\n",
    "            train_dataset,  # The training samples.\n",
    "            sampler = RandomSampler(train_dataset), # Select batches randomly\n",
    "            batch_size = batch_size # Trains with this batch size.\n",
    "        )\n",
    "\n",
    "# For validation the order doesn't matter, so we'll just read them sequentially.\n",
    "validation_dataloader = DataLoader(\n",
    "            val_dataset, # The validation samples.\n",
    "            sampler = SequentialSampler(val_dataset), # Pull out batches sequentially.\n",
    "            batch_size = batch_size # Evaluate with this batch size\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "zo5q4EOYZaq4",
    "outputId": "0c123fe7-6a7a-4c8d-dbd3-a580a0a0f6c4"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForSequenceClassification: ['cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias']\n",
      "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "BertForSequenceClassification(\n",
       "  (bert): BertModel(\n",
       "    (embeddings): BertEmbeddings(\n",
       "      (word_embeddings): Embedding(30522, 768, padding_idx=0)\n",
       "      (position_embeddings): Embedding(512, 768)\n",
       "      (token_type_embeddings): Embedding(2, 768)\n",
       "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (encoder): BertEncoder(\n",
       "      (layer): ModuleList(\n",
       "        (0): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (1): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (2): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (3): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (4): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (5): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (6): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (7): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (8): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (9): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (10): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (11): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (pooler): BertPooler(\n",
       "      (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "      (activation): Tanh()\n",
       "    )\n",
       "  )\n",
       "  (dropout): Dropout(p=0.1, inplace=False)\n",
       "  (classifier): Linear(in_features=768, out_features=2, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 9,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from transformers import BertForSequenceClassification, AdamW, BertConfig\n",
    "\n",
    "# Load BertForSequenceClassification, the pretrained BERT model with a single \n",
    "# linear classification layer on top. \n",
    "model = BertForSequenceClassification.from_pretrained(\n",
    "    \"bert-base-uncased\", # Use the 12-layer BERT model, with an uncased vocab.\n",
    "    num_labels = 2, # The number of output labels--2 for binary classification.\n",
    "                    # You can increase this for multi-class tasks.   \n",
    "    output_attentions = False, # Whether the model returns attentions weights.\n",
    "    output_hidden_states = False, # Whether the model returns all hidden-states.\n",
    ")\n",
    "\n",
    "# # Tell pytorch to run this model on the GPU.\n",
    "model.cuda()\n",
    "#model.cpu()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "DcRnw83qZaq4"
   },
   "outputs": [],
   "source": [
    "# Note: AdamW is a class from the huggingface library (as opposed to pytorch) \n",
    "# I believe the 'W' stands for 'Weight Decay fix\"\n",
    "optimizer = AdamW(model.parameters(),\n",
    "                  lr = 2e-5, # args.learning_rate - default is 5e-5, our notebook had 2e-5\n",
    "                  eps = 1e-8 # args.adam_epsilon  - default is 1e-8.\n",
    "                )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "qdGUUYF6Zaq4"
   },
   "outputs": [],
   "source": [
    "from transformers import get_linear_schedule_with_warmup\n",
    "\n",
    "# Number of training epochs. The BERT authors recommend between 2 and 4. \n",
    "# We chose to run for 4, but we'll see later that this may be over-fitting the\n",
    "# training data.\n",
    "epochs = 3\n",
    "\n",
    "# Total number of training steps is [number of batches] x [number of epochs]. \n",
    "# (Note that this is not the same as the number of training samples).\n",
    "total_steps = len(train_dataloader) * epochs\n",
    "\n",
    "# Create the learning rate scheduler.\n",
    "scheduler = get_linear_schedule_with_warmup(optimizer, \n",
    "                                            num_warmup_steps = 0, # Default value in run_glue.py\n",
    "                                            num_training_steps = total_steps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "NYV8P1STZaq4"
   },
   "outputs": [],
   "source": [
    "# Function to calculate the accuracy of our predictions vs labels\n",
    "def flat_accuracy(preds, labels):\n",
    "    pred_flat = np.argmax(preds, axis=1).flatten()\n",
    "    labels_flat = labels.flatten()\n",
    "    return np.sum(pred_flat == labels_flat) / len(labels_flat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "1zbbwmVMZaq4"
   },
   "outputs": [],
   "source": [
    "import time\n",
    "import datetime\n",
    "\n",
    "def format_time(elapsed):\n",
    "    '''\n",
    "    Takes a time in seconds and returns a string hh:mm:ss\n",
    "    '''\n",
    "    # Round to the nearest second.\n",
    "    elapsed_rounded = int(round((elapsed)))\n",
    "    \n",
    "    # Format as hh:mm:ss\n",
    "    return str(datetime.timedelta(seconds=elapsed_rounded))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "zBq9WULYZaq4",
    "outputId": "9aee1197-5e64-4a9f-d927-282aed940889"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======== Epoch 1 / 3 ========\n",
      "Training...\n",
      "  Batch    40  of    675.    Elapsed: 0:00:16.\n",
      "  Batch    80  of    675.    Elapsed: 0:00:33.\n",
      "  Batch   120  of    675.    Elapsed: 0:00:49.\n",
      "  Batch   160  of    675.    Elapsed: 0:01:06.\n",
      "  Batch   200  of    675.    Elapsed: 0:01:22.\n",
      "  Batch   240  of    675.    Elapsed: 0:01:38.\n",
      "  Batch   280  of    675.    Elapsed: 0:01:55.\n",
      "  Batch   320  of    675.    Elapsed: 0:02:11.\n",
      "  Batch   360  of    675.    Elapsed: 0:02:28.\n",
      "  Batch   400  of    675.    Elapsed: 0:02:44.\n",
      "  Batch   440  of    675.    Elapsed: 0:03:01.\n",
      "  Batch   480  of    675.    Elapsed: 0:03:17.\n",
      "  Batch   520  of    675.    Elapsed: 0:03:33.\n",
      "  Batch   560  of    675.    Elapsed: 0:03:50.\n",
      "  Batch   600  of    675.    Elapsed: 0:04:06.\n",
      "  Batch   640  of    675.    Elapsed: 0:04:23.\n",
      "\n",
      "  Average training loss: 0.70\n",
      "  Training epoch took: 0:04:37\n",
      "\n",
      "Running Validation...\n",
      "  Accuracy: 0.50\n",
      "  Validation Loss: 0.70\n",
      "  Validation took: 0:00:10\n",
      "\n",
      "======== Epoch 2 / 3 ========\n",
      "Training...\n",
      "  Batch    40  of    675.    Elapsed: 0:00:16.\n",
      "  Batch    80  of    675.    Elapsed: 0:00:33.\n",
      "  Batch   120  of    675.    Elapsed: 0:00:49.\n",
      "  Batch   160  of    675.    Elapsed: 0:01:06.\n",
      "  Batch   200  of    675.    Elapsed: 0:01:22.\n",
      "  Batch   240  of    675.    Elapsed: 0:01:38.\n",
      "  Batch   280  of    675.    Elapsed: 0:01:55.\n",
      "  Batch   320  of    675.    Elapsed: 0:02:11.\n",
      "  Batch   360  of    675.    Elapsed: 0:02:28.\n",
      "  Batch   400  of    675.    Elapsed: 0:02:44.\n",
      "  Batch   440  of    675.    Elapsed: 0:03:00.\n",
      "  Batch   480  of    675.    Elapsed: 0:03:17.\n",
      "  Batch   520  of    675.    Elapsed: 0:03:33.\n",
      "  Batch   560  of    675.    Elapsed: 0:03:50.\n",
      "  Batch   600  of    675.    Elapsed: 0:04:06.\n",
      "  Batch   640  of    675.    Elapsed: 0:04:22.\n",
      "\n",
      "  Average training loss: 0.69\n",
      "  Training epoch took: 0:04:37\n",
      "\n",
      "Running Validation...\n",
      "  Accuracy: 0.49\n",
      "  Validation Loss: 0.69\n",
      "  Validation took: 0:00:10\n",
      "\n",
      "======== Epoch 3 / 3 ========\n",
      "Training...\n",
      "  Batch    40  of    675.    Elapsed: 0:00:16.\n",
      "  Batch    80  of    675.    Elapsed: 0:00:33.\n",
      "  Batch   120  of    675.    Elapsed: 0:00:49.\n",
      "  Batch   160  of    675.    Elapsed: 0:01:06.\n",
      "  Batch   200  of    675.    Elapsed: 0:01:22.\n",
      "  Batch   240  of    675.    Elapsed: 0:01:38.\n",
      "  Batch   280  of    675.    Elapsed: 0:01:55.\n",
      "  Batch   320  of    675.    Elapsed: 0:02:11.\n",
      "  Batch   360  of    675.    Elapsed: 0:02:27.\n",
      "  Batch   440  of    675.    Elapsed: 0:03:00.\n",
      "  Batch   480  of    675.    Elapsed: 0:03:17.\n",
      "  Batch   520  of    675.    Elapsed: 0:03:33.\n",
      "  Batch   560  of    675.    Elapsed: 0:03:49.\n",
      "  Batch   600  of    675.    Elapsed: 0:04:06.\n",
      "  Batch   640  of    675.    Elapsed: 0:04:22.\n",
      "\n",
      "  Average training loss: 0.68\n",
      "  Training epoch took: 0:04:36\n",
      "\n",
      "Running Validation...\n",
      "  Accuracy: 0.51\n",
      "  Validation Loss: 0.70\n",
      "  Validation took: 0:00:10\n",
      "\n",
      "Training complete!\n",
      "Total training took 0:14:19 (h:mm:ss)\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "\n",
    "# This training code is based on the `run_glue.py` script here:\n",
    "# https://github.com/huggingface/transformers/blob/5bfcd0485ece086ebcbed2d008813037968a9e58/examples/run_glue.py#L128\n",
    "\n",
    "# Set the seed value all over the place to make this reproducible.\n",
    "seed_val = 42\n",
    "\n",
    "random.seed(seed_val)\n",
    "np.random.seed(seed_val)\n",
    "torch.manual_seed(seed_val)\n",
    "torch.cuda.manual_seed_all(seed_val)\n",
    "\n",
    "# We'll store a number of quantities such as training and validation loss, \n",
    "# validation accuracy, and timings.\n",
    "training_stats = []\n",
    "\n",
    "# Measure the total training time for the whole run.\n",
    "total_t0 = time.time()\n",
    "\n",
    "# For each epoch...\n",
    "for epoch_i in range(0, epochs):\n",
    "    \n",
    "    # ========================================\n",
    "    #               Training\n",
    "    # ========================================\n",
    "    \n",
    "    # Perform one full pass over the training set.\n",
    "\n",
    "    print(\"\")\n",
    "    print('======== Epoch {:} / {:} ========'.format(epoch_i + 1, epochs))\n",
    "    print('Training...')\n",
    "\n",
    "    # Measure how long the training epoch takes.\n",
    "    t0 = time.time()\n",
    "\n",
    "    # Reset the total loss for this epoch.\n",
    "    total_train_loss = 0\n",
    "\n",
    "    # Put the model into training mode. Don't be misled--the call to \n",
    "    # `train` just changes the *mode*, it doesn't *perform* the training.\n",
    "    # `dropout` and `batchnorm` layers behave differently during training\n",
    "    # vs. test (source: https://stackoverflow.com/questions/51433378/what-does-model-train-do-in-pytorch)\n",
    "    model.train()\n",
    "\n",
    "    # For each batch of training data...\n",
    "    for step, batch in enumerate(train_dataloader):\n",
    "\n",
    "        # Progress update every 40 batches.\n",
    "        if step % 40 == 0 and not step == 0:\n",
    "            # Calculate elapsed time in minutes.\n",
    "            elapsed = format_time(time.time() - t0)\n",
    "            \n",
    "            # Report progress.\n",
    "            print('  Batch {:>5,}  of  {:>5,}.    Elapsed: {:}.'.format(step, len(train_dataloader), elapsed))\n",
    "\n",
    "        # Unpack this training batch from our dataloader. \n",
    "        #\n",
    "        # As we unpack the batch, we'll also copy each tensor to the GPU using the \n",
    "        # `to` method.\n",
    "        #\n",
    "        # `batch` contains three pytorch tensors:\n",
    "        #   [0]: input ids \n",
    "        #   [1]: attention masks\n",
    "        #   [2]: labels \n",
    "        b_input_ids = batch[0].to(device)\n",
    "        b_input_mask = batch[1].to(device)\n",
    "        b_labels = batch[2].to(device)\n",
    "\n",
    "        # Always clear any previously calculated gradients before performing a\n",
    "        # backward pass. PyTorch doesn't do this automatically because \n",
    "        # accumulating the gradients is \"convenient while training RNNs\". \n",
    "        # (source: https://stackoverflow.com/questions/48001598/why-do-we-need-to-call-zero-grad-in-pytorch)\n",
    "        model.zero_grad()        \n",
    "\n",
    "        # Perform a forward pass (evaluate the model on this training batch).\n",
    "        # The documentation for this `model` function is here: \n",
    "        # https://huggingface.co/transformers/v2.2.0/model_doc/bert.html#transformers.BertForSequenceClassification\n",
    "        # It returns different numbers of parameters depending on what arguments\n",
    "        # arge given and what flags are set. For our useage here, it returns\n",
    "        # the loss (because we provided labels) and the \"logits\"--the model\n",
    "        # outputs prior to activation.\n",
    "        loss, logits = model(b_input_ids, \n",
    "                             token_type_ids=None, \n",
    "                             attention_mask=b_input_mask, \n",
    "                             labels=b_labels.long())\n",
    "\n",
    "        # Accumulate the training loss over all of the batches so that we can\n",
    "        # calculate the average loss at the end. `loss` is a Tensor containing a\n",
    "        # single value; the `.item()` function just returns the Python value \n",
    "        # from the tensor.\n",
    "        total_train_loss += loss.item()\n",
    "\n",
    "        # Perform a backward pass to calculate the gradients.\n",
    "        loss.backward()\n",
    "\n",
    "        # Clip the norm of the gradients to 1.0.\n",
    "        # This is to help prevent the \"exploding gradients\" problem.\n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
    "\n",
    "        # Update parameters and take a step using the computed gradient.\n",
    "        # The optimizer dictates the \"update rule\"--how the parameters are\n",
    "        # modified based on their gradients, the learning rate, etc.\n",
    "        optimizer.step()\n",
    "\n",
    "        # Update the learning rate.\n",
    "        scheduler.step()\n",
    "\n",
    "    # Calculate the average loss over all of the batches.\n",
    "    avg_train_loss = total_train_loss / len(train_dataloader)            \n",
    "    \n",
    "    # Measure how long this epoch took.\n",
    "    training_time = format_time(time.time() - t0)\n",
    "\n",
    "    print(\"\")\n",
    "    print(\"  Average training loss: {0:.2f}\".format(avg_train_loss))\n",
    "    print(\"  Training epoch took: {:}\".format(training_time))\n",
    "        \n",
    "    # ========================================\n",
    "    #               Validation\n",
    "    # ========================================\n",
    "    # After the completion of each training epoch, measure our performance on\n",
    "    # our validation set.\n",
    "\n",
    "    print(\"\")\n",
    "    print(\"Running Validation...\")\n",
    "\n",
    "    t0 = time.time()\n",
    "\n",
    "    # Put the model in evaluation mode--the dropout layers behave differently\n",
    "    # during evaluation.\n",
    "    model.eval()\n",
    "\n",
    "    # Tracking variables \n",
    "    total_eval_accuracy = 0\n",
    "    total_eval_loss = 0\n",
    "    nb_eval_steps = 0\n",
    "\n",
    "    # Evaluate data for one epoch\n",
    "    for batch in validation_dataloader:\n",
    "        \n",
    "        # Unpack this training batch from our dataloader. \n",
    "        #\n",
    "        # As we unpack the batch, we'll also copy each tensor to the GPU using \n",
    "        # the `to` method.\n",
    "        #\n",
    "        # `batch` contains three pytorch tensors:\n",
    "        #   [0]: input ids \n",
    "        #   [1]: attention masks\n",
    "        #   [2]: labels \n",
    "        b_input_ids = batch[0].to(device)\n",
    "        b_input_mask = batch[1].to(device)\n",
    "        b_labels = batch[2].to(device)\n",
    "        \n",
    "        # Tell pytorch not to bother with constructing the compute graph during\n",
    "        # the forward pass, since this is only needed for backprop (training).\n",
    "        with torch.no_grad():        \n",
    "\n",
    "            # Forward pass, calculate logit predictions.\n",
    "            # token_type_ids is the same as the \"segment ids\", which \n",
    "            # differentiates sentence 1 and 2 in 2-sentence tasks.\n",
    "            # The documentation for this `model` function is here: \n",
    "            # https://huggingface.co/transformers/v2.2.0/model_doc/bert.html#transformers.BertForSequenceClassification\n",
    "            # Get the \"logits\" output by the model. The \"logits\" are the output\n",
    "            # values prior to applying an activation function like the softmax.\n",
    "            (loss, logits) = model(b_input_ids, \n",
    "                                   token_type_ids=None, \n",
    "                                   attention_mask=b_input_mask,\n",
    "                                   labels=b_labels.long())\n",
    "            \n",
    "        # Accumulate the validation loss.\n",
    "        total_eval_loss += loss.item()\n",
    "\n",
    "        # Move logits and labels to CPU\n",
    "        logits = logits.detach().cpu().numpy()\n",
    "        label_ids = b_labels.to('cpu').numpy()\n",
    "\n",
    "        # Calculate the accuracy for this batch of test sentences, and\n",
    "        # accumulate it over all batches.\n",
    "        total_eval_accuracy += flat_accuracy(logits, label_ids)\n",
    "        \n",
    "\n",
    "    # Report the final accuracy for this validation run.\n",
    "    avg_val_accuracy = total_eval_accuracy / len(validation_dataloader)\n",
    "    print(\"  Accuracy: {0:.2f}\".format(avg_val_accuracy))\n",
    "\n",
    "    # Calculate the average loss over all of the batches.\n",
    "    avg_val_loss = total_eval_loss / len(validation_dataloader)\n",
    "    \n",
    "    # Measure how long the validation run took.\n",
    "    validation_time = format_time(time.time() - t0)\n",
    "    \n",
    "    print(\"  Validation Loss: {0:.2f}\".format(avg_val_loss))\n",
    "    print(\"  Validation took: {:}\".format(validation_time))\n",
    "\n",
    "    # Record all statistics from this epoch.\n",
    "    training_stats.append(\n",
    "        {\n",
    "            'epoch': epoch_i + 1,\n",
    "            'Training Loss': avg_train_loss,\n",
    "            'Valid. Loss': avg_val_loss,\n",
    "            'Valid. Accur.': avg_val_accuracy,\n",
    "            'Training Time': training_time,\n",
    "            'Validation Time': validation_time\n",
    "        }\n",
    "    )\n",
    "\n",
    "print(\"\")\n",
    "print(\"Training complete!\")\n",
    "\n",
    "print(\"Total training took {:} (h:mm:ss)\".format(format_time(time.time()-total_t0)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 166
    },
    "id": "C19KLyEDZaq4",
    "outputId": "13bf066b-f9ce-4116-93e2-6f11968e3330"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Valid. Loss</th>\n",
       "      <th>Valid. Accur.</th>\n",
       "      <th>Training Time</th>\n",
       "      <th>Validation Time</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>epoch</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.70</td>\n",
       "      <td>0.70</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0:04:37</td>\n",
       "      <td>0:00:10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.69</td>\n",
       "      <td>0.69</td>\n",
       "      <td>0.49</td>\n",
       "      <td>0:04:37</td>\n",
       "      <td>0:00:10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.68</td>\n",
       "      <td>0.70</td>\n",
       "      <td>0.51</td>\n",
       "      <td>0:04:36</td>\n",
       "      <td>0:00:10</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Training Loss  Valid. Loss  Valid. Accur. Training Time Validation Time\n",
       "epoch                                                                         \n",
       "1               0.70         0.70           0.50       0:04:37         0:00:10\n",
       "2               0.69         0.69           0.49       0:04:37         0:00:10\n",
       "3               0.68         0.70           0.51       0:04:36         0:00:10"
      ]
     },
     "execution_count": 15,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Display floats with two decimal places.\n",
    "pd.set_option('precision', 2)\n",
    "\n",
    "# Create a DataFrame from our training statistics.\n",
    "df_stats = pd.DataFrame(data=training_stats)\n",
    "\n",
    "# Use the 'epoch' as the row index.\n",
    "df_stats = df_stats.set_index('epoch')\n",
    "\n",
    "# A hack to force the column headers to wrap.\n",
    "#df = df.style.set_table_styles([dict(selector=\"th\",props=[('max-width', '70px')])])\n",
    "\n",
    "# Display the table.\n",
    "df_stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "X_HOGZyVZaq5",
    "outputId": "5bf4ebb6-4d8b-4343-a3e5-942cf0f70be5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "testing on toxic examples\n",
      "Number of test sentences: 1,000\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/transformers/tokenization_utils_base.py:2022: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
      "  FutureWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicting labels for 1,000 test sentences...\n",
      "    DONE.\n",
      "Total F1: 0.466\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light",
      "tags": []
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculating and F1 score for each batch...\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light",
      "tags": []
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "testing on nontoxic examples\n",
      "Number of test sentences: 1,000\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/transformers/tokenization_utils_base.py:2022: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
      "  FutureWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicting labels for 1,000 test sentences...\n",
      "    DONE.\n",
      "Total F1: 0.553\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light",
      "tags": []
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculating and F1 score for each batch...\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light",
      "tags": []
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# create test set\n",
    "#df = toxicity[5000:5500]\n",
    "#df = pd.concat([toxic[2500:2750], nontoxic[2500:2750]])\n",
    "#df = pd.concat([female_set.sample(250), other.sample(250)])\n",
    "\n",
    "for i in range(2):\n",
    "  if i == 0:\n",
    "    df = pd.concat([female_toxic.sample(500), other_toxic.sample(500)])\n",
    "\n",
    "    print('testing on toxic examples')\n",
    "  else:\n",
    "    df = pd.concat([female_nontoxic.sample(500), other_nontoxic.sample(500)])\n",
    "    print('testing on nontoxic examples')\n",
    "\n",
    "  df = df.sample(frac=1)\n",
    "  print('Number of test sentences: {:,}\\n'.format(df.shape[0]))\n",
    "\n",
    "  comments = df.comment.values\n",
    "  labels = df.female_binary.values\n",
    "  scores = df.toxicity_score.values\n",
    "\n",
    "  # Tokenize all of the sentences and map the tokens to thier word IDs.\n",
    "  input_ids = []\n",
    "  attention_masks = []\n",
    "\n",
    "  # For every sentence...\n",
    "  for i in range(len(comments)):\n",
    "      # `encode_plus` will:\n",
    "      #   (1) Tokenize the sentence.\n",
    "      #   (2) Prepend the `[CLS]` token to the start.\n",
    "      #   (3) Append the `[SEP]` token to the end.\n",
    "      #   (4) Map tokens to their IDs.\n",
    "      #   (5) Pad or truncate the sentence to `max_length`\n",
    "      #   (6) Create attention masks for [PAD] tokens.\n",
    "      cmt = str(scores[i])+\" \"+comments[i]\n",
    "      encoded_dict = tokenizer.encode_plus(\n",
    "                          cmt,                      # Sentence to encode.\n",
    "                          add_special_tokens = True, # Add '[CLS]' and '[SEP]'\n",
    "                          max_length = 250,           # Pad & truncate all sentences.\n",
    "                          pad_to_max_length = True,\n",
    "                          return_attention_mask = True,   # Construct attn. masks.\n",
    "                          return_tensors = 'pt',     # Return pytorch tensors.\n",
    "                    )\n",
    "      \n",
    "      # Add the encoded sentence to the list.    \n",
    "      input_ids.append(encoded_dict['input_ids'])\n",
    "      \n",
    "      # And its attention mask (simply differentiates padding from non-padding).\n",
    "      attention_masks.append(encoded_dict['attention_mask'])\n",
    "\n",
    "  # Convert the lists into tensors.\n",
    "  input_ids = torch.cat(input_ids, dim=0)\n",
    "  attention_masks = torch.cat(attention_masks, dim=0)\n",
    "  labels = torch.tensor(labels)\n",
    "\n",
    "  # Set the batch size.  \n",
    "  batch_size = 16\n",
    "\n",
    "  # Create the DataLoader.\n",
    "  prediction_data = TensorDataset(input_ids, attention_masks, labels)\n",
    "  prediction_sampler = SequentialSampler(prediction_data)\n",
    "  prediction_dataloader = DataLoader(prediction_data, sampler=prediction_sampler, batch_size=batch_size)\n",
    "\n",
    "  # Prediction on test set\n",
    "\n",
    "  print('Predicting labels for {:,} test sentences...'.format(len(input_ids)))\n",
    "\n",
    "  # Put model in evaluation mode\n",
    "  model.eval()\n",
    "\n",
    "  # Tracking variables \n",
    "  predictions , true_labels = [], []\n",
    "\n",
    "  # Predict \n",
    "  for batch in prediction_dataloader:\n",
    "    # Add batch to GPU\n",
    "    batch = tuple(t.to(device) for t in batch)\n",
    "    \n",
    "    # Unpack the inputs from our dataloader\n",
    "    b_input_ids, b_input_mask, b_labels = batch\n",
    "    \n",
    "    # Telling the model not to compute or store gradients, saving memory and \n",
    "    # speeding up prediction\n",
    "    with torch.no_grad():\n",
    "        # Forward pass, calculate logit predictions\n",
    "        outputs = model(b_input_ids, token_type_ids=None, \n",
    "                        attention_mask=b_input_mask)\n",
    "\n",
    "    logits = outputs[0]\n",
    "\n",
    "    # Move logits and labels to CPU\n",
    "    logits = logits.detach().cpu().numpy()\n",
    "    label_ids = b_labels.to('cpu').numpy()\n",
    "    \n",
    "    # Store predictions and true labels\n",
    "    predictions.append(logits)\n",
    "    true_labels.append(label_ids)\n",
    "\n",
    "  print('    DONE.')\n",
    "\n",
    "  from sklearn.metrics import f1_score, confusion_matrix\n",
    "  import seaborn as sns\n",
    "  import matplotlib.pyplot as plt\n",
    "\n",
    "  # Combine the results across all batches. \n",
    "  flat_predictions = np.concatenate(predictions, axis=0)\n",
    "\n",
    "  # For each sample, pick the label (0 or 1) with the higher score.\n",
    "  flat_predictions = np.argmax(flat_predictions, axis=1).flatten()\n",
    "\n",
    "  # Combine the correct labels for each batch into a single list.\n",
    "  flat_true_labels = np.concatenate(true_labels, axis=0)\n",
    "\n",
    "  f1 = f1_score(flat_true_labels, flat_predictions)\n",
    "  print('Total F1: %.3f' % f1)\n",
    "\n",
    "  cf_matrix = confusion_matrix(flat_true_labels, flat_predictions)\n",
    "  group_names = ['True Neg','False Pos','False Neg','True Pos']\n",
    "  group_counts = ['{0:0.0f}'.format(value) for value in\n",
    "                  cf_matrix.flatten()]\n",
    "  group_percentages = ['{0:.2%}'.format(value) for value in\n",
    "                      cf_matrix.flatten()/np.sum(cf_matrix)]\n",
    "  labels = [f'{v1}\\n{v2}\\n{v3}' for v1, v2, v3 in\n",
    "            zip(group_names,group_counts,group_percentages)]\n",
    "  labels = np.asarray(labels).reshape(2,2)\n",
    "  sns.heatmap(cf_matrix, annot=labels, fmt='', cmap='Blues')\n",
    "  plt.show()\n",
    "\n",
    "  f1_set = []\n",
    "\n",
    "  # Evaluate each test batch\n",
    "  print('Calculating and F1 score for each batch...')\n",
    "\n",
    "  # For each input batch...\n",
    "  for i in range(len(true_labels)):\n",
    "    \n",
    "    # The predictions for this batch are a 2-column ndarray (one column for \"0\" \n",
    "    # and one column for \"1\"). Pick the label with the highest value and turn this\n",
    "    # in to a list of 0s and 1s.\n",
    "    pred_labels_i = np.argmax(predictions[i], axis=1).flatten()\n",
    "    \n",
    "    # Calculate and store the coef for this batch.  \n",
    "    score = f1_score(true_labels[i], pred_labels_i)\n",
    "    f1_set.append(score)\n",
    "\n",
    "  # Create a barplot showing the f1 score for each batch of test samples.\n",
    "  ax = sns.barplot(x=list(range(len(f1_set))), y=f1_set, ci=None)\n",
    "\n",
    "  plt.title('f1 Score per Batch')\n",
    "  plt.ylabel('f1 Score (0 to +1)')\n",
    "  plt.xlabel('Batch #')\n",
    "\n",
    "  plt.show()"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "BERT Classifier.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
