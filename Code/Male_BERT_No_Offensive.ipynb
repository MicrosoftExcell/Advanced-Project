{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7ak_Ca3w_rNy"
   },
   "source": [
    "## BERT classifier v9: Removing toxic words from training data to see which model picks up on context/semantics\n",
    "Trained on balanced data for male annotators in toxic/nontoxic classes with all toxic words removed from training data, label = toxicity, tested toxicity predictions for toxic comments annotated by men/women.\n",
    "\n",
    "Using BERT code from: https://mccormickml.com/2019/07/22/BERT-fine-tuning/\n",
    "\n",
    "Adapted BERT for sentiment analysis using code from: https://curiousily.com/posts/sentiment-analysis-with-bert-and-hugging-face-using-pytorch-and-python/\n",
    "\n",
    "After training the model will be saved in bert_male_notoxic_state.bin and can be reused for future runs\n",
    "\n",
    "Using offensive words list from: https://www.cs.cmu.edu/~biglou/resources/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Before running, check values of:\n",
    "* file paths\n",
    "* MAX_LEN\n",
    "* batch_size\n",
    "* size\n",
    "* epochs\n",
    "* pretrained\n",
    "* saved_test_set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install required libraries\n",
    "#!conda install -y tensorflow\n",
    "#!conda install -y pytorch torchvision -c pytorch\n",
    "#!pip install transformers\n",
    "#!pip install transformers==3.5.1\n",
    "#!pip install -U seaborn\n",
    "#!pip install wordcloud"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "RBWkIenb_xH-",
    "outputId": "fb551ee7-1634-45cd-8656-8b8d82be77c2"
   },
   "outputs": [],
   "source": [
    "# Import libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from collections import defaultdict\n",
    "import random\n",
    "import math\n",
    "import nltk\n",
    "import datetime\n",
    "import time\n",
    "import string\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.utils.data import TensorDataset, random_split\n",
    "from torch.utils.data import DataLoader, RandomSampler, SequentialSampler\n",
    "from transformers import BertTokenizer\n",
    "from transformers import BertForSequenceClassification, AdamW, BertConfig\n",
    "from transformers import logging\n",
    "from transformers import get_linear_schedule_with_warmup\n",
    "from sklearn.metrics import f1_score, confusion_matrix, accuracy_score\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import plotly.graph_objects as go\n",
    "import pickle\n",
    "from wordcloud import WordCloud\n",
    "\n",
    "# In order to use notebook in Google Colab\n",
    "# from google.colab import drive\n",
    "# drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Choose whether to use pretrained model\n",
    "pretrained = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 262
    },
    "id": "NrVW-FsUABeB",
    "outputId": "9027af8e-a87c-4318-ca90-dd1a5901c514"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>comment</th>\n",
       "      <th>year</th>\n",
       "      <th>logged_in</th>\n",
       "      <th>ns</th>\n",
       "      <th>sample</th>\n",
       "      <th>split</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rev_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2232.0</th>\n",
       "      <td>This:NEWLINE_TOKEN:One can make an analogy in ...</td>\n",
       "      <td>2002</td>\n",
       "      <td>True</td>\n",
       "      <td>article</td>\n",
       "      <td>random</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4216.0</th>\n",
       "      <td>`NEWLINE_TOKENNEWLINE_TOKEN:Clarification for ...</td>\n",
       "      <td>2002</td>\n",
       "      <td>True</td>\n",
       "      <td>user</td>\n",
       "      <td>random</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8953.0</th>\n",
       "      <td>Elected or Electoral? JHK</td>\n",
       "      <td>2002</td>\n",
       "      <td>False</td>\n",
       "      <td>article</td>\n",
       "      <td>random</td>\n",
       "      <td>test</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26547.0</th>\n",
       "      <td>`This is such a fun entry.   DevotchkaNEWLINE_...</td>\n",
       "      <td>2002</td>\n",
       "      <td>True</td>\n",
       "      <td>article</td>\n",
       "      <td>random</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28959.0</th>\n",
       "      <td>Please relate the ozone hole to increases in c...</td>\n",
       "      <td>2002</td>\n",
       "      <td>True</td>\n",
       "      <td>article</td>\n",
       "      <td>random</td>\n",
       "      <td>test</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   comment  year  logged_in  \\\n",
       "rev_id                                                                        \n",
       "2232.0   This:NEWLINE_TOKEN:One can make an analogy in ...  2002       True   \n",
       "4216.0   `NEWLINE_TOKENNEWLINE_TOKEN:Clarification for ...  2002       True   \n",
       "8953.0                           Elected or Electoral? JHK  2002      False   \n",
       "26547.0  `This is such a fun entry.   DevotchkaNEWLINE_...  2002       True   \n",
       "28959.0  Please relate the ozone hole to increases in c...  2002       True   \n",
       "\n",
       "              ns  sample  split  \n",
       "rev_id                           \n",
       "2232.0   article  random  train  \n",
       "4216.0      user  random  train  \n",
       "8953.0   article  random   test  \n",
       "26547.0  article  random  train  \n",
       "28959.0  article  random   test  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>rev_id</th>\n",
       "      <th>worker_id</th>\n",
       "      <th>toxicity</th>\n",
       "      <th>toxicity_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2232.0</td>\n",
       "      <td>723</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2232.0</td>\n",
       "      <td>4000</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2232.0</td>\n",
       "      <td>3989</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2232.0</td>\n",
       "      <td>3341</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2232.0</td>\n",
       "      <td>1574</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   rev_id  worker_id  toxicity  toxicity_score\n",
       "0  2232.0        723         0             0.0\n",
       "1  2232.0       4000         0             0.0\n",
       "2  2232.0       3989         0             1.0\n",
       "3  2232.0       3341         0             0.0\n",
       "4  2232.0       1574         0             1.0"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>worker_id</th>\n",
       "      <th>gender</th>\n",
       "      <th>english_first_language</th>\n",
       "      <th>age_group</th>\n",
       "      <th>education</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>85</td>\n",
       "      <td>female</td>\n",
       "      <td>0</td>\n",
       "      <td>18-30</td>\n",
       "      <td>bachelors</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1617</td>\n",
       "      <td>female</td>\n",
       "      <td>0</td>\n",
       "      <td>45-60</td>\n",
       "      <td>bachelors</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1394</td>\n",
       "      <td>female</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>bachelors</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>311</td>\n",
       "      <td>male</td>\n",
       "      <td>0</td>\n",
       "      <td>30-45</td>\n",
       "      <td>bachelors</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1980</td>\n",
       "      <td>male</td>\n",
       "      <td>0</td>\n",
       "      <td>45-60</td>\n",
       "      <td>masters</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   worker_id  gender  english_first_language age_group  education\n",
       "0         85  female                       0     18-30  bachelors\n",
       "1       1617  female                       0     45-60  bachelors\n",
       "2       1394  female                       0       NaN  bachelors\n",
       "3        311    male                       0     30-45  bachelors\n",
       "4       1980    male                       0     45-60    masters"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Read files and create dataframe (may need to change path)\n",
    "toxicity_comments = pd.read_csv('../toxicity_annotated_comments.tsv', sep = '\\t', index_col = 0)\n",
    "toxicity_annotations = pd.read_csv('../toxicity_annotations.tsv',  sep = '\\t')\n",
    "toxicity_demographics = pd.read_csv('../toxicity_worker_demographics.tsv', sep = '\\t')\n",
    "    \n",
    "# Take a look at data\n",
    "display (toxicity_comments.head(5))\n",
    "display (toxicity_annotations.head(5))\n",
    "display (toxicity_demographics.head(5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 262
    },
    "id": "NrVW-FsUABeB",
    "outputId": "9027af8e-a87c-4318-ca90-dd1a5901c514"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>rev_id</th>\n",
       "      <th>comment</th>\n",
       "      <th>year</th>\n",
       "      <th>logged_in</th>\n",
       "      <th>ns</th>\n",
       "      <th>sample</th>\n",
       "      <th>split</th>\n",
       "      <th>worker_id</th>\n",
       "      <th>toxicity</th>\n",
       "      <th>toxicity_score</th>\n",
       "      <th>gender</th>\n",
       "      <th>english_first_language</th>\n",
       "      <th>age_group</th>\n",
       "      <th>education</th>\n",
       "      <th>female_binary</th>\n",
       "      <th>male_binary</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3467</th>\n",
       "      <td>2232.0</td>\n",
       "      <td>This: :One can make an analogy in mathematical...</td>\n",
       "      <td>2002</td>\n",
       "      <td>True</td>\n",
       "      <td>article</td>\n",
       "      <td>random</td>\n",
       "      <td>train</td>\n",
       "      <td>405</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>male</td>\n",
       "      <td>0.0</td>\n",
       "      <td>30-45</td>\n",
       "      <td>masters</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3039</th>\n",
       "      <td>2232.0</td>\n",
       "      <td>This: :One can make an analogy in mathematical...</td>\n",
       "      <td>2002</td>\n",
       "      <td>True</td>\n",
       "      <td>article</td>\n",
       "      <td>random</td>\n",
       "      <td>train</td>\n",
       "      <td>680</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>male</td>\n",
       "      <td>0.0</td>\n",
       "      <td>18-30</td>\n",
       "      <td>masters</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2232.0</td>\n",
       "      <td>This: :One can make an analogy in mathematical...</td>\n",
       "      <td>2002</td>\n",
       "      <td>True</td>\n",
       "      <td>article</td>\n",
       "      <td>random</td>\n",
       "      <td>train</td>\n",
       "      <td>723</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>female</td>\n",
       "      <td>0.0</td>\n",
       "      <td>30-45</td>\n",
       "      <td>bachelors</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2600</th>\n",
       "      <td>2232.0</td>\n",
       "      <td>This: :One can make an analogy in mathematical...</td>\n",
       "      <td>2002</td>\n",
       "      <td>True</td>\n",
       "      <td>article</td>\n",
       "      <td>random</td>\n",
       "      <td>train</td>\n",
       "      <td>772</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>male</td>\n",
       "      <td>0.0</td>\n",
       "      <td>18-30</td>\n",
       "      <td>bachelors</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2169</th>\n",
       "      <td>2232.0</td>\n",
       "      <td>This: :One can make an analogy in mathematical...</td>\n",
       "      <td>2002</td>\n",
       "      <td>True</td>\n",
       "      <td>article</td>\n",
       "      <td>random</td>\n",
       "      <td>train</td>\n",
       "      <td>1508</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>female</td>\n",
       "      <td>1.0</td>\n",
       "      <td>45-60</td>\n",
       "      <td>hs</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      rev_id                                            comment  year  \\\n",
       "3467  2232.0  This: :One can make an analogy in mathematical...  2002   \n",
       "3039  2232.0  This: :One can make an analogy in mathematical...  2002   \n",
       "0     2232.0  This: :One can make an analogy in mathematical...  2002   \n",
       "2600  2232.0  This: :One can make an analogy in mathematical...  2002   \n",
       "2169  2232.0  This: :One can make an analogy in mathematical...  2002   \n",
       "\n",
       "      logged_in       ns  sample  split  worker_id  toxicity  toxicity_score  \\\n",
       "3467       True  article  random  train        405         0             1.0   \n",
       "3039       True  article  random  train        680         0             0.0   \n",
       "0          True  article  random  train        723         0             0.0   \n",
       "2600       True  article  random  train        772         0             1.0   \n",
       "2169       True  article  random  train       1508         0             1.0   \n",
       "\n",
       "      gender  english_first_language age_group  education  female_binary  \\\n",
       "3467    male                     0.0     30-45    masters              0   \n",
       "3039    male                     0.0     18-30    masters              0   \n",
       "0     female                     0.0     30-45  bachelors              1   \n",
       "2600    male                     0.0     18-30  bachelors              0   \n",
       "2169  female                     1.0     45-60         hs              1   \n",
       "\n",
       "      male_binary  \n",
       "3467            1  \n",
       "3039            1  \n",
       "0               0  \n",
       "2600            1  \n",
       "2169            0  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Merge into single DataFrame\n",
    "toxicity = toxicity_comments.merge(toxicity_annotations, how ='outer', on=\"rev_id\")\n",
    "toxicity = toxicity.merge(toxicity_demographics, how ='outer', on=\"worker_id\").sort_values(by=['rev_id','worker_id'])\n",
    "\n",
    "# Remove newline and tab tokens from comments\n",
    "toxicity['comment'] = toxicity['comment'].apply(lambda x: x.replace(\"NEWLINE_TOKEN\", \" \"))\n",
    "toxicity['comment'] = toxicity['comment'].apply(lambda x: x.replace(\"TAB_TOKEN\", \" \"))\n",
    "\n",
    "# Remove annotators with 'other' as gender (too few to include in results)\n",
    "toxicity = toxicity[toxicity['gender']!='other']\n",
    "\n",
    "# Add binary gender columns\n",
    "toxicity = pd.concat([toxicity, pd.get_dummies(toxicity.gender).rename(columns = \"{}_binary\".format)], axis = 1)\n",
    "\n",
    "# Look at data with new columns\n",
    "display (toxicity.head(5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 262
    },
    "id": "NrVW-FsUABeB",
    "outputId": "9027af8e-a87c-4318-ca90-dd1a5901c514"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "smallest: 21863\n",
      "test size: 8744\n",
      "train size: 69964\n"
     ]
    }
   ],
   "source": [
    "# Separate comments into categories\n",
    "very_toxic = toxicity[toxicity.toxicity_score == -2.0]\n",
    "toxic = toxicity[toxicity.toxicity_score == -1.0]\n",
    "nontoxic = toxicity[toxicity.toxicity == 0]\n",
    "\n",
    "# Filter for male annotated data\n",
    "male_toxic = toxic[toxic.male_binary == 1]\n",
    "male_very_toxic = very_toxic[very_toxic.male_binary == 1]\n",
    "male_nontoxic = nontoxic[nontoxic.male_binary == 1]\n",
    "\n",
    "# Find smallest toxic dataset\n",
    "size = min(male_toxic.shape[0],male_very_toxic.shape[0])\n",
    "print(\"smallest:\",size)\n",
    "\n",
    "# Manually choose size if necessary\n",
    "# size = 2000\n",
    "\n",
    "# Split into train and test sets\n",
    "test_size = math.floor(size*0.2)\n",
    "train_size = math.ceil(size*0.8)\n",
    "\n",
    "# Create toxic test dataset and drop from dataframes so not also chosen for training\n",
    "male_toxic_test = male_toxic.sample(n=test_size)\n",
    "male_toxic = male_toxic.drop(male_toxic_test.index)\n",
    "male_vtoxic_test = male_very_toxic.sample(n=test_size)\n",
    "male_very_toxic = male_very_toxic.drop(male_vtoxic_test.index)\n",
    "male_test_data = pd.concat([male_toxic_test,male_vtoxic_test])\n",
    "male_test_data = male_test_data.sample(frac=1)\n",
    "print(\"test size:\",male_test_data.shape[0])\n",
    "\n",
    "# Training data composed of equal proportions of male toxic/nontoxic\n",
    "male_data = pd.concat([male_toxic.sample(train_size),male_very_toxic.sample(train_size),male_nontoxic.sample(train_size*2)])\n",
    "male_data = male_data.sample(frac=1)\n",
    "print(\"train size:\",male_data.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>rev_id</th>\n",
       "      <th>comment</th>\n",
       "      <th>year</th>\n",
       "      <th>logged_in</th>\n",
       "      <th>ns</th>\n",
       "      <th>sample</th>\n",
       "      <th>split</th>\n",
       "      <th>worker_id</th>\n",
       "      <th>toxicity</th>\n",
       "      <th>toxicity_score</th>\n",
       "      <th>gender</th>\n",
       "      <th>english_first_language</th>\n",
       "      <th>age_group</th>\n",
       "      <th>education</th>\n",
       "      <th>female_binary</th>\n",
       "      <th>male_binary</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>834848</th>\n",
       "      <td>92134476.0</td>\n",
       "      <td>*OK, go for it.  I'm only following your pro...</td>\n",
       "      <td>2006</td>\n",
       "      <td>True</td>\n",
       "      <td>article</td>\n",
       "      <td>random</td>\n",
       "      <td>train</td>\n",
       "      <td>916</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>male</td>\n",
       "      <td>0.0</td>\n",
       "      <td>30-45</td>\n",
       "      <td>masters</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1573705</th>\n",
       "      <td>155726253.0</td>\n",
       "      <td>Yeah, the video is really of negligible intell...</td>\n",
       "      <td>2007</td>\n",
       "      <td>True</td>\n",
       "      <td>article</td>\n",
       "      <td>random</td>\n",
       "      <td>train</td>\n",
       "      <td>4066</td>\n",
       "      <td>1</td>\n",
       "      <td>-2.0</td>\n",
       "      <td>male</td>\n",
       "      <td>0.0</td>\n",
       "      <td>45-60</td>\n",
       "      <td>hs</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>563605</th>\n",
       "      <td>474146181.0</td>\n",
       "      <td>`  == HI!!! ==  We are BloomAisha. We got our ...</td>\n",
       "      <td>2012</td>\n",
       "      <td>True</td>\n",
       "      <td>user</td>\n",
       "      <td>blocked</td>\n",
       "      <td>train</td>\n",
       "      <td>150</td>\n",
       "      <td>1</td>\n",
       "      <td>-2.0</td>\n",
       "      <td>male</td>\n",
       "      <td>0.0</td>\n",
       "      <td>45-60</td>\n",
       "      <td>hs</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44376</th>\n",
       "      <td>274775983.0</td>\n",
       "      <td>::Seriously, how would you expect someone to ...</td>\n",
       "      <td>2009</td>\n",
       "      <td>True</td>\n",
       "      <td>user</td>\n",
       "      <td>random</td>\n",
       "      <td>test</td>\n",
       "      <td>516</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>male</td>\n",
       "      <td>0.0</td>\n",
       "      <td>18-30</td>\n",
       "      <td>hs</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1185376</th>\n",
       "      <td>33918108.0</td>\n",
       "      <td>: Hey. I see tht youve already been bitten b...</td>\n",
       "      <td>2006</td>\n",
       "      <td>True</td>\n",
       "      <td>user</td>\n",
       "      <td>blocked</td>\n",
       "      <td>train</td>\n",
       "      <td>253</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>male</td>\n",
       "      <td>0.0</td>\n",
       "      <td>18-30</td>\n",
       "      <td>bachelors</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              rev_id                                            comment  year  \\\n",
       "834848    92134476.0    *OK, go for it.  I'm only following your pro...  2006   \n",
       "1573705  155726253.0  Yeah, the video is really of negligible intell...  2007   \n",
       "563605   474146181.0  `  == HI!!! ==  We are BloomAisha. We got our ...  2012   \n",
       "44376    274775983.0   ::Seriously, how would you expect someone to ...  2009   \n",
       "1185376   33918108.0    : Hey. I see tht youve already been bitten b...  2006   \n",
       "\n",
       "         logged_in       ns   sample  split  worker_id  toxicity  \\\n",
       "834848        True  article   random  train        916         0   \n",
       "1573705       True  article   random  train       4066         1   \n",
       "563605        True     user  blocked  train        150         1   \n",
       "44376         True     user   random   test        516         0   \n",
       "1185376       True     user  blocked  train        253         0   \n",
       "\n",
       "         toxicity_score gender  english_first_language age_group  education  \\\n",
       "834848              0.0   male                     0.0     30-45    masters   \n",
       "1573705            -2.0   male                     0.0     45-60         hs   \n",
       "563605             -2.0   male                     0.0     45-60         hs   \n",
       "44376               1.0   male                     0.0     18-30         hs   \n",
       "1185376             0.0   male                     0.0     18-30  bachelors   \n",
       "\n",
       "         female_binary  male_binary  \n",
       "834848               0            1  \n",
       "1573705              0            1  \n",
       "563605               0            1  \n",
       "44376                0            1  \n",
       "1185376              0            1  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Take a look at training data\n",
    "display (male_data.head(5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "HM4vJigyDP3j",
    "outputId": "cc473f51-5d50-4a89-be40-d5ed9ad4bac8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 1 GPU(s) available.\n",
      "We will use the GPU: GeForce RTX 2070\n"
     ]
    }
   ],
   "source": [
    "# Try to use gpu\n",
    "if torch.cuda.is_available():      \n",
    "    device = torch.device(\"cuda\")\n",
    "    print('There are %d GPU(s) available.' % torch.cuda.device_count())\n",
    "    print('We will use the GPU:', torch.cuda.get_device_name(0))\n",
    "\n",
    "else:\n",
    "    print('No GPU available, using the CPU instead.')\n",
    "    device = torch.device(\"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Removing punctuation and converting capital letters to lowercase\n",
    "male_data['comment'] = male_data['comment'].str.translate(str.maketrans('', '', string.punctuation))\n",
    "male_data['comment'] = male_data['comment'].str.lower()\n",
    "male_test_data['comment'] = male_test_data['comment'].str.translate(str.maketrans('', '', string.punctuation))\n",
    "male_test_data['comment'] = male_test_data['comment'].str.lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "O5Q5ntvhDWxN"
   },
   "outputs": [],
   "source": [
    "# Extract relevant information from training data (comment and toxicity of comment)\n",
    "comments = male_data.comment.values\n",
    "labels = male_data.toxicity.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Count number of offensive words in comment\n",
    "\n",
    "# List of offensive words taken from: https://www.cs.cmu.edu/~biglou/resources/\n",
    "file = open('bad-words.txt','r')\n",
    "offensive_words = file.read().splitlines()\n",
    "offensive_words = [word.replace(\" \",\"\") for word in offensive_words]\n",
    "file.close()\n",
    "\n",
    "# Removing acceptable words from offensive words list\n",
    "acceptable = ['','adult','africa','alla','allah','african','arab','arabs','asian','american','angry','australian','baptist','bible','bigger','black','blacks','burn','canadian','catholic','cemetery','catholics',\"children's\",'chinese','christian','church','cigarette','cocaine','cocktail','color','ecstacy','ethiopian','european','faith','fear','filipina','filipino','fire','funeral','german','gin','girls','heroin','israel','israeli',\"israel's\",'italiano','japanese','jew','jewish','joint','kid','latin','lsd','lucifer','marijuana','meth','mexican','mormon','muslim','narcotic','nigerian','nigerians','palestinian','poverty','pot','protestant','rabbi','vatican','welfare','whites',\"women's\"]\n",
    "for word in acceptable:\n",
    "    offensive_words.remove(word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove offensive words from comment\n",
    "def clean_comment(comment):\n",
    "    words = nltk.word_tokenize(comment)\n",
    "    new_comment = []\n",
    "    for word in words:\n",
    "        if word not in offensive_words:\n",
    "            new_comment.append(word)\n",
    "    return \" \".join(new_comment)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Removing offensive words from comments\n",
    "new_comments = []\n",
    "for comment in comments:\n",
    "    new_comment = clean_comment(comment)\n",
    "    new_comments.append(new_comment)\n",
    "comments = new_comments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 687,
     "referenced_widgets": [
      "9a413a00269e406f910a554babc8ddac",
      "050fad76094442ccabc0a9dd1841b1e7",
      "4ef1d475bfb44fb5b4e8f77843e9c13d",
      "c27bc61cdcfe419eab175f61768cb692",
      "a679570eb7834b98b460e7235fab57be",
      "7245dba34af84f019e9aa7b4167655c2",
      "2f72600eb7d241d38861be5e6cac560d",
      "b0aa11e7b5f44d7a9c094b3860f1fe1f"
     ]
    },
    "id": "UhlZR6pXD1Jl",
    "outputId": "3f2ca88e-54f7-4b79-9176-6d4f3781a8d4"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading BERT tokenizer...\n"
     ]
    }
   ],
   "source": [
    "# Load the BERT tokenizer.\n",
    "print('Loading BERT tokenizer...')\n",
    "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased', do_lower_case=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plot the distribution of sequence lengths to optimize the maximum sequence length used.  Large sequence lengths use a lot of GPU memory.\n",
    "\n",
    "plot_dist = True\n",
    "\n",
    "if plot_dist:\n",
    "\n",
    "    token_lens = []\n",
    "\n",
    "    for txt in comments:\n",
    "      tokens = tokenizer.encode(txt, max_length=512, truncation=True)\n",
    "      token_lens.append(len(tokens))\n",
    "\n",
    "    sns.histplot(token_lens)\n",
    "    plt.xlim([0, 256]);\n",
    "    plt.xlabel('Token count');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "f3gKFb5wD7eS",
    "outputId": "b6e81334-2d1c-4be1-981d-0f130a9c505d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original:  ok go for it im only following your progress because you listed it for grading on wikiprojectaustralia so you should expect a thorough examination\n",
      "Token IDs: tensor([  101,  7929,  2175,  2005,  2009, 10047,  2069,  2206,  2115,  5082,\n",
      "         2138,  2017,  3205,  2009,  2005, 26886,  2006, 15536,  3211, 21572,\n",
      "        20614, 20559, 21493,  2401,  2061,  2017,  2323,  5987,  1037, 16030,\n",
      "         7749,   102,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0])\n"
     ]
    }
   ],
   "source": [
    "# Limit the length of the sequence in tokens to control memory usage\n",
    "MAX_LEN=100\n",
    "\n",
    "# Tokenize all of the sentences and map the tokens to their word IDs.\n",
    "input_ids = []\n",
    "attention_masks = []\n",
    "\n",
    "# For every sentence...\n",
    "for cmt in comments:\n",
    "    # `encode_plus` will:\n",
    "    #   (1) Tokenize the sentence.\n",
    "    #   (2) Prepend the `[CLS]` token to the start.\n",
    "    #   (3) Append the `[SEP]` token to the end.\n",
    "    #   (4) Map tokens to their IDs.\n",
    "    #   (5) Pad or truncate the sentence to `max_length`\n",
    "    #   (6) Create attention masks for [PAD] tokens.\n",
    "    encoded_dict = tokenizer.encode_plus(\n",
    "                        cmt,                      # Sentence to encode.\n",
    "                        add_special_tokens = True, # Add '[CLS]' and '[SEP]'\n",
    "                        max_length = MAX_LEN,           # Pad & truncate all sentences.\n",
    "                        padding='max_length',\n",
    "                        truncation=True,\n",
    "                        return_attention_mask = True,   # Construct attn. masks.\n",
    "                        return_tensors = 'pt',     # Return pytorch tensors.\n",
    "                   )\n",
    "    \n",
    "    # Add the encoded sentence to the list.    \n",
    "    input_ids.append(encoded_dict['input_ids'])\n",
    "    \n",
    "    # And its attention mask (simply differentiates padding from non-padding).\n",
    "    attention_masks.append(encoded_dict['attention_mask'])\n",
    "\n",
    "# Convert the lists into tensors.\n",
    "input_ids = torch.cat(input_ids, dim=0)\n",
    "attention_masks = torch.cat(attention_masks, dim=0)\n",
    "labels = torch.tensor(labels)\n",
    "\n",
    "# # Print sentence 0, now as a list of IDs.\n",
    "print('Original: ', comments[0])\n",
    "print('Token IDs:', input_ids[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "vocab size: 30522\n"
     ]
    }
   ],
   "source": [
    "# Examining tokenization\n",
    "print(\"vocab size:\",tokenizer.vocab_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "gaaSOCAIEZq-",
    "outputId": "c6a08f0b-1fac-4b56-fe06-9ecb9eeb13c3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "62,967 training samples\n",
      "6,997 validation samples\n"
     ]
    }
   ],
   "source": [
    "# Combine the training inputs into a TensorDataset.\n",
    "dataset = TensorDataset(input_ids, attention_masks, labels)\n",
    "\n",
    "# Create a 90-10 train-validation split.\n",
    "\n",
    "# Calculate the number of samples to include in each set.\n",
    "train_size = int(0.9 * len(dataset))\n",
    "val_size = len(dataset) - train_size\n",
    "\n",
    "# Divide the dataset by randomly selecting samples.\n",
    "train_dataset, val_dataset = random_split(dataset, [train_size, val_size])\n",
    "\n",
    "print('{:>5,} training samples'.format(train_size))\n",
    "print('{:>5,} validation samples'.format(val_size))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "id": "LHf1KGY_GvSj"
   },
   "outputs": [],
   "source": [
    "# The DataLoader needs to know our batch size for training, so we specify it \n",
    "# here. For fine-tuning BERT on a specific task, the authors recommend a batch \n",
    "# size of 16 or 32.\n",
    "batch_size = 8\n",
    "\n",
    "# Create the DataLoaders for our training and validation sets.\n",
    "# We'll take training samples in random order. \n",
    "train_dataloader = DataLoader(\n",
    "            train_dataset,  # The training samples.\n",
    "            sampler = RandomSampler(train_dataset), # Select batches randomly\n",
    "            batch_size = batch_size # Trains with this batch size.\n",
    "        )\n",
    "\n",
    "# For validation the order doesn't matter, so we'll just read them sequentially.\n",
    "validation_dataloader = DataLoader(\n",
    "            val_dataset, # The validation samples.\n",
    "            sampler = SequentialSampler(val_dataset), # Pull out batches sequentially.\n",
    "            batch_size = batch_size # Evaluate with this batch size\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000,
     "referenced_widgets": [
      "73f18bedea76480fb9981b5d526cbc2d",
      "5523466dab5342c1976c15d4495362a0",
      "e5186ba30dbd4973a6983d88ba06ee17",
      "7b11996e92974efaaa6db91f5ac2e59f",
      "2d24a0780c6e46e3b5d2c348c788d383",
      "cf76c66b89b749e4a79a179e56bd8b78",
      "13892e698d894bb7b7555e3c725f7bff",
      "7035649df34f421b936faded0d3ee5b6",
      "ef0f5c28845d44b6ada41f72ec2dd982",
      "3a643aebf84147d2baec20687a8d467e",
      "312fbca9a0d34423bf15e7bb52755bf1",
      "82a19fe3427542d38429d1b8ccaa931d",
      "ce6d4c02eb45429cb45832f86228b98e",
      "3cef259bc6c348139134a71ad635082f",
      "4d6dfec252104ceeb314babbf507bf6c",
      "6c549a6980514e7fbc05d2f3bded708a"
     ]
    },
    "id": "2Z5LPc0pG265",
    "outputId": "e3cc73dc-c3c4-42e1-8602-4d854a210917"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BertForSequenceClassification(\n",
       "  (bert): BertModel(\n",
       "    (embeddings): BertEmbeddings(\n",
       "      (word_embeddings): Embedding(30522, 768, padding_idx=0)\n",
       "      (position_embeddings): Embedding(512, 768)\n",
       "      (token_type_embeddings): Embedding(2, 768)\n",
       "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (encoder): BertEncoder(\n",
       "      (layer): ModuleList(\n",
       "        (0): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (1): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (2): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (3): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (4): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (5): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (6): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (7): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (8): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (9): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (10): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (11): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (pooler): BertPooler(\n",
       "      (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "      (activation): Tanh()\n",
       "    )\n",
       "  )\n",
       "  (dropout): Dropout(p=0.1, inplace=False)\n",
       "  (classifier): Linear(in_features=768, out_features=2, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logging.set_verbosity_error() # set to warning to show warnings\n",
    "\n",
    "# Load BertForSequenceClassification, the pretrained BERT model with a single \n",
    "# linear classification layer on top. \n",
    "model = BertForSequenceClassification.from_pretrained(\n",
    "    \"bert-base-uncased\", # Use the 12-layer BERT model, with an uncased vocab.\n",
    "    num_labels = 2, # The number of output labels--2 for binary classification.\n",
    "                    # You can increase this for multi-class tasks.   \n",
    "    output_attentions = False, # Whether the model returns attentions weights.\n",
    "    output_hidden_states = False, # Whether the model returns all hidden-states.\n",
    ")\n",
    "\n",
    "# Tell pytorch to run this model on the GPU.\n",
    "model.cuda()\n",
    "#model.cpu()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "id": "AksknLguH3My"
   },
   "outputs": [],
   "source": [
    "# Note: AdamW is a class from the huggingface library (as opposed to pytorch) \n",
    "# I believe the 'W' stands for 'Weight Decay fix\"\n",
    "optimizer = AdamW(model.parameters(),\n",
    "                  lr = 2e-5, # args.learning_rate - default is 5e-5, our notebook had 2e-5\n",
    "                  eps = 1e-8 # args.adam_epsilon  - default is 1e-8.\n",
    "                )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "id": "ioeJ5LI8H5QS"
   },
   "outputs": [],
   "source": [
    "# Number of training epochs. The BERT authors recommend between 2 and 4. \n",
    "# We chose to run for 4, but we'll see later that this may be over-fitting the\n",
    "# training data.\n",
    "epochs = 2\n",
    "\n",
    "# Total number of training steps is [number of batches] x [number of epochs]. \n",
    "# (Note that this is not the same as the number of training samples).\n",
    "total_steps = len(train_dataloader) * epochs\n",
    "\n",
    "# Create the learning rate scheduler.\n",
    "scheduler = get_linear_schedule_with_warmup(optimizer, \n",
    "                                            num_warmup_steps = 0, # Default value in run_glue.py\n",
    "                                            num_training_steps = total_steps)\n",
    "\n",
    "# Defining loss function\n",
    "loss_fn = nn.CrossEntropyLoss().to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def format_time(elapsed):\n",
    "    '''\n",
    "    Takes a time in seconds and returns a string hh:mm:ss\n",
    "    '''\n",
    "    # Round to the nearest second.\n",
    "    elapsed_rounded = int(round((elapsed)))\n",
    "    \n",
    "    # Format as hh:mm:ss\n",
    "    return str(datetime.timedelta(seconds=elapsed_rounded))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining training epoch of BERT model\n",
    "def train_epoch(\n",
    "  model, \n",
    "  data_loader, \n",
    "  loss_fn, \n",
    "  optimizer, \n",
    "  device, \n",
    "  scheduler, \n",
    "  n_examples\n",
    "):\n",
    "    \n",
    "  # Measure how long the training epoch takes.\n",
    "  t0 = time.time()\n",
    "    \n",
    "  # Put the model into training mode\n",
    "  model = model.train()\n",
    "\n",
    "  losses = []\n",
    "  correct_predictions = 0\n",
    "  \n",
    "  # For each batch of training data...\n",
    "  for step, batch in enumerate(data_loader):\n",
    "    \n",
    "    # Progress update every few batches.\n",
    "    if step % 200 == 0 and not step == 0:\n",
    "        # Calculate elapsed time in minutes.\n",
    "        elapsed = format_time(time.time() - t0)\n",
    "              \n",
    "        # Report progress.\n",
    "        print('  Batch {:>5,}  of  {:>5,}.    Elapsed: {:}.'.format(step, len(data_loader), elapsed))\n",
    "    \n",
    "    # Unpack this training batch from our dataloader. \n",
    "    # As we unpack the batch, we'll also copy each tensor to the GPU using the `to` method.\n",
    "    input_ids = batch[0].to(device)\n",
    "    attention_mask = batch[1].to(device)\n",
    "    targets = batch[2].type(torch.LongTensor).to(device)\n",
    "    \n",
    "    outputs = model(\n",
    "      input_ids=input_ids,\n",
    "      attention_mask=attention_mask\n",
    "    )\n",
    "\n",
    "    _, preds = torch.max(outputs[0], dim=1)\n",
    "    loss = loss_fn(outputs[0], targets)\n",
    "\n",
    "    correct_predictions += torch.sum(preds == targets)\n",
    "    \n",
    "    # Accumulate the training loss over all of the batches so that we can calculate the average loss at the end\n",
    "    losses.append(loss.item())\n",
    "\n",
    "    # Perform a backward pass to calculate the gradients.\n",
    "    loss.backward()\n",
    "    \n",
    "    # Clip the norm of the gradients to 1.0.\n",
    "    # This is to help prevent the \"exploding gradients\" problem.\n",
    "    nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)\n",
    "    \n",
    "    # Update parameters and take a step using the computed gradient.\n",
    "    optimizer.step()\n",
    "    \n",
    "    # Update the learning rate.\n",
    "    scheduler.step()\n",
    "    optimizer.zero_grad()\n",
    "\n",
    "  return correct_predictions.double() / n_examples, np.mean(losses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def eval_model(model, data_loader, loss_fn, device, n_examples):\n",
    "  # Put the model in evaluation mode--the dropout layers behave differently during evaluation.\n",
    "  model = model.eval()\n",
    "\n",
    "  losses = []\n",
    "  correct_predictions = 0\n",
    "\n",
    "  # Tell pytorch not to bother with constructing the compute graph during the forward pass, since this is only needed for backprop (training).\n",
    "  with torch.no_grad():\n",
    "    for batch in data_loader:\n",
    "        \n",
    "      # Unpack this validation batch from our dataloader. \n",
    "      # As we unpack the batch, we'll also copy each tensor to the GPU using the `to` method.\n",
    "      input_ids = batch[0].to(device)\n",
    "      attention_mask = batch[1].to(device)\n",
    "      targets = batch[2].type(torch.LongTensor).to(device)\n",
    "\n",
    "      outputs = model(\n",
    "        input_ids=input_ids,\n",
    "        attention_mask=attention_mask\n",
    "      )\n",
    "      _, preds = torch.max(outputs[0], dim=1)\n",
    "\n",
    "      loss = loss_fn(outputs[0], targets)\n",
    "\n",
    "      correct_predictions += torch.sum(preds == targets)\n",
    "    \n",
    "      # Accumulate the validation loss\n",
    "      losses.append(loss.item())\n",
    "\n",
    "  return correct_predictions.double() / n_examples, np.mean(losses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 139 ms, sys: 84 ms, total: 223 ms\n",
      "Wall time: 222 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "history = defaultdict(list)\n",
    "best_accuracy = 0\n",
    "\n",
    "if pretrained:\n",
    "    model.load_state_dict(torch.load('bert_male_notoxic_state.bin'))\n",
    "    model = model.to(device)\n",
    "else:\n",
    "    # Performing training and validation for each epoch\n",
    "    # Report loss and accuracy\n",
    "    for epoch in range(epochs):\n",
    "\n",
    "        print(f'Epoch {epoch + 1}/{epochs}')\n",
    "        print('-' * 10)\n",
    "\n",
    "        train_acc, train_loss = train_epoch(\n",
    "        model,\n",
    "        train_dataloader,    \n",
    "        loss_fn, \n",
    "        optimizer, \n",
    "        device, \n",
    "        scheduler, \n",
    "        train_size\n",
    "        )\n",
    "\n",
    "        print(f'Train loss {train_loss} accuracy {train_acc}')\n",
    "\n",
    "        val_acc, val_loss = eval_model(\n",
    "        model,\n",
    "        validation_dataloader,\n",
    "        loss_fn, \n",
    "        device, \n",
    "        val_size\n",
    "        )\n",
    "\n",
    "        print(f'Val   loss {val_loss} accuracy {val_acc}')\n",
    "        print()\n",
    "\n",
    "        history['train_acc'].append(train_acc)\n",
    "        history['train_loss'].append(train_loss)\n",
    "        history['val_acc'].append(val_acc)\n",
    "        history['val_loss'].append(val_loss)\n",
    "\n",
    "        # Save the model if it has the best accuracy so far\n",
    "        if val_acc > best_accuracy:\n",
    "            torch.save(model.state_dict(), 'bert_male_notoxic_state.bin')\n",
    "            best_accuracy = val_acc\n",
    "\n",
    "    # Plot the performance of the model over all epochs\n",
    "    plt.figure(0)\n",
    "    plt.plot(history['train_acc'], label='train accuracy')\n",
    "    plt.plot(history['val_acc'], label='validation accuracy')\n",
    "\n",
    "    plt.title('Training history')\n",
    "    plt.ylabel('Accuracy')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.legend()\n",
    "    plt.ylim([0, 1]);\n",
    "    \n",
    "    plt.figure(1)\n",
    "    plt.plot(history['train_loss'], label='train loss')\n",
    "    plt.plot(history['val_loss'], label='validation loss')\n",
    "\n",
    "    plt.title('Training history')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.legend()\n",
    "    plt.ylim([0, 1]);\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 835
    },
    "id": "PCXAxB6tIXY5",
    "outputId": "989a2a82-18af-461e-d910-a7ca561c1bdf"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using male toxic test data without offensive words\n",
      "Number of test sentences: 8,744\n",
      "\n",
      "Predicting labels for 8,744 test sentences...\n",
      "    DONE.\n",
      "Total F1: 0.895\n",
      "Accuracy: 0.81\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXwAAAEGCAYAAABmXi5tAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjMuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8vihELAAAACXBIWXMAAAsTAAALEwEAmpwYAAAqbklEQVR4nO3deZyN5f/H8ddnFmbsxpYtlJDsu5ClSEXZlyhJadfuV5FE0kKbJC0i4pvKklbRZimyi1IqlH03zH7m+v1xjjGYGYM5s5338/HwcO7luq/rHrfPXOe67+tzm3MOERHJ/YKyugEiIpI5FPBFRAKEAr6ISIBQwBcRCRAK+CIiASIkqxuQmpgE9PiQiMhZCgvBUtumHr6ISIBQwBcRCRAK+CIiAUIBX0QkQCjgi4gECAV8EZEAoYAvIhIgFPBFRAKEAr6ISIBQwBcRCRAK+CIiAUIBX0QkQCjgi4gECAV8EZEAoYAvIhIgFPBFRAKEAr6ISIBQwBcRCRAK+CIiAUIBX0QkQCjgi4gECAV8EZEAoYAvIhIgFPBFRAKEAr6ISIBQwBcRCRAK+CIiAUIBX0QkQCjgi4gECAV8EZEAoYAvIhIgFPBFRAKEAr6ISIBQwBcRCRAK+CIiAUIBX0QkQCjgi4gECAV8EZEAEZLVDZCTHTp0kIG33gLAvn37CAoOIqJoBAAf/O8jQvPkOe86BtxyE1FRx5gxcxYAG35dz0tjXuDdyVPP+9iSu9WteSmXXFIlafnlceMpW7Zcivs2aVCXn1esPq/6nnziMVasWE7BAgWxoCCeGDqM2nXqntcxA5kCfjZTpEhRZs6aC8CE8ePIly8f/foPSNqekJBASMj5/7Md2H+AxYt+oHmLlud9LAkcefOGJV2fmeWhhwfT9ur2LF2ymJFPD+Pj2fMytf7cRAE/B3jyiccoVLgwv/+2kUurX0b+/PlP+kXQ5YYOjHvjTcqWLcdn8+YyfdpUEuLjqVGrNkOefIrg4ODTjtnv1gG8/eaE0wK+x+Ph1ZfHsGL5cuLi4+jZuw/de/QiMTGR0c+MYMWKXyhbrhwuMZFOnbvS9ur2mfIzkOwp6tgx7r/vbo4cOUJCQgL3Drqf1m2uOmmfvXv3MPjhBzl29CgJHg9Dhw2nXv0GLF2ymAnjxxEXF0f58uUZ8cxo8uXPn2pd9Rs05N9t2wB4f/J7zJn9CQBdunaj7823EBUVxeCHH2D3rl14EhMZeOfdtL/mWv+dfA6kgJ9DbN26hbfenUxwcDATxo9LcZ+///qLr7/8kinTZhAaGsqoEcP54rN5dLyh02n71q5dh28XfMPyZT+TP9l/stmffEyBAgWZPvMT4uLi6Ne3F00vb8ZvGzawY8d2PpkzjwP799Pp+mvp1Lmrn85WsqvY2Bh6dLkBgDLlyjHmpVd5+bXxFChQgIMHD3BT7560an0lZpZU5ovPP+PyZs25/Y678Hg8xMREc/DgAd6eOIGJ77xHvnz5mPTOW7w/5T3uvPveVOv+4ftvqXxJFTZu+JW5c2YxbcZMcI4+vXtQv2Ejtv/7LyVKlOT1CW8BEBkZ6d8fRg6kgJ9DtGvXPsWeenLLfv6J3zb+Sp+e3QCIiY0holixVPe//Y67eHviBB546JGkdT8tXcIff2xiwfyvAYg8Gsm2rVtZvWolba9uT1BQEMVLlKBho8YZcFaS05w6pBMfH89rr7zEqpW/EGRB7Nmzm/379lG8RImkfWrUqMlTQ58gISGB1m2uotqll7Lil+/4+6/N3NK3d9JxatWpk2KdL419gbcnTqBoRATDR45i+c8/0ebKq8iXLx8AV17VllUrV9CseQvGjnmel8e+SMtWralXv4H/fhA5lAJ+DhEeHp70OTg4mMTExKTluNhYAByOjjd05v4HH07XMRs3acob415l3dq1Seucczz2xFCaNW9x0r6Lfvz+PFovudUXn83j4MEDzJg5i9DQUK5p24bYuNiT9qnfoCGT3p/Goh9+YMjjg7ml/wAKFipEk6bNeH7MS2es4/gY/nHLflqa4n4VK1bifzNnsWjRD7z68liaXt4szW8MgUiPZeZAZcqW5bffNgLw28YNbN/+HwCNGzdlwfyv2b9/PwCHDx1ix47taR7rtjvuYvKkd5KWL2/WnI8+nEF8fDwAW7b8Q1RUFHXr1WfBN/NJTExk/759rFi+3B+nJjnM0aORREQUIzQ0lOXLfk7xetuxYzsREcXo2r0Hnbt05beNG6hVuw5rVq9i29atAERHR7Nlyz/pqrN+g4Z89+0CoqOjiYqK4tuFC6hXvwF79uwmLDycDh1voF//Afzu+z8iJ6iHnwNd1fZq5n06lx5dbuCyGjWpULEiABdXrsw9gx7grttvJdElEhISyhNDh1GmTNlUj9XiipYUjYhIWu7SrTs7dmynV/cuOOcoWrQor4x7g6vaXs2yn3+i6w0dqFCxIjVr1aJAwYL+PlXJ5q7t0JFB99xF7x5dqFrtUipddNFp+6xYvpzJ771LSEgI+fLl45nRzxMREcGIUaN57NGHiIuPA+De+x6gYsVKZ6zz0uqXcf0NXejTqzvgvWl76aXVWbJ4ES+PfYEgCyIkJIQhw4Zn6LnmBuacy+o2pCgmgezZsAAWdewY+fLn59Chg/Tp1Z0pU2ecNFYrIlkvLARLbZt6+JJu991zJ5FHjhAfH8/AO+5WsBfJYdTDFxHJRdLq4eumrYhIgFDAz+WWLPqR66+7mg7t2/Lu229ldXNETqLrM3Mp4OdiHo+HZ0eN4I0332H2p5/z1Ref8dfmzVndLBFA12dW8GvAN7P8ZhaUbDnIzPL5s0454df16yhfvgLlypcnNE8e2l97Hd9/tzCrmyUC6PrMCv7u4S8Ekgf4fMACP9cpPnt27+aC0hckLZcsVYrdu3dnYYtETtD1mfn8HfDDnHNHjy/4PqfawzezgWa2wsxWaDzv/LkUHnRKntRKJCvp+sx8/n4O/5iZ1XPOrQIws/pAdGo7O+feAt4CPZaZEUqVuoBdO3clLe/ZvZuSJUtmYYtETtD1mfn83cN/APjIzBaZ2SLgQ0DZjDLJZTVqsm3bFv7771/i4+L46ovPadm6TVY3SwTQ9ZkV/NrDd879YmbVgKqAAb875+L9WaecEBISwuNDhnHXwNtITPTQqXNXKle+JKubJQLo+swKfplpa2ZtnHPfmlmXlLY752ad6Rga0hEROXtZkUunJfAt0DGFbQ44Y8AXEZGMpVw6IiK5SJbl0jGzqWZWONlyBTPTzIrzcKap6M45nnv2GTq0b0u3zh35beOGM5Z9eeyLdOvckSGPD05aN+/TOXwwdYp/T0ZyFV2b2Z+/n9JZDCwzs2vN7HbgG+AVP9eZa6VnKvriRT+ybesW5n05n2HDR/LMiOFplo2MjGTtmtV8PHseiR4Pf/6xiZiYGD6dM5sevW7M/JOUHEnXZs7g14DvnJsI3AbMBUYAVzjn5vmzztwsPVPRv/t2IR2v74SZUat2HSIjj7B3755UywYFGfHx8TjniImNJSQkhMmT3uHGvjcRGhqaRWcqOY2uzZzB30M6NwGTgJuBycAXZlbbn3XmZumZir5nz25KXXBin1KlLmDP7t2pls2fvwBXtW1Hz66dKFu2HAUKFmTDr7/Sus1V/j8hyTV0beYM/p5p2xVo7pzbA8wws9l4A39dP9ebK6VrKnoKN+HNLM2y/QfcTv8BtwMwfNgQ7r5vELM+/oifli7mkipVGXjn3RnQesnNdG3mDP4e0ukEHDKzGmZWA1gNNPZnnblZeqailyx1Abt3ndhn9+5dlChZMl1lf/ttIwAVKlRk3qdzePGlV9m8+U+2bt3ih7OR3ETXZs7g7yGdlsCfwHjgDeAPoIk/68zN0jMVvVXrNsz7dA7OOdatXUOBAgUpUaJkusqOH/cqd987iISEBBI9HgCCLIiY6JhMO0fJmXRt5gz+HtJ5CWjnnNsEYGZVgBlAfT/XmyulNhV95oczAOjRszctrmjJ4h9/oMM1bQkLC2fEM8+mWfa4bxcuoEaNmpQsWQqAWnXq0rVTR6pUqULVatUy/2QlR9G1mTP4deKVma1zztU607qUaOKViMjZy4rUCsetMLN3gam+5T7ASj/XKSIiKfB3Dz8vcA/QHG+2zB+B8c65uDOVVQ9fROTspdXD93fAv9859+qZ1qVEAV9E5OxlWS4doF8K627xc50iIpICv4zhm1lv4Eagkpl9mmxTQWC/P+oUEZG0+eum7VJgJ1AcGJtsfSSwzk91iohIGpQPX0QkF8nKfPhdzOxPMztsZkfMLNLMjvizThERSZm/n9LZDHR0zv12tmXVwxcROXtZ+ZTO7nMJ9iIikvEyY6bth8AcIPb4SuecXmIuIpLJ/B3wCwFRQLtk6xyggC8iksn0lI6ISC6SlU/plDOz2Wa2x8x2m9knZlbOn3WKiEjKUh3SMbN6aRV0zq1Kx/HfA6YD3X3LfX3r2qa3gSIikjFSHdIxs+/SKOecc23S2H78GGucc3XOtC4lGtIRETl755QP3znXOgPq3mdmffG+5QqgN8qlIyKSJc44hm9m+cxsqJm95Vu+xMw6pPP4twI9gF14c+t0860TEZFMdsandHzP0a8EbnbO1TCzcOCn9AzLnA8N6YiInL3zfcXhxc65nr6Uxzjnos0s1QMCmNmwNDY759zIdNQrIiIZKD0BP87Xq3cAZnYxyWbNpuJYCuvyAwOAYoACvohIJkvPkE5bYChQHZgPNANucc59n64KzAoC9+MN9jOBsc65PWcqpyEdEZGzd97vtDWzYkATvC8i/9k5ty8dZSKAh4A+wBTgVefcwfQ2WgFfROTsne8YPkBLoDneYZ1QYHZaO5vZi0AX4C2gpnPuaDrrERERP0nPkM4bQGVOPEvfE/jLOXdPGmUS8Y7zJ8BJPXXDe9O20Jkaph6+iMjZO68hHTPbANRwvh3NLAhY75y7LENbeQoFfBGRs3e+ydM2ARcmWy6PXkQuIpLjpJU8bR7e4ZjCwG9mtty33BhYmjnNExGRjJLWTdsxmdYKERHxO70ARUQkFzmvMXwza2Jmv5jZUTOLMzOPmR3J2CaKiIi/peem7et40xr/CYQDt/nWiYhIDpKuiVfOuc1mFuyc8wDvmZlu2oqI5DDpCfhRZpYHWGNmL+DNa5/fv80SEZGMlp4hnZt8+92LNwtmebxpE0REJAc5p6d0zOxD51xPP7QniZ7SERE5e+c70zYlTc+xnIiIZJFzDfgiIpLDpJVaoV5qm/CmSParddsO+7sKkXPSsuuQrG6CSKqiV6f+1HxaT+mMTWPb7+fcGhERyRKpBnznXOvMbIiIiPiXxvBFRAKEAr6ISIBQwBcRCRDpyZZpZtbXzIb5li80s0b+b5qIiGSk9PTw38A70aq3bzkSGO+3FomIiF+kJ3laY+dcPTNbDeCcO+hLpiYiIjlIenr48WYWjPd9tphZCSDRr60SEZEMl56A/xowGyhpZqOAxcCzfm2ViIhkuDMO6TjnPjCzlcCVeNMqdHLO/eb3lomISIY6Y8A3swuBKGBe8nXOuW3+bJiIiGSs9Ny0/Rzv+L0BYUAlYBNwmR/bJSIiGSw9Qzo1ky/7smje4bcWiYiIX5z1TFvn3CqgoR/aIiIifpSeMfyHki0GAfWAvX5rkYiI+EV6xvALJvucgHdM/xP/NEdERPwlzYDvm3BVwDn3aCa1R0RE/CTVMXwzC3HOefAO4YiISA6XVg9/Od5gv8bMPgU+Ao4d3+icm+XntomISAZKzxh+BLAfaMOJ5/EdoIAvIpKDpBXwS/qe0PmVE4H+OOfXVomISIZLK+AHAwU4OdAfp4AvIpLDpBXwdzrnRmRaS0RExK/SmmmbUs9eRERyqLQC/pWZ1goREfG7VAO+c+5AZjZERET866yTp4mISM6kgC8iEiAU8EVEAoQCvohIgFDAFxEJEAr4IiIBQgFfRCRAKOCLiAQIBXwRkQChgC8iEiAU8EVEAkR63nglmeTm65pQvuLFScsPDHuREqXKpLjvbZ1b8s7sH86rvoljn2bD6uWMnTSb0Dx5iDx8iGGD+vHylLnndVzJ3SIK5+eLifcBUKpYIRITE9l78CgALfq+SHyC57zr+Prt+7mgeCFi4uI5FhXLHcM/4M+te877uIFOAT8byZMnL6PGf5CpdQYFBfHD/E+5qkO3TK1Xcq4Dh4/RpNdzAAy541qORcXyytSFSduDg4PweBLPu57+Q6awauM2bu3SjGcf7Ez3Byae9zEDnQJ+NhYTHcXLTz/CsaOReDwJdLv5Tuo3bXnSPocO7OP10U8QHXUMj8dD/3v/j6o16rJ+5c/MmvYW8fHxlCxdloEPDSMsPN9pdVzdqRdfz5lB62s6nbbt84+nsuzHBSTEx1P/8lZ0vWkgAHOmv8vS774iokQpChYqQsXK1biuW1+//AwkZ3jr6b4cPBJF7arlWPP7v0Qeiz3pF8GKj56gy6A32bbzAL2ubcg9vVsSGhrCL+u3cP/oD0lMTP0leotXbebePq0AePaBTrRrVh3n4Pl3vuLj+au4oHghpj5/KwXzhxESHMT9z37IktV/ZcZp5zgK+NlIXFwsQ+7pA0CJUmW4b8hoHnjyBcLzFyDy8CGGP3gr9ZpcgdmJd9Ms/e5ratZrwg29byXR4yE2NobIw4eY+79J/N/o8YSFhfPZzCl8OWs6nfvcdlqdxUpcQJXqdViy8EvqNm6RtH79yp/Ztf1fnn51Ms45Xn76YX5fv4o8ecP4Zcm3PPP6VDweD0/edzMVK1fz/w9Hsr3KF5bk2jvHkZjoGHLHtSnuU7VSKbq1q0fr/i+RkJDIK4/3oNe1DZn+2fJUj3vdFTXY8OcOOl1Zh1pVy9Go52iKFynA4mmPsnjVZnpe04Bvlv7GC+9+TVCQkS8sj79OMcdTwM9GTh3SSUhIYOaUCWxavxoLMg7u38vhg/spElE8aZ+LqlzK2y8/g8eTQP2mrahwcRVWL1vE9m3/MPJhb4BPiE+g8qU1Uq33+l638NLwR6jdqFnSuvWrlvHrqmUMvdfbc4+JjmbXjn+JiYqiXpOW5MkbBkDdxs0z9GcgOdesBavT7KkDtG5UlXrVL2TxtMEAhOcNZe+Boynu+96ofkTHxrNtx34eev4jBvVtw8yvVpCY6NhzIJJFKzdT/7IKrNiwlYlP9SU0JJh5361l3R/bM/zccgsF/Gxs6XdfEXn4ICPGvU9ISAgP9ruB+Pi4k/apVrMeQ1+cyJrlS3hzzFNc17Uv+QoUokbdxtzz2DPpqqdUmfJUuPgSlv+4INlaR8ee/WhzbZeT9v1y9vTzPS3JpaKiY5M+J3g8BAWd+CYalicUADNj2rxlDBv36RmPd3wM/7jk32yTW7LqL9re9grtm1/Gu8/04+X3F6T5jSGQ6bHMbCz62FEKFS5KSEgIG9euYN+enafts2/3TgoVKUrrazrRst31bNm8icrVavDnxrXs3vEvALExMez8b2uadV3fqz9ffHLi20XNek34Yf48YqKjADiwbw+HDx2gavU6rF62iLi4WGKio1izfEkGnrHkFlt3HKDOpeUBqFOtHBXLFgPgu+Wb6HxVHUoULQBA0UL5uLB00XQdc/GqzXRrV5+gIKN40QI0r1+ZFb9u4cLSRdlzIJL3Zi9lypyl1K1W3j8nlQuoh5+NXd66PS8Nf4hhg27mwouqUKZ8xdP2+W3dSj7/ZBohwSHkDQ/njkeGU6hIUW5/aBjjnxtKQnw8AN363UnpchVSratchYupWLkqWzZvAqBm/Sbs+HcLTz80AICwsHDufHQEF1WtTr0mLRhydx+KlyxNpUsuJV/+Ahl/8pKjzVm4hj4dGvHz/x5j5YatSY9U/v73Lp4e/xnzJtxLkBnxCR4efG4m23YePOMx5367lsa1KrH8w8dxDoa8Mofd+yPp07ExD958JfEJHo5FxTLgyan+Pr0cy5xLe8wtqyz/+3D2bJgQEx1FWHg+YmNiGDV4ILcOeiKgbty27Dokq5sgkqro1a+nPPaFevhyDia99izbt/1DfFwcza+6LqCCvUhOpoAvZ+3u/0vfzWARyV4U8HOot18ayerliylUpCjPvfm/pPXz537IN/M+Ijg4mNqNmtF7wCAAtv3zJ++9NproqGNYUBBPvzqZPHny8sLQQRw6sI9Ej4eqNerQ7+7BBAUHZ9VpSS5wSYWSTH3+1qTlSmWLMXLC53zw2XKmPn8rFcpEsHXHAfoOfpdDkdGEhAQxYVgf6lQrT0hwEB98vpwxk+YDMPyejvTp0IgihfJRotnDWXVKuYYCfg7Vou11tL2+O2+OGZ60buPaFaz6+UeefWM6oXnycPjQAQA8ngTefOEp7nh0OBUuqkLkkUOEBHv/6e97/FnC8xfAOcdrox5j2aKFNG3VLitOSXKJP7fuSUq9EBRk/PX1KD79bi2P9G/L98s3Mea9b3ikf1se6d+Ooa/NpetV9cibJ4SGPZ4lPCyU1Z8MZeaXK9i28wBf/LieNz/8gfVzn8ris8od9FhmDlWtZj3yFyx00rqFn39Chx79CM3jnWlYuEgEAOtXLqN8pcpUuKgKAAULFUnqxYf7nrDxeDwkxMen+qyzyLlo3agq//y3l207D9KhVS2mzVsGwLR5y+jYuhYADke+sDwEBwcRnjcPcfEeIo/FALB8/RZ27TuSZe3PbfzWwzeze4APnHOHfMtFgd7OuTf8VWeg27V9G5t+XcNHUyYQGpqHG2+7n4uqVmfX9m2YGS8MuY8jhw/RpGVbOnS/OancC0Pu468/NlK7QVMaNW+ThWcguU33q+sz86uVAJQsVjApeO/ad4QSEQUB7wzdDq1q8c83o8gXlofBY2Zx8EhUlrU5N/NnD//248EewDl3ELg9rQJmNtDMVpjZitkzJvuxabmTx+Ph2NEjDH95Er1vG8S40Y/jnMPj8bBpwxruGjySJ8e8zcql37Nh9YmZiINHjWPcB18QHx/PhrUrsvAMJDcJDQnmupY1mfXN6jT3a3hZRTyeRC5qN4RLr3uK+29qkzRRSzKWPwN+kCUbHzCzYCDNrEbOubeccw2ccw06977Fj03LnSKKl6Rhs9aYGRdXvYwgCyLy8CEiipekWs16FCxchLxhYdRu2Iwtf206qWyePHmp17gFq37+MYtaL7nN1c2rs+b3f9lzIBKAPfsjuaC4dxjyguKF2Otb3+OaBsxfupGEBG9e/Z/W/E396hdmWbtzM38G/K+BmWZ2pZm1AWYAX/mxvoBXv2lLNq7x9tB3/reVhIR4ChYuQq36Tfj3n83ExsTg8STw+/pVlL2wEjHRURw6sA/w3thdu2IpZdKYjStyNnq0b5A0nAPw+Q/r6duxMQB9Ozbms+/XAfDfrgO0algVgHxheWhUqyKbtuzO/AYHAL/NtDWzIOAO4ErAgPnAO865dL0ORzNt0zb+uaH8tm4lR48colCRYnS56Xaat7mWt18eyda//yAkJJTetw3isjoNAVjy7ZfM+3AymFG74eX0HjCIwwf3M/aph0iIjycx0UP12g3oc8eDBAfr4a20aKbtmYWHhfLnl89QveNTHDnqvQEbUTg/056/lfKli/LvzoP0GfwuB49EkT88D2893ZdqF5XGDKbO/ZmX3/fm0R91/w30vKYBpUsUZufew7w3+ydGTfwiK08t20trpq1SK4icJQV8yc4yNbWCmc10zvUws/XAaUHbOVcro+sUEZEz88d39/t9f3fww7FFROQcZXjAd84dT9qe3zm3Mfk2M2sFpJ2YXURE/MKfd+dmmtlU4AUgzPd3A6CpH+vMdVLKmbP17z+YPO45YmKiKV6yNHcPHpE0Yza5dSt+YuqbY0lMTKRV+xvo2KMfADPeeY3VyxYREhJKydJluf2hYeQvUJA/Nqxl8uvPExIayj2PPUOpMuU5djSS8aOf4NFnXtMsXDnNfX1ac0vny3HOsWHzDgY+NY18YXlSzJlzqnt6t6J/l8sxM96btYTXp38PQK0qZRk3pBd584aS4EnkgWc/ZMWGrTStfRGvPtGTuPgEbn78Pf7+dx+FC4Qz9flbuf6e8Zl85jmTPx/LbAyUB5YCvwA7gGZplpDTtGh7HYOfefWkde++Mooe/e9l9IQZNLi8FZ9/Mu20cokeD1PGv8CjI1/l+Ykf8tP3X7N9698A1KjbiNFvzuDZCdO5oOyF3qd3gC9nfcCgoc/R/Za7Wfj5JwDMnfEuHXv2V7CX05QpUZi7e7ekWZ8XaND9WYKDguh+df2knDk1bxjB98s38Uj/03MzVb+4NP27XE6Lm16kUc/RXHNFDS6+sAQAox7oxKi3vqRJr+cYOeEzRj3QCYD7b2pD70ffYdi4eQzs3gKAxwe254VJX2faOed0/gz48UA0EI63h/+Pcy7Rj/XlSinlzNn53zaq1awLQI16jfll8Xenlfvrjw2UKlOOkqXLEhIaSpOW7Vjpm1RVs36TpEcvK1erwYF93rcRBYeEEBcXS1xsDMHBIeze8R8H9u3l0lr1/HmKkoOFBAcTnjfUmwcnLA879x5ONWdOctUqXcDy9VuIjonH40lk0crN3NC6NgDOQaH8YQAULhDOzr2HAYhP8BCeN5R84aHEJ3ioVK44ZUoWYfHKzZl0tjmfP4d0fgHmAg2BYsBEM+vmnOvmxzoDQrmKF7Hq5x+p37Qlyxct4MC+0yepHNy3l4gSpZKWI4qX5K9NG07b74f582jSsi0AHXvcwqRXR5Mnb17ufGQ40995jW433+G/E5Ecbcfew7zy/kL++HIk0bFxLPzpdxb+/HuqOXOS2/DXDobf25GIwvmJjo2jffPLkl5Y/uiYj5k3/h5GP9iZoCCj9S1jAXhx0nzGD+1NdGw8A4a+z+iHOvP0G59l3gnnAv4M+AOcc8cTs+wCbjCzm/xYX8C4/cEnmTphLHOmv0vdJi0ICTn9n9Gd/kQspw7KzJ0xieDgYC5v3R6AChdXYfgrkwD4ff0qihYrjnOO10c/QXBwCDfefj+FiyrHiXgVKRhOh1Y1ubTDUxyKjGL6CwPodW3DdJXd9M9uxk7+hs8m3Mux6FjW/bGdhATvnMyB3VsweOws5ixcQ9e2dZnwVB+uu/N11v2xnZb9vMG/Wb2L2bn3MIYx9bn+xCd4eOyl2UlpHCRl/hzSWWtmg8zsY9+fe4H/nbGUnFGZ8hX5v2fHMXLc+zRt2Y6Spcudtk9E8ZIc2Hui539g3x6KFCuRtLzom89Ys3wxdw0eedr4vHOOuTPeo1PvAcz+4B269B1IszbXMH/uh/47Kclx2jSuxpYd+9l38CgJCYnM+XYtTWpXSjVnzqmmzPmJy298nrYDXuHg4WNs3rYXgD4dGjNn4RoAPvlmNQ0uOz3dx2O3tWf0W18y5I5rGPnmF8z44hfu7t3KL+eZm/gz4E8A6gNv+P4c/yzn6fiLTRITE5n7v0m0ubbLaftcVKU6u3b8y55d20mIj+fnH+ZTr4n3Rte6FT/x2UdTefCpseQNCzut7KIFn1OnUTPyFyxEXGwMZoaZERsb498Tkxzl310HaFSzEuFhoYA39/2mf3anmjPnVCWKep8sK39BUW5oU5uZX/nyQO09TIv6lwDQqlGVpF8Ex/Xt2JivFm3gUGQ0+cLykJjoSEx05PO1Q1Lnj5m2Ic65BKChc652sk3fmtnajK4vt0ueM2dQ3w50uel2YqOjWfDZRwA0uLw1V7TrCMDB/Xt555VRPDryFYKDQ7j5rkd5ceggEj2JXNGuI+UqXAzAlDdeJCE+jueH3At4b9z2v+9xAGJjYli84HMGjxoHwDVdbuS1UY8REhLK3f83MrNPX7KxX37dyuwFq/lp+v+R4Elk7e//8e4nSyiQLy/Tnr+Vfp2aJuXMAShdojBvDLuRzvdNAGDGmNuIKJKf+AQPDzw3M+nRzXtGTufFR7sREhJEbGwC9z4zI6nO8LBQ+nZsTIe7XwfgtWnfMmPMbcTFJ9Dv8cmZ+wPIgTI8l46ZrXLO1TOzVUB359xfvvUXAR8759L1yIdy6Uh2pVw6kp1lai4dTtwbfAT4zsz+9i1XBPr7oT4REUkHfwT8Emb2kO/zRCAYOIb3Wfy6wOkPjYuIiN/5I+AHAwU4+SnA4/P+T38gV0REMoU/Av5O59wIPxxXRETOgz8ey1TSFRGRbMgfAf9KPxxTRETOU4YHfOfcgYw+poiInD9/zrQVEZFsRAFfRCRAKOCLiAQIBXwRkQChgC8iEiAU8EVEAoQCvohIgFDAFxEJEAr4IiIBQgFfRCRAKOCLiAQIBXwRkQChgC8iEiAU8EVEAoQCvohIgFDAFxEJEAr4IiIBQgFfRCRAKOCLiAQIBXwRkQChgC8iEiAU8EVEAoQCvohIgFDAFxEJEAr4IiIBQgFfRCRAKOCLiAQIBXwRkQChgC8iEiAU8EVEAoQCvohIgDDnXFa3QTKBmQ10zr2V1e0QOZWuzcyjHn7gGJjVDRBJha7NTKKALyISIBTwRUQChAJ+4NAYqWRXujYziW7aiogECPXwRUQChAK+iEiAUMDPhszMmdnYZMuPmNnwczxWRTO78TzaMsLMrjrX8hJ4zKyYma3x/dllZtuTLedJR/kyZvZxZrQ10GgMPxsysxhgJ9DQObfPzB4BCjjnhp/DsVoBjzjnOmRoI0XSwddROeqcG5PVbRH18LOrBLxPLjx46gYzq2BmC81sne/vC33rJ5vZa2a21Mz+NrNuviLPAS18vasHzSzMzN4zs/VmttrMWvvKzzWzm32f7zCzD5Idt5vvc0Pf8dea2XIzK+j/H4XkBmZ2pe96W29mk8wsr+96Wue7JvOb2QYzq+H7Vvqrr1ywmY3xlVtnZvdl9bnkZCFZ3QBJ1XhgnZm9cMr614H3nXNTzOxW4DWgk29baaA5UA34FPgYeIxkPXwzexjAOVfTzKoB882sCt7ZjkvM7B/gYaBJ8kp9X8U/BHo6534xs0JAdAafs+ROYcBk4Ern3B9m9j5wl3PuFTP7FHgGCAemOed+NbOKycoOBCoBdZ1zCWYWkcltz1XUw8+mnHNHgPeBQadsagpM932eijfAHzfHOZfonNsIlErl0M195XDO/Q5sBao453YDw4DvgIedcwdOKVcV2Omc++V4+5xzCed0chJogoF/nHN/+JanAFf4Po8A2gINgFM7NwBXAW8ev9ZSuC7lLCjgZ2+vAAOA/Gnsk/wmTGyyz5bK/qmtB6gJ7AfKpFJON3zkXBxLY1sEUAAoiPebwKl03WUgBfxszNebmYk36B+3FOjl+9wHWHyGw0Ti/c903I++cviGci4ENplZI+AaoC7wiJlVOuU4vwNlzKyhr2xBM9OQoKRHGFDRzCr7lm8CfvB9fgt4EvgAeD6FsvOBO49faxrSOT8K+NnfWKB4suVBQH8zW4f3P879Zyi/Dkjw3Wh9EHgDCDaz9XjH5G/x7fc2cKtzbgfeMfxJZpb0bcA5Fwf0BMaZ2VrgG1LukYmcKgboD3zku+4SgTd9DwkkOOem4324oKGZtTml7DvANrz3s9YC5/yIseixTBGRgKEevohIgFDAFxEJEAr4IiIBQgFfRCRAKOCLiAQIBXzJ1szM48sD9KuZfWRm+c7jWMnzAr1jZtXT2LeVmV1+DnVsMbPi6V2fyjFuMbPXM6JekeQU8CW7i3bO1XHO1QDigDuTbzSz4HM5qHPuNl8KitS0As464ItkZwr4kpMsAir7et/fmdl0YL0vo+KLZvaLL6PiHQDm9bqZbTSzz4GSxw9kZt+bWQPf5/Zmtso3OW2hL3nXncCDvm8XLcyshJl94qvjFzNr5itbzMzm+zJBTiTt1BUnMbNGvuyjq31/V022ubyZfWVmm8zsqWRl+voyla4xs4nn+gtPApOmxkuO4Jtafw3wlW9VI6CGc+4fMxsIHHbONTSzvHizfs7HmyaiKt4cQaWAjcCkU45bAu8s4yt8x4pwzh0wszdJlsfd98vlZefcYvOmpP4auBR4CljsnBthZtfhze6YXr/76k0w70tmngW6Jj8/IAr4xfcL6xje2c7NnHPxZvYG3jQZ759FnRLAFPAluws3szW+z4uAd/EOtSx3zv3jW98OqGUn3gFQGLgEb0bGGc45D7DDzL5N4fhNgB+PHyuNbIxXAdWTZZsoZN73AVwBdPGV/dzMDp7FuRUGppjZJXgThIUm2/aNc24/gJnNwpvlNAGoj/cXAHhTCu85i/okwCngS3YX7Zyrk3yFL9glz8BowH3Oua9P2e9azpxpMb3ZGIOAps65k94B4GvLueYnGQl855zr7BtG+j7ZtlOP6XxtneKce/wc65MApzF8yQ2+Bu4ys1DwZgE1s/x4M4P28o3xlwZap1D2J6Dl8eygybIxnppldD5w7/EFM6vj+5g8++g1QNGzaHdhYLvv8y2nbGtrZhFmFo73BTdLgIVANzMrebytZlbhLOqTAKeAL7nBO3jH51eZ99V4E/F+e50N/AmsByZwIiVvEufcXrzj7rN82Rg/9G2aB3Q+ftMWb5bSBr6bwhs58bTQ08AVZrYK79DStjTauc7M/vP9eQnvCz9Gm9kSvC8JSW4x3hfVrAE+cc6t8D1VNBTvW8rW4c1YWjp9PyIRZcsUEQkY6uGLiAQIBXwRkQChgC8iEiAU8EVEAoQCvohIgFDAFxEJEAr4IiIB4v8BBzsxGRHzcnMAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Evaluating test set\n",
    "\n",
    "# Initialising\n",
    "accuracies = []\n",
    "\n",
    "# Get previous test data if pretrained\n",
    "if pretrained:\n",
    "    with open(\"male_notoxic_test.data\", 'rb') as file:\n",
    "        df = pickle.load(file)\n",
    "    file.close()\n",
    "else:\n",
    "    df = male_test_data\n",
    "    with open(\"male_notoxic_test.data\", 'wb') as file:\n",
    "        pickle.dump(df,file)\n",
    "    file.close()\n",
    "    \n",
    "df = df.sample(frac=1)\n",
    "print('Using male toxic test data without offensive words')\n",
    "print('Number of test sentences: {:,}\\n'.format(df.shape[0]))\n",
    "\n",
    "# Extract necessary information\n",
    "comments = df.comment.values\n",
    "labels = df.toxicity.values\n",
    "\n",
    "# Removing offensive words from comments\n",
    "new_comments = []\n",
    "for comment in comments:\n",
    "    new_comment = clean_comment(comment)\n",
    "    new_comments.append(new_comment)\n",
    "comments = new_comments\n",
    "\n",
    "# Tokenize all of the sentences and map the tokens to their word IDs.\n",
    "input_ids = []\n",
    "attention_masks = []\n",
    "\n",
    "# For every sentence...\n",
    "for cmt in comments:\n",
    "    # `encode_plus` will:\n",
    "    #   (1) Tokenize the sentence.\n",
    "    #   (2) Prepend the `[CLS]` token to the start.\n",
    "    #   (3) Append the `[SEP]` token to the end.\n",
    "    #   (4) Map tokens to their IDs.\n",
    "    #   (5) Pad or truncate the sentence to `max_length`\n",
    "    #   (6) Create attention masks for [PAD] tokens.\n",
    "    encoded_dict = tokenizer.encode_plus(\n",
    "                        cmt,                      # Sentence to encode.\n",
    "                        add_special_tokens = True, # Add '[CLS]' and '[SEP]'\n",
    "                        max_length = MAX_LEN,           # Pad & truncate all sentences.\n",
    "                        padding='max_length',\n",
    "                        truncation=True,\n",
    "                        return_attention_mask = True,   # Construct attn. masks.\n",
    "                        return_tensors = 'pt',     # Return pytorch tensors.\n",
    "                )\n",
    "      \n",
    "    # Add the encoded sentence to the list.    \n",
    "    input_ids.append(encoded_dict['input_ids'])\n",
    "      \n",
    "    # And its attention mask (simply differentiates padding from non-padding).\n",
    "    attention_masks.append(encoded_dict['attention_mask'])\n",
    "\n",
    "# Convert the lists into tensors.\n",
    "input_ids = torch.cat(input_ids, dim=0)\n",
    "attention_masks = torch.cat(attention_masks, dim=0)\n",
    "labels = torch.tensor(labels)\n",
    "\n",
    "# Set the batch size.  \n",
    "batch_size = 8\n",
    "\n",
    "# Create the DataLoader.\n",
    "prediction_data = TensorDataset(input_ids, attention_masks, labels)\n",
    "prediction_sampler = SequentialSampler(prediction_data)\n",
    "prediction_dataloader = DataLoader(prediction_data, sampler=prediction_sampler, batch_size=batch_size)\n",
    "\n",
    "# Prediction on test set\n",
    "\n",
    "print('Predicting labels for {:,} test sentences...'.format(len(input_ids)))\n",
    "\n",
    "# Put model in evaluation mode\n",
    "model.eval()\n",
    "\n",
    "# Tracking variables \n",
    "predictions , true_labels = [], []\n",
    "\n",
    "# Predict \n",
    "for batch in prediction_dataloader:\n",
    "    # Add batch to GPU\n",
    "    batch = tuple(t.to(device) for t in batch)\n",
    "    \n",
    "    # Unpack the inputs from our dataloader\n",
    "    b_input_ids, b_input_mask, b_labels = batch\n",
    "    \n",
    "    # Telling the model not to compute or store gradients, saving memory and \n",
    "    # speeding up prediction\n",
    "    with torch.no_grad():\n",
    "        # Forward pass, calculate logit predictions\n",
    "        outputs = model(b_input_ids, token_type_ids=None, \n",
    "                        attention_mask=b_input_mask)\n",
    "\n",
    "    logits = outputs[0]\n",
    "    \n",
    "\n",
    "    # Move logits and labels to CPU\n",
    "    logits = logits.detach().cpu().numpy()\n",
    "    label_ids = b_labels.to('cpu').numpy()\n",
    "    \n",
    "    # Store predictions and true labels\n",
    "    predictions.append(logits)\n",
    "    true_labels.append(label_ids)\n",
    "\n",
    "print('    DONE.')\n",
    "  \n",
    "# Combine the results across all batches. \n",
    "flat_pred = np.concatenate(predictions, axis=0)\n",
    "# For each sample, pick the label (0 or 1) with the higher score.\n",
    "flat_predictions = np.argmax(flat_pred, axis=1).flatten()\n",
    "\n",
    "# Combine the correct labels for each batch into a single list.\n",
    "flat_true_labels = np.concatenate(true_labels, axis=0)\n",
    "\n",
    "# Return metrics\n",
    "f1 = f1_score(flat_true_labels, flat_predictions)\n",
    "print('Total F1: %.3f' % f1)\n",
    "acc = accuracy_score(flat_true_labels,flat_predictions)\n",
    "print('Accuracy: %.2f' % acc)\n",
    "accuracies.append(acc)\n",
    "\n",
    "# Print Confusion matrix\n",
    "cf_matrix = confusion_matrix(flat_true_labels, flat_predictions)\n",
    "group_names = ['True Neg','False Pos','False Neg','True Pos']\n",
    "group_counts = ['{0:0.0f}'.format(value) for value in\n",
    "                cf_matrix.flatten()]\n",
    "group_percentages = ['{0:.2%}'.format(value) for value in\n",
    "                    cf_matrix.flatten()/np.sum(cf_matrix)]\n",
    "labels = [f'{v1}\\n{v2}\\n{v3}' for v1, v2, v3 in\n",
    "        zip(group_names,group_counts,group_percentages)]\n",
    "matrix = pd.DataFrame(np.array([cf_matrix[0],cf_matrix[1]]), columns = ['Nontoxic','Toxic'], index=['Nontoxic','Toxic'])\n",
    "matrix = matrix.rename_axis(\"True Label\")\n",
    "matrix = matrix.rename_axis(\"Predicted Label\",axis=\"columns\")\n",
    "try:\n",
    "    labels = np.asarray(labels).reshape(2,2)\n",
    "    sns.heatmap(matrix, annot=labels, fmt='',cbar = False, cmap='Blues')\n",
    "    plt.show()\n",
    "except ValueError:\n",
    "    print(\"could not display\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using male toxic test data with offensive words\n",
      "Number of test sentences: 8,744\n",
      "\n",
      "Predicting labels for 8,744 test sentences...\n",
      "    DONE.\n",
      "Total F1: 0.909\n",
      "Accuracy: 0.83\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXwAAAEGCAYAAABmXi5tAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjMuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8vihELAAAACXBIWXMAAAsTAAALEwEAmpwYAAAqcklEQVR4nO3deZxO5f/H8ddnFmbGvpO1sodkTUSIJL6WZAmljUppX6SQqChpQ7QjlZStVeFXVEL2rdWSfd9mX67fH/dtDGbGMHPPdr+fj4eH+yzXcsbxmeu+zjmfY845REQk9wvI6g6IiEjmUMAXEfETCvgiIn5CAV9ExE8o4IuI+ImgrO5ASqLi0O1DIiLnKSQIS2mbRvgiIn5CAV9ExE8o4IuI+AkFfBERP6GALyLiJxTwRUT8hAK+iIifUMAXEfETCvgiIn5CAV9ExE8o4IuI+AkFfBERP6GALyLiJxTwRUT8hAK+iIifUMAXEfETCvgiIn5CAV9ExE8o4IuI+AkFfBERP6GALyLiJxTwRUT8hAK+iIifUMAXEfETCvgiIn5CAV9ExE8o4IuI+AkFfBERP6GALyLiJxTwRUT8hAK+iIifUMAXEfETCvgiIn5CAV9ExE8o4IuI+AkFfBERP6GALyLiJxTwRUT8RFBWd0BOd+TIYfrf3g+AAwcOEBAYQNEiRQH46JPPCM6TJ91t3NGvLxER4Xw84wsANqxfxysvj+HdD6amu27J3a6oXYMqVaomLo97Yzxly5ZLdt8rG1zB0hWr0tXeM089yYoVyyiQvwAWEMBTTw/l8rpXpKtOf6aAn80ULlyEGV/MAWDi+DcICwvj1tvuSNweFxdHUFD6/9kOHTzEksU/0uzqFumuS/xH3rwhiednZnn4kcdpc107fvl5Cc89O5SZs+Zlavu5iQJ+DvDMU09SsFAhNm/aSI2al5EvX77TfhF07dSBNya8Rdmy5fhy3hymT5tKXGwstepczpBnhhEYGHhWnbfefgdvvzXxrIAfHx/Pa+NeZsWyZcTExtCjV29u6t6ThIQEXhg5ghUrllO2XDlcQgKdu9xIm+vaZcrPQLKniPBwHrj/Xo4dO0ZcXBz3DXqAlq2uPW2f/fv38fgjDxF+4gRx8fE8PXQ49eo34JeflzBx/BvExMRQvnx5Rox8gbB8+VJsq36Dhvy3fTsAUz54n9mzPgeg643d6HNLPyIiInj8kQfZu2cP8QkJ9L/7Xtpd3953B58DKeDnENu2bWXyux8QGBjIxPFvJLvPv//8w3fffMOH0z4mODiYUSOG8/WX8+jYqfNZ+15+eV0W/vA9y35bSr4k/8lmfT6T/PkLMH3G58TExHBrn540uaopmzZsYNeunXw+ex6HDh6k8//a07nLjT46WsmuoqOj6N61EwAXlSvHy6+8xrjXx5M/f34OHz5E3149uKZla8wssczXX33JVU2bcdeAe4iPjycqKpLDhw/x9qSJTHrnfcLCwnjvnclM+fB97r73vhTb/vH/FlK5SlU2bljPnNlfMO3jGeAcvXt1p37DRuz87z9KlCjJmxMnA3D8+HHf/jByIAX8HKJt23bJjtST+m3pr2zauJ7ePboBEBUdRdFixVLc/64B9/D2pIk8+PCjiet+/eVn/vzzD36Y/x0Ax08cZ/u2baxa+TttrmtHQEAAxUuUoGGjxhlwVJLTnDmlExsby+uvvsLK35cTYAHs27eXgwcOULxEicR9atWqzbCnnyIuLo6Wra6leo0arFi+iH//+Zt+fXol1lOnbt1k23xl7BjenjSRIkWLMvy5USxb+iutWl9LWFgYAK2vbcPK31fQtNnVjH15NOPGvkSLa1pSr34D3/0gcigF/BwiNDQ08XNgYCAJCQmJyzHR0QA4HB07deGBhx5JU52Nr2zChDdeY+2aNYnrnHM8+dTTNG129Wn7Lv7p/9LRe8mtvv5yHocPH+LjGV8QHBzM9W1aER0Tfdo+9Rs05L0p01j8448MGfw4/W67gwIFC3Jlk6aMfvmVc7Zxcg7/pN9+/SXZ/SpVuphPZnzB4sU/8tq4sTS5qmmq3xj8kW7LzIEuKluWTZs2ArBp4wZ27twBQOPGTfhh/nccPHgQgKNHjrBr185U67pzwD188N47ictXNW3GZ59+TGxsLABbt24hIiKCK+rV54fv55OQkMDBAwdYsWyZLw5NcpgTJ45TtGgxgoODWfbb0mTPt127dlK0aDFuvKk7XbreyKaNG6hzeV1Wr1rJ9m3bAIiMjGTr1i1parN+g4YsWvgDkZGRREREsHDBD9Sr34B9+/YSEhpKh46duPW2O9js/T8ip2iEnwNd2+Y65s2dQ/eunbisVm0qVqoEwKWVKzNw0IPcc9ftJLgEgoKCeerpoVx0UdkU67q6eQuKFC2auNy1203s2rWTnjd1xTlHkSJFePWNCVzb5jp+W/orN3bqQMVKlahdpw75CxTw9aFKNte+Q0cGDbyHXt27Uq16DS6+5JKz9lmxbBkfvP8uQUFBhIWFMfKF0RQtWpQRo17gycceJiY2BoD77n+QSpUuPmebNWpexv86daV3z5sAz0XbGjVq8vOSxYwbO4YACyAoKIghQ4dn6LHmBuacy+o+JCsqjuzZMT8WER5OWL58HDlymN49b+LDqR+fNlcrIlkvJAhLaZtG+JJm9w+8m+PHjhEbG0v/Afcq2IvkMBrhi4jkIqmN8HXRVkTETyjg53I/L/6J/91wHR3ateHdtydndXdETqPzM3Mp4Odi8fHxPD9qBBPeeodZc7/i26+/5J+//87qbokAOj+zgk8DvpnlM7OAJMsBZhbmyzbllPXr1lK+fEXKlS9PcJ48tGt/A/+3aEFWd0sE0PmZFXw9wl8AJA3wYcAPPm5TvPbt3UvpMqUTl0uWKsXevXuzsEcip+j8zHy+DvghzrkTJxe8n1Mc4ZtZfzNbYWYrNJ+Xfi6ZG52SJrUSyUo6PzOfr+/DDzezes65lQBmVh+ITGln59xkYDLotsyMUKpUafbs3pO4vG/vXkqWLJmFPRI5Redn5vP1CP9B4DMzW2xmi4FPAWUzyiSX1arN9u1b2bHjP2JjYvj2669o0bJVVndLBND5mRV8OsJ3zi03s+pANcCAzc65WF+2KacEBQUxeMhQ7ul/JwkJ8XTuciOVK1fJ6m6JADo/s4JPnrQ1s1bOuYVm1jW57c65L85Vh6Z0RETOX1bk0mkBLAQ6JrPNAecM+CIikrGUS0dEJBfJslw6ZjbVzAolWa5oZnqyIh3O9Si6c44Xnx9Jh3Zt6NalI5s2bjhn2XFjX6Jbl44MGfx44rp5c2fz0dQPfXswkqvo3Mz+fH2XzhLgNzNrb2Z3Ad8Dr/q4zVwrLY+iL1n8E9u3bWXeN/MZOvw5Ro4YnmrZ48ePs2b1KmbOmkdCfDx//fkHUVFRzJ09i+49b878g5QcSedmzuDTgO+cmwTcCcwBRgDNnXPzfNlmbpaWR9EXLVxAx/91xsyoc3ldjh8/xv79+1IsGxBgxMbG4pwjKjqaoKAgPnjvHW7u05fg4OAsOlLJaXRu5gy+ntLpC7wH3AJ8AHxtZpf7ss3cLC2Pou/bt5dSpU/tU6pUafbt3Zti2Xz58nNtm7b0uLEzZcuWI3+BAmxYv56Wra71/QFJrqFzM2fw9ZO2NwLNnHP7gI/NbBaewH+Fj9vNldL0KHoyF+HNLNWyt91xF7fdcRcAw4cO4d77B/HFzM/49ZclVKlajf5335sBvZfcTOdmzuDrKZ3OwBEzq2VmtYBVQGNftpmbpeVR9JKlSrN3z6l99u7dQ4mSJdNUdtOmjQBUrFiJeXNn89Irr/H333+xbdtWHxyN5CY6N3MGX0/ptAD+AsYDE4A/gSt92WZulpZH0a9p2Yp5c2fjnGPtmtXkz1+AEiVKpqns+Dde4977BhEXF0dCfDwAARZAVGRUph2j5Ew6N3MGX0/pvAK0dc79AWBmVYGPgfo+bjdXSulR9BmffgxA9x69uLp5C5b89CMdrm9DSEgoI0Y+n2rZkxYu+IFatWpTsmQpAOrUvYIbO3ekatWqVKtePfMPVnIUnZs5g08fvDKztc65Oudalxw9eCUicv6yIrXCSSvM7F1gqne5N/C7j9sUEZFk+HqEnxcYCDTDky3zJ2C8cy7mXGU1whcROX+pjfB9HfAfcM69dq51yVHAFxE5f1mWSwe4NZl1/XzcpoiIJMMnc/hm1gu4GbjYzOYm2VQAOOiLNkVEJHW+umj7C7AbKA6MTbL+OLDWR22KiEgqlA9fRCQXycp8+F3N7C8zO2pmx8zsuJkd82WbIiKSPF/fpfM30NE5t+l8y2qELyJy/rLyLp29FxLsRUQk42XGk7afArOB6JMrnXN6ibmISCbzdcAvCEQAbZOsc4ACvohIJtNdOiIiuUhW3qVTzsxmmdk+M9trZp+bWTlftikiIslLcUrHzOqlVtA5tzIN9b8PTAdu8i738a5rk9YOiohIxkhxSsfMFqVSzjnnWqWy/WQdq51zdc+1Ljma0hEROX8XlA/fOdcyA9o+YGZ98LzlCqAXyqUjIpIlzjmHb2ZhZva0mU32Llcxsw5prP92oDuwB09unW7edSIiksnOeZeO9z7634FbnHO1zCwU+DUt0zLpoSkdEZHzl95XHF7qnOvhTXmMcy7SzFKsEMDMhqay2TnnnktDuyIikoHSEvBjvKN6B2Bml5LkqdkUhCezLh9wB1AMUMAXEclkaZnSaQM8DdQE5gNNgX7Ouf9LUwNmBYAH8AT7GcBY59y+c5XTlI6IyPlL9zttzawYcCWeF5Evdc4dSEOZosDDQG/gQ+A159zhtHZaAV9E5Pyldw4foAXQDM+0TjAwK7WdzewloCswGajtnDuRxnZERMRH0jKlMwGozKl76XsA/zjnBqZSJgHPPH8cnDZSNzwXbQueq2Ma4YuInL90TemY2QaglvPuaGYBwDrn3GUZ2sszKOCLiJy/9CZP+wOokGS5PHoRuYhIjpNa8rR5eKZjCgGbzGyZd7kx8EvmdE9ERDJKahdtX860XoiIiM/pBSgiIrlIuubwzexKM1tuZifMLMbM4s3sWMZ2UUREfC0tF23fxJPW+C8gFLjTu05ERHKQND145Zz728wCnXPxwPtmpou2IiI5TFoCfoSZ5QFWm9kYPHnt8/m2WyIiktHSMqXT17vffXiyYJbHkzZBRERykAu6S8fMPnXO9fBBfxLpLh0RkfOX3idtk9PkAsuJiEgWudCALyIiOUxqqRXqpbQJT4pkn/pj13FfNyFyQa7sNDiruyCSoshVKd81n9pdOmNT2bb5gnsjIiJZIsWA75xrmZkdERER39IcvoiIn1DAFxHxEwr4IiJ+Ii3ZMs3M+pjZUO9yBTNr5PuuiYhIRkrLCH8CngetenmXjwPjfdYjERHxibQkT2vsnKtnZqsAnHOHvcnUREQkB0nLCD/WzALxvM8WMysBJPi0VyIikuHSEvBfB2YBJc1sFLAEeN6nvRIRkQx3zikd59xHZvY70BpPWoXOzrlNPu+ZiIhkqHMGfDOrAEQA85Kuc85t92XHREQkY6Xlou1XeObvDQgBLgb+AC7zYb9ERCSDpWVKp3bSZW8WzQE+65GIiPjEeT9p65xbCTT0QV9ERMSH0jKH/3CSxQCgHrDfZz0SERGfSMscfoEkn+PwzOl/7pvuiIiIr6Qa8L0PXOV3zj2WSf0REREfSXEO38yCnHPxeKZwREQkh0tthL8MT7BfbWZzgc+A8JMbnXNf+LhvIiKSgdIyh18UOAi04tT9+A5QwBcRyUFSC/glvXforOdUoD/J+bRXIiKS4VIL+IFAfk4P9Ccp4IuI5DCpBfzdzrkRmdYTERHxqdSetE1uZC8iIjlUagG/dab1QkREfC7FgO+cO5SZHREREd867+RpIiKSMyngi4j4CQV8ERE/oYAvIuInFPBFRPyEAr6IiJ9QwBcR8RMK+CIifkIBX0TETyjgi4j4CQV8ERE/kZY3Xkkm6XFdIypUqpy4/NizL1Oy9EXJ7tu349VMnbc4Xe2NHzOctSt/480pcwjOk4djR48weGBfxk+bl656JXcrWigfX0+6H4BSxQqSkJDA/sMnALi6z0vExsWnu43v3n6A0sULEhUTS3hENAOGf8Rf2/alu15/p4CfjeTJk5eXJk3P1DYDAgJY9N1c2nbslqntSs516Gg4V/Z8EYAhA9oTHhHNq1MXJG4PDAwgPj4h3e3cNuRDVm7czu1dm/L8Q1246cFJ6a7T3yngZ2NRkRGMGfoI4SeOERcXR8/b7qHhVdects/hgwd4ddRgIsLDSUiI485Bg6lR+wrWrFjKjCmTiIuNoVSZctz72DBCQsPOauOGrr346vPptG7f+axtc2dM4dcffyA2NoZGTVvS/dYBAMyc9g5LFn5DsRKlKFCwMJdUrcH/burrix+B5BCTn+3D4WMRXF6tHKs3/8fx8OjTfhGs+Owpug56i+27D9GzfUMG9mpBcHAQy9dt5YEXPiUhIeWX6C1Z+Tf39b4GgOcf7EzbpjVxDka/8y0z56+kdPGCTB19OwXyhRAUGMADz3/Kz6v+yYzDznEU8LORmJhoHhtwMwAly1zEw8+8yKPDXyIsX36OHT3CkEH9aNCkBWan3k2zZOG3XF7/Srr2voOE+Hiio6M4dvQIX0x/l2dGTyAkNJTZn3zAlzM/olvfu85qs3jJ0lSrdTk/ff819Zs0T1y/ZsVSdu/8j+ff/BDnHGOGPszGtSvJmzeE3xYvZMzEj4iPj+eJe/pwSdUavv/hSLZXuUJJ2t/9BgkJjiED2ie7T7WLS9GtbT1a3vYKcXEJvDq4Oz3bN2T6l8tSrPeG5rXY8NcuOreuS51q5WjU4wWKF87PkmmPsWTl3/S4vgHf/7KJMe9+R0CAERaSx1eHmOMp4GcjZ07pxMXF8fF749m0bhVmARw6sJ+jhw9SuGjxxH0urVaTiWNHEBcfR6OrrqFS5WpsXLqYHdv+5ZkH7/DWE0vVmrVTbLdrr9sZPfRh6jVulrhuze9LWfv7Uh6/uzcAUVER7Nm5ncjICBpe1YI8eUMAqN/k6gz9GUjO9cUPq1IdqQO0bFSNejUrsGTa4wCE5g1m/6ETye77/qhbiYyOZfuugzw8+jMG9WnFjG9XkJDg2HfoOIt//5v6l1VkxYZtTBrWh+CgQOYtWsPaP3dm+LHlFgr42diSBd9w7OgRXpwwjaCgIAb26UhMTMxp+9SsU49nx77NymVLeGP0UP7XvS/58hekdr3GPDjk+TS1U7pseSpdWpVff/z+1Ern6NyzH2063Hjavl9+/lG6j0typ4jI6MTPcfHxBASc+iYakicYADNj2rzfGPrG3HPWd3IO/6Sk32yT+nnlP7S581XaNbuMd0feyrgpP6T6jcGf6bbMbCwi/ASFChchKCiI9atXsH/v7rP22b93N4WKFOHa9l1odX0ntvz1B1Vr1OaPDWvYs/M/AKKjoti1Y1uqbXW9+XbmzZyWuHx5gyYs+m4uUZERABw6sI+jhw9RvVZdfl/6EzEx0URFRrDytyUZeMSSW2zbdYi6NcoDULd6OSqVLQbAomV/0OXaupQokh+AIgXDqFCmSJrqXLLyb7q1rU9AgFG8SH6a1a/MivVbqVCmCPsOHef9Wb/w4exfuKJ6ed8cVC6gEX421qz19Yx+5iGevLcvlS6tStnylc7aZ8Oa35n32RQCA4MICQ3jvsefpWDhIgx8bDivPT+E2FjPN4Ke/e7honIVU2yrfKVLubhydbb8vRmAyxtcyc7tWxgy6DYAQkLDuP/J56hc7TLqN2nOYwN6UaJkGS6tWpOwfPkz/uAlR5u9YDW9OzRi6SdP8vuGbYm3VG7+dw/Pjv+SeRPvI8CM2Lh4HnpxBtt3Hz5nnXMWrqFxnYtZ9ulgnIMhr85m78Hj9O7YmIduaU1sXDzhEdHc8cxUXx9ejmXOpT7nllXWbD+ePTsmREVGEBIaRnRUFMMevov+Dw3hkirVs7pbmebKToOzugsiKYpc9Wbyc19ohC8XYNK4UezYtoXY2GhatOngV8FeJCdTwJfz9sBTo7K6CyJyARTwc6gJLz/Lyt+WUKhwEca+PeO0bXM/m8q0ya/xzswfKFioMPv27OKhO25KnMOvUqMW/R98CvDcxz/r4/cxM4oUK8H9Tz5HwUKFM/twJBepUrEkU0ffnrh8cdliPDfxKy4qWZj2zWsRExvPlh0H6D9sGkdPRBIUFMDEob2pW708QYEBfPTVMl5+bz4AwUGBjHuyO80bVCEhIYHh479k9oLVWXRkOZ8Cfg51TduOtOvUg/Fjhp62/sC+Paz7/TeKlyx92vrSF5U9K21DfHwcH0wcyyvvfEbBQoWZ9vZrfDvnU7rfMsDn/Zfc669t+xJTLwQEGP98N4q5i9ZQpWIpnnljLvHxCYwc1InHbm/L06/P4cZr65E3TxANuz9PaEgwqz5/mhnfrGD77kM8ced17D90nDqdR2BmFC109tPikna6LTOHqlmnHvkLFDxr/YdvvULvuwaleM9yUs6Bc47oqEicc0SEh1O0WAlfdFf8VMtG1diyYz/bdx9mwdLNiTl2lq3bQtlShQFwOMJC8hAYGEBo3jzExMZzPDwKgFs7NeEl72jfOcfBI+FZchy5hc8CvpkNNLPCSZaLmNm9vmpPYMUvP1K0WEkqXVr1rG379uzi8btvZtjD/dm0bhUAQUFB3DXoSR7t35MBPduxc/sWWrXrlNndllzspuvqM+Pb389af0unJnz380bA84RuRFQMW74fxZ/fjODVKQs4fCyCQvlDARg2sAO/TH+Cj8bcTsmiBTK1/7mNL0f4dznnjpxccM4dBs5O5pKEmfU3sxVmtmLm9Pd92LXcJzoqii8+fo8e/e4+a1uRosWZ8NGXjHlrOrfe/RCvv/A0EeEniIuLY/68zxk98SMmffItFS6uzKxP9HOXjBEcFMgNLWrzxferTlv/+B3XER+fwCdfLweg4WWViI9P4JK2Q6hxwzAe6NuKSmWLERQUQLnSRfh19b9cdfNoflu7lRce6pIVh5Jr+DLgB1iSeQUzCwRSzWrknJvsnGvgnGvQ7ebbfNi13Gfv7h3s27OLxwb0YmCfjhzcv48n7unNkUMHCM6ThwIFCwNwSdUalCpTlt07trP1nz8AKH1ROcyMJi3a8OeGtVl4FJKbXNesJqs3/8e+Q8cT1/Xu2Jj2zWvRb8gHieu6X9+A+b9sJC7Ok1f/19X/Ur9mBQ4eCSc8Mpo5C9cA8MX3KxOf3pUL48uA/x0ww8xam1kr4GPgWx+259cqXFyZdz77nvHT5jF+2jyKlSjJ6IkfUbhocY4dOUxCvOelFHt372D3zv8oVaYsRYuVZMf2fzl2xPOU49qVv1G2wsVZeRiSi3Rv1+C06Zw2V9XgkX7X0u3BSURGxSau37HnENc0rAZAWEgeGtWpxB9b9wLw9U/rad6gCgDXNKrG5n/PTi8iaeezJ23NLAAYALQGDJgPvOOcS9PrcPSkbepeHfUUG9f+zvGjRyhUpBjdb+lPq+s7J24f2KcjL4yfSsFChVm6eAEzPpxEYGAgAQEB3HTLABp4UyHPnzeTb2Z9QmBQEMVLlWHgY8MSvw1I8vSk7bmFhgTz1zcjqdlxGMdOeC7Arp8zjLx5gjh41HPhddm6rQwa9Qn5QvMw+dk+VL+kDGYwdc5Sxk3x5NGvUKYI7468lUL5Qzlw+AQDhk/jvz3nTsPgz1J70lapFUTOkwK+ZGeZmlrBzGY457qb2TrgrKDtnKuT0W2KiMi5+eLBqwe8f3fwQd0iInKBMjzgO+dOXlXJ55zbmHSbmV0DpJ6YXUREfMKXqRVmmNlUYAwQ4v27AdDEh23mOinlzPlm9id8O2cGgYFB1GvclD53PXBW2fATx3nrlef4b+s/GMY9jw6las06jBs5mF3/eX7vRoQfJyxfAV6aNJ3N61fzzusvEhychweeGkXpsuUJP3GcV0cO5qkX3kjT07viX+7v3ZJ+Xa7COceGv3fRf9g0nrjzOjq0qEOCc+w/dJz+w6axe//R08rlzRPED+8+SJ48QQQFBjLrh1WMfOtrAIbee0Oy5ZtcfgmvPdWDmNg4bhn8Pv/+d4BC+UOZOvp2/jdwfFYcfo7jy7t08gGjgfpAAeAjYLRzLiEt5XXR1mPj2pWEhIYxfszQxIC/fvUKZk1/jydHvkpwnjwcPXyIQkWKnlX2zTHDqFHrClq370xcbCzR0VHky3/6k4pT3hpHWL78dOt7Fy8Pf4zed97P/r27WL38V265+yGmvDWOBk2aU/Py+plyvDmBLtp6XFSiEAvef4grbhxFVHQs00bfzrdLNjBn4ZrE1Aj39mpB9UvKMGjUJ2eVzxeah/DIGIKCAlj43sM8+tJMlq3bSoF8IcmW/+TlOxny+hwqlilG26Y1ePKVWbz4cBe+/HEdS37/O1OPPTtL7aKtL+/DjwUigVA8I/wtaQ32ckpyOXPmz5tJp563EpzH8xxbcsE+IvwEm9atotX1nlQJQcHBZwV75xy//vQDTVteB0BgUBAxMdFER0cRGBTEnl07OHRwn4K9pCgoMJDQvMGePDghedi9/2hisAYIC81LSoPK8EjP29iCgwIJCgpM3C+l8rFx8YTmDSYsNJjYuHguLleci0oWVrA/D76c0lkOzAEaAsWASWbWzTnXzYdt+oXdO7azed1qPnl/AsHBeek74AEqV7vstH327d5JwUKFmfDSs2z7908uqVKDfvc+SkhoaOI+m9atolDhopQpVwGALj37MXncKPLkzct9T4xg6uRX6XHrPZl6bJJz7Np/lFenLODPb54jMjqGBb9uZsFSzysyhw/sSO8OjTh6IpJ2/V9PtnxAgPHL9Ce4tHwJJn36E8vXn7q8l1z5l96bz/inexEZHcsdT0/hhYe78OyEL31/oLmIL0f4dzjnhjrnYp1ze5xznfD8ApB0SkiI48SJY4x6/QP69h/EuJGDzxpFxcfHs+WvP2jbsRtj3ppO3pBQZn/6wWn7/Lzou8TRPUClytUY9cYHDHt5Ent376RIsRI4HONGDub1F5/hyOGDmXF4kkMULhBKh2tqU6PDMC5pO4R8oXno2b4hAMPHz6PK9c/wyTcruLtH82TLJyQ4ruz5IpWve5oGtSpS89IyiduSK7/2z520uHUs7fq/TqVyxdi9/yiGMfXF23hv5C1KrJYGvgz4a8xskJnN9P65Dzh7Ik/OW9HipWjcrCVmRuXqtQgw4/jRI6ftU6xESYqVKEmVGrUAuLJ5a7b8tTlxe3x8HMuWLOKqa9qcVb9zji8+epcbe9/JzKlv0/2WATRvfT3fzNI/n5zSqnF1tu46yIHDJ4iLS2D2wjVcefnpqTlmfLOczq3rplrP0ROR/LTiL9peVfOsbSmVf/LOdrww+RuGDLie5976mo+/Xs69va5Jx9H4B18G/Il4LthO8P45+VnSqeFVLVi/agUAu3ZsIy4ujgJnvKWqcNHiFCtRil3/bQVg3apllKt4SeL2dSuXcVH5ShQrUeqs+n+c/yX1Gjcjf4GCREdHYQGGWQDR0VFn7Sv+6789h2hU+2JCQ4IBT+77P7bs5dIKp96pcEOLOvzpzYuTVPEi+RPTH4fkDaZV42qJ+XPOVb5Px8Z8u3gDR45HEhaSh4QER0KCI8zbD0mZL560DXLOxQENnXOXJ9m00MzWZHR7uV3SnDl392rvyZnTrhMTxo7gkbu6ExQUzMDHhmNmHDqwn0mvPMfg5z1znrcPfIzXX3iGuLhYSpYpy72PDkus9+dF82nasu1Z7UVHRfHj918y5EXPbW4dbuzN2GcfJyg4WO+yldMsX7+NWT+s4tfpTxAXn8CazTt49/Of+fCFflSpWJKEBMf23YcS79ApU6IQE4beTJf7J1K6eEHeHtGXwIAAAgKMz79fyTeL1wMwclCnZMuDJ0dPn46N6XDvmwC8Pm0hH798JzGxcdw6+INM/xnkNBl+W6aZrXTO1TOzlcBNzrl/vOsvAWY65+qlpR7dlinZlW7LlOwsU3Pp4MmMCfAosMjM/vUuVwKU5F5EJIv4IuCXMLOHvZ8nAYFAOJ578a8AFvmgTREROQdfBPxAID+nRvp4l8HzxK2IiGQBXwT83c65ET6oV0RE0sEXt2Uqw5aISDbki4Df2gd1iohIOmV4wHfOHcroOkVEJP18+aStiIhkIwr4IiJ+QgFfRMRPKOCLiPgJBXwRET+hgC8i4icU8EVE/IQCvoiIn1DAFxHxEwr4IiJ+QgFfRMRPKOCLiPgJBXwRET+hgC8i4icU8EVE/IQCvoiIn1DAFxHxEwr4IiJ+QgFfRMRPKOCLiPgJBXwRET+hgC8i4icU8EVE/IQCvoiIn1DAFxHxEwr4IiJ+QgFfRMRPKOCLiPgJBXwRET+hgC8i4icU8EVE/IQ557K6D5IJzKy/c25yVvdD5Ew6NzOPRvj+o39Wd0AkBTo3M4kCvoiIn1DAFxHxEwr4/kNzpJJd6dzMJLpoKyLiJzTCFxHxEwr4IiJ+QgE/GzIzZ2Zjkyw/ambDL7CuSmZ2czr6MsLMrr3Q8uJ/zKyYma32/tljZjuTLOdJQ/mLzGxmZvTV32gOPxsysyhgN9DQOXfAzB4F8jvnhl9AXdcAjzrnOmRoJ0XSwDtQOeGcezmr+yIa4WdXcXjuXHjozA1mVtHMFpjZWu/fFbzrPzCz183sFzP718y6eYu8CFztHV09ZGYhZva+ma0zs1Vm1tJbfo6Z3eL9PMDMPkpSbzfv54be+teY2TIzK+D7H4XkBmbW2nu+rTOz98wsr/d8Wus9J/OZ2QYzq+X9VrreWy7QzF72lltrZvdn9bHkZEFZ3QFJ0XhgrZmNOWP9m8AU59yHZnY78DrQ2butDNAMqA7MBWYCT5JkhG9mjwA452qbWXVgvplVxfO0489mtgV4BLgyaaPer+KfAj2cc8vNrCAQmcHHLLlTCPAB0No596eZTQHucc69amZzgZFAKDDNObfezColKdsfuBi4wjkXZ2ZFM7nvuYpG+NmUc+4YMAUYdMamJsB07+epeAL8SbOdcwnOuY1AqRSqbuYth3NuM7ANqOqc2wsMBRYBjzjnDp1Rrhqw2zm3/GT/nHNxF3Rw4m8CgS3OuT+9yx8Czb2fRwBtgAbAmYMbgGuBt06ea8mcl3IeFPCzt1eBO4B8qeyT9CJMdJLPlsL+Ka0HqA0cBC5KoZwu+MiFCE9lW1EgP1AAzzeBM+m8y0AK+NmYdzQzA0/QP+kXoKf3c29gyTmqOY7nP9NJP3nL4Z3KqQD8YWaNgOuBK4BHzeziM+rZDFxkZg29ZQuYmaYEJS1CgEpmVtm73Bf40ft5MvAM8BEwOpmy84G7T55rmtJJHwX87G8sUDzJ8iDgNjNbi+c/zgPnKL8WiPNeaH0ImAAEmtk6PHPy/bz7vQ3c7pzbhWcO/z0zS/w24JyLAXoAb5jZGuB7kh+RiZwpCrgN+Mx73iUAb3lvEohzzk3Hc3NBQzNrdUbZd4DteK5nrQEu+BZj0W2ZIiJ+QyN8ERE/oYAvIuInFPBFRPyEAr6IiJ9QwBcR8RMK+JKtmVm8Nw/QejP7zMzC0lFX0rxA75hZzVT2vcbMrrqANraaWfG0rk+hjn5m9mZGtCuSlAK+ZHeRzrm6zrlaQAxwd9KNZhZ4IZU65+70pqBIyTXAeQd8kexMAV9yksVAZe/oe5GZTQfWeTMqvmRmy70ZFQcAmMebZrbRzL4CSp6syMz+z8waeD+3M7OV3ofTFniTd90NPOT9dnG1mZUws8+9bSw3s6bessXMbL43E+QkUk9dcRoza+TNPrrK+3e1JJvLm9m3ZvaHmQ1LUqaPN1PpajObdKG/8MQ/6dF4yRG8j9ZfD3zrXdUIqOWc22Jm/YGjzrmGZpYXT9bP+XjSRFTDkyOoFLAReO+Mekvgecq4ubeuos65Q2b2FknyuHt/uYxzzi0xT0rq74AawDBgiXNuhJndgCe7Y1pt9rYbZ56XzDwP3Jj0+IAIYLn3F1Y4nqedmzrnYs1sAp40GVPOo03xYwr4kt2Fmtlq7+fFwLt4plqWOee2eNe3BerYqXcAFAKq4MnI+LFzLh7YZWYLk6n/SuCnk3Wlko3xWqBmkmwTBc3zPoDmQFdv2a/M7PB5HFsh4EMzq4InQVhwkm3fO+cOApjZF3iynMYB9fH8AgBPSuF959Ge+DkFfMnuIp1zdZOu8Aa7pBkYDbjfOffdGfu159yZFtOajTEAaOKcO+0dAN6+XGh+kueARc65Lt5ppP9Lsu3MOp23rx865wZfYHvi5zSHL7nBd8A9ZhYMniygZpYPT2bQnt45/jJAy2TK/gq0OJkdNEk2xjOzjM4H7ju5YGZ1vR+TZh+9HihyHv0uBOz0fu53xrY2ZlbUzELxvODmZ2AB0M3MSp7sq5lVPI/2xM8p4Etu8A6e+fmV5nk13iQ8315nAX8B64CJnErJm8g5tx/PvPsX3myMn3o3zQO6nLxoiydLaQPvReGNnLpb6FmguZmtxDO1tD2Vfq41sx3eP6/geeHHC2b2M56XhCS1BM+LalYDnzvnVnjvKnoaz1vK1uLJWFombT8iEWXLFBHxGxrhi4j4CQV8ERE/oYAvIuInFPBFRPyEAr6IiJ9QwBcR8RMK+CIifuL/AQfZS6jIIU+dAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Evaluating test set\n",
    "\n",
    "# Initialising\n",
    "accuracies = []\n",
    "    \n",
    "print('Using male toxic test data with offensive words')\n",
    "print('Number of test sentences: {:,}\\n'.format(df.shape[0]))\n",
    "\n",
    "# Extract necessary information\n",
    "comments = df.comment.values\n",
    "labels = df.toxicity.values\n",
    "\n",
    "# Tokenize all of the sentences and map the tokens to their word IDs.\n",
    "input_ids = []\n",
    "attention_masks = []\n",
    "\n",
    "# For every sentence...\n",
    "for cmt in comments:\n",
    "    # `encode_plus` will:\n",
    "    #   (1) Tokenize the sentence.\n",
    "    #   (2) Prepend the `[CLS]` token to the start.\n",
    "    #   (3) Append the `[SEP]` token to the end.\n",
    "    #   (4) Map tokens to their IDs.\n",
    "    #   (5) Pad or truncate the sentence to `max_length`\n",
    "    #   (6) Create attention masks for [PAD] tokens.\n",
    "    encoded_dict = tokenizer.encode_plus(\n",
    "                        cmt,                      # Sentence to encode.\n",
    "                        add_special_tokens = True, # Add '[CLS]' and '[SEP]'\n",
    "                        max_length = MAX_LEN,           # Pad & truncate all sentences.\n",
    "                        padding='max_length',\n",
    "                        truncation=True,\n",
    "                        return_attention_mask = True,   # Construct attn. masks.\n",
    "                        return_tensors = 'pt',     # Return pytorch tensors.\n",
    "                )\n",
    "      \n",
    "    # Add the encoded sentence to the list.    \n",
    "    input_ids.append(encoded_dict['input_ids'])\n",
    "      \n",
    "    # And its attention mask (simply differentiates padding from non-padding).\n",
    "    attention_masks.append(encoded_dict['attention_mask'])\n",
    "\n",
    "# Convert the lists into tensors.\n",
    "input_ids = torch.cat(input_ids, dim=0)\n",
    "attention_masks = torch.cat(attention_masks, dim=0)\n",
    "labels = torch.tensor(labels)\n",
    "\n",
    "# Set the batch size.  \n",
    "batch_size = 8\n",
    "\n",
    "# Create the DataLoader.\n",
    "prediction_data = TensorDataset(input_ids, attention_masks, labels)\n",
    "prediction_sampler = SequentialSampler(prediction_data)\n",
    "prediction_dataloader = DataLoader(prediction_data, sampler=prediction_sampler, batch_size=batch_size)\n",
    "\n",
    "# Prediction on test set\n",
    "\n",
    "print('Predicting labels for {:,} test sentences...'.format(len(input_ids)))\n",
    "\n",
    "# Put model in evaluation mode\n",
    "model.eval()\n",
    "\n",
    "# Tracking variables \n",
    "predictions , true_labels = [], []\n",
    "\n",
    "# Predict \n",
    "for batch in prediction_dataloader:\n",
    "    # Add batch to GPU\n",
    "    batch = tuple(t.to(device) for t in batch)\n",
    "    \n",
    "    # Unpack the inputs from our dataloader\n",
    "    b_input_ids, b_input_mask, b_labels = batch\n",
    "    \n",
    "    # Telling the model not to compute or store gradients, saving memory and \n",
    "    # speeding up prediction\n",
    "    with torch.no_grad():\n",
    "        # Forward pass, calculate logit predictions\n",
    "        outputs = model(b_input_ids, token_type_ids=None, \n",
    "                        attention_mask=b_input_mask)\n",
    "\n",
    "    logits = outputs[0]\n",
    "    \n",
    "\n",
    "    # Move logits and labels to CPU\n",
    "    logits = logits.detach().cpu().numpy()\n",
    "    label_ids = b_labels.to('cpu').numpy()\n",
    "    \n",
    "    # Store predictions and true labels\n",
    "    predictions.append(logits)\n",
    "    true_labels.append(label_ids)\n",
    "\n",
    "print('    DONE.')\n",
    "  \n",
    "# Combine the results across all batches. \n",
    "flat_pred = np.concatenate(predictions, axis=0)\n",
    "# For each sample, pick the label (0 or 1) with the higher score.\n",
    "flat_predictions = np.argmax(flat_pred, axis=1).flatten()\n",
    "\n",
    "# Combine the correct labels for each batch into a single list.\n",
    "flat_true_labels = np.concatenate(true_labels, axis=0)\n",
    "\n",
    "# Return metrics\n",
    "f1 = f1_score(flat_true_labels, flat_predictions)\n",
    "print('Total F1: %.3f' % f1)\n",
    "acc = accuracy_score(flat_true_labels,flat_predictions)\n",
    "print('Accuracy: %.2f' % acc)\n",
    "accuracies.append(acc)\n",
    "\n",
    "# Print Confusion matrix\n",
    "cf_matrix = confusion_matrix(flat_true_labels, flat_predictions)\n",
    "group_names = ['True Neg','False Pos','False Neg','True Pos']\n",
    "group_counts = ['{0:0.0f}'.format(value) for value in\n",
    "                cf_matrix.flatten()]\n",
    "group_percentages = ['{0:.2%}'.format(value) for value in\n",
    "                    cf_matrix.flatten()/np.sum(cf_matrix)]\n",
    "labels = [f'{v1}\\n{v2}\\n{v3}' for v1, v2, v3 in\n",
    "        zip(group_names,group_counts,group_percentages)]\n",
    "matrix = pd.DataFrame(np.array([cf_matrix[0],cf_matrix[1]]), columns = ['Nontoxic','Toxic'], index=['Nontoxic','Toxic'])\n",
    "matrix = matrix.rename_axis(\"True Label\")\n",
    "matrix = matrix.rename_axis(\"Predicted Label\",axis=\"columns\")\n",
    "try:\n",
    "    labels = np.asarray(labels).reshape(2,2)\n",
    "    sns.heatmap(matrix, annot=labels, fmt='',cbar = False, cmap='Blues')\n",
    "    plt.show()\n",
    "except ValueError:\n",
    "    print(\"could not display\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating and evaluating female toxic test set\n",
    "\n",
    "# Choose whether to use saved data\n",
    "saved_test_set = True\n",
    "    \n",
    "if saved_test_set:\n",
    "    with open(\"female_notoxic_test.data\", 'rb') as file:\n",
    "        df = pickle.load(file)\n",
    "    file.close()\n",
    "else:\n",
    "    # Create balanced test data (between toxic and very toxic)\n",
    "    female_toxic = toxic[toxic.female_binary == 1]\n",
    "    female_very_toxic = very_toxic[very_toxic.female_binary == 1]\n",
    "    test_size = min(test_size, female_toxic.shape[0],female_very_toxic.shape[0])\n",
    "    female_toxic_test = female_toxic.sample(n=test_size)\n",
    "    female_vtoxic_test = female_very_toxic.sample(n=test_size)\n",
    "    df = pd.concat([female_toxic_test,female_vtoxic_test])\n",
    "    \n",
    "    # Removing punctuation and converting capital letters to lowercase\n",
    "    df['comment'] = df['comment'].str.translate(str.maketrans('', '', string.punctuation))\n",
    "    df['comment'] = df['comment'].str.lower()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using female toxic test data without offensive words\n",
      "Number of test sentences: 5,630\n",
      "\n",
      "Predicting labels for 5,630 test sentences...\n",
      "    DONE.\n",
      "Total F1: 0.857\n",
      "Accuracy: 0.75\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Evaluating test set\n",
    "\n",
    "# Initialising\n",
    "accuracies = []\n",
    "\n",
    "df = df.sample(frac=1)\n",
    "print('Using female toxic test data without offensive words')\n",
    "print('Number of test sentences: {:,}\\n'.format(df.shape[0]))\n",
    "\n",
    "# Extract necessary information\n",
    "comments = df.comment.values\n",
    "labels = df.toxicity.values\n",
    "\n",
    "# Removing offensive words from comments\n",
    "new_comments = []\n",
    "for comment in comments:\n",
    "    new_comment = clean_comment(comment)\n",
    "    new_comments.append(new_comment)\n",
    "comments = new_comments\n",
    "\n",
    "# Tokenize all of the sentences and map the tokens to their word IDs.\n",
    "input_ids = []\n",
    "attention_masks = []\n",
    "\n",
    "# For every sentence...\n",
    "for cmt in comments:\n",
    "    # `encode_plus` will:\n",
    "    #   (1) Tokenize the sentence.\n",
    "    #   (2) Prepend the `[CLS]` token to the start.\n",
    "    #   (3) Append the `[SEP]` token to the end.\n",
    "    #   (4) Map tokens to their IDs.\n",
    "    #   (5) Pad or truncate the sentence to `max_length`\n",
    "    #   (6) Create attention masks for [PAD] tokens.\n",
    "    encoded_dict = tokenizer.encode_plus(\n",
    "                        cmt,                      # Sentence to encode.\n",
    "                        add_special_tokens = True, # Add '[CLS]' and '[SEP]'\n",
    "                        max_length = MAX_LEN,           # Pad & truncate all sentences.\n",
    "                        padding='max_length',\n",
    "                        truncation=True,\n",
    "                        return_attention_mask = True,   # Construct attn. masks.\n",
    "                        return_tensors = 'pt',     # Return pytorch tensors.\n",
    "                )\n",
    "      \n",
    "    # Add the encoded sentence to the list.    \n",
    "    input_ids.append(encoded_dict['input_ids'])\n",
    "      \n",
    "    # And its attention mask (simply differentiates padding from non-padding).\n",
    "    attention_masks.append(encoded_dict['attention_mask'])\n",
    "\n",
    "# Convert the lists into tensors.\n",
    "input_ids = torch.cat(input_ids, dim=0)\n",
    "attention_masks = torch.cat(attention_masks, dim=0)\n",
    "labels = torch.tensor(labels)\n",
    "\n",
    "# Set the batch size.  \n",
    "batch_size = 8\n",
    "\n",
    "# Create the DataLoader.\n",
    "prediction_data = TensorDataset(input_ids, attention_masks, labels)\n",
    "prediction_sampler = SequentialSampler(prediction_data)\n",
    "prediction_dataloader = DataLoader(prediction_data, sampler=prediction_sampler, batch_size=batch_size)\n",
    "\n",
    "# Prediction on test set\n",
    "\n",
    "print('Predicting labels for {:,} test sentences...'.format(len(input_ids)))\n",
    "\n",
    "# Put model in evaluation mode\n",
    "model.eval()\n",
    "\n",
    "# Tracking variables \n",
    "predictions , true_labels = [], []\n",
    "\n",
    "# Predict \n",
    "for batch in prediction_dataloader:\n",
    "    # Add batch to GPU\n",
    "    batch = tuple(t.to(device) for t in batch)\n",
    "    \n",
    "    # Unpack the inputs from our dataloader\n",
    "    b_input_ids, b_input_mask, b_labels = batch\n",
    "    \n",
    "    # Telling the model not to compute or store gradients, saving memory and \n",
    "    # speeding up prediction\n",
    "    with torch.no_grad():\n",
    "        # Forward pass, calculate logit predictions\n",
    "        outputs = model(b_input_ids, token_type_ids=None, \n",
    "                        attention_mask=b_input_mask)\n",
    "\n",
    "    logits = outputs[0]\n",
    "    \n",
    "\n",
    "    # Move logits and labels to CPU\n",
    "    logits = logits.detach().cpu().numpy()\n",
    "    label_ids = b_labels.to('cpu').numpy()\n",
    "    \n",
    "    # Store predictions and true labels\n",
    "    predictions.append(logits)\n",
    "    true_labels.append(label_ids)\n",
    "\n",
    "print('    DONE.')\n",
    "  \n",
    "# Combine the results across all batches. \n",
    "flat_pred = np.concatenate(predictions, axis=0)\n",
    "# For each sample, pick the label (0 or 1) with the higher score.\n",
    "flat_predictions = np.argmax(flat_pred, axis=1).flatten()\n",
    "\n",
    "# Combine the correct labels for each batch into a single list.\n",
    "flat_true_labels = np.concatenate(true_labels, axis=0)\n",
    "\n",
    "# Return metrics\n",
    "f1 = f1_score(flat_true_labels, flat_predictions)\n",
    "print('Total F1: %.3f' % f1)\n",
    "acc = accuracy_score(flat_true_labels,flat_predictions)\n",
    "print('Accuracy: %.2f' % acc)\n",
    "accuracies.append(acc)\n",
    "\n",
    "# Print Confusion matrix\n",
    "cf_matrix = confusion_matrix(flat_true_labels, flat_predictions)\n",
    "group_names = ['True Neg','False Pos','False Neg','True Pos']\n",
    "group_counts = ['{0:0.0f}'.format(value) for value in\n",
    "                cf_matrix.flatten()]\n",
    "group_percentages = ['{0:.2%}'.format(value) for value in\n",
    "                    cf_matrix.flatten()/np.sum(cf_matrix)]\n",
    "labels = [f'{v1}\\n{v2}\\n{v3}' for v1, v2, v3 in\n",
    "        zip(group_names,group_counts,group_percentages)]\n",
    "matrix = pd.DataFrame(np.array([cf_matrix[0],cf_matrix[1]]), columns = ['Nontoxic','Toxic'], index=['Nontoxic','Toxic'])\n",
    "matrix = matrix.rename_axis(\"True Label\")\n",
    "matrix = matrix.rename_axis(\"Predicted Label\",axis=\"columns\")\n",
    "try:\n",
    "    labels = np.asarray(labels).reshape(2,2)\n",
    "    sns.heatmap(matrix, annot=labels, fmt='',cbar = False, cmap='Blues')\n",
    "    plt.show()\n",
    "except ValueError:\n",
    "    print(\"could not display\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using female toxic test data with offensive words\n",
      "Number of test sentences: 5,630\n",
      "\n",
      "Predicting labels for 5,630 test sentences...\n",
      "    DONE.\n",
      "Total F1: 0.873\n",
      "Accuracy: 0.77\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Evaluating test set\n",
    "\n",
    "# Initialising\n",
    "accuracies = []\n",
    "\n",
    "print('Using female toxic test data with offensive words')\n",
    "print('Number of test sentences: {:,}\\n'.format(df.shape[0]))\n",
    "\n",
    "# Extract necessary information\n",
    "comments = df.comment.values\n",
    "labels = df.toxicity.values\n",
    "\n",
    "# Tokenize all of the sentences and map the tokens to their word IDs.\n",
    "input_ids = []\n",
    "attention_masks = []\n",
    "\n",
    "# For every sentence...\n",
    "for cmt in comments:\n",
    "    # `encode_plus` will:\n",
    "    #   (1) Tokenize the sentence.\n",
    "    #   (2) Prepend the `[CLS]` token to the start.\n",
    "    #   (3) Append the `[SEP]` token to the end.\n",
    "    #   (4) Map tokens to their IDs.\n",
    "    #   (5) Pad or truncate the sentence to `max_length`\n",
    "    #   (6) Create attention masks for [PAD] tokens.\n",
    "    encoded_dict = tokenizer.encode_plus(\n",
    "                        cmt,                      # Sentence to encode.\n",
    "                        add_special_tokens = True, # Add '[CLS]' and '[SEP]'\n",
    "                        max_length = MAX_LEN,           # Pad & truncate all sentences.\n",
    "                        padding='max_length',\n",
    "                        truncation=True,\n",
    "                        return_attention_mask = True,   # Construct attn. masks.\n",
    "                        return_tensors = 'pt',     # Return pytorch tensors.\n",
    "                )\n",
    "      \n",
    "    # Add the encoded sentence to the list.    \n",
    "    input_ids.append(encoded_dict['input_ids'])\n",
    "      \n",
    "    # And its attention mask (simply differentiates padding from non-padding).\n",
    "    attention_masks.append(encoded_dict['attention_mask'])\n",
    "\n",
    "# Convert the lists into tensors.\n",
    "input_ids = torch.cat(input_ids, dim=0)\n",
    "attention_masks = torch.cat(attention_masks, dim=0)\n",
    "labels = torch.tensor(labels)\n",
    "\n",
    "# Set the batch size.  \n",
    "batch_size = 8\n",
    "\n",
    "# Create the DataLoader.\n",
    "prediction_data = TensorDataset(input_ids, attention_masks, labels)\n",
    "prediction_sampler = SequentialSampler(prediction_data)\n",
    "prediction_dataloader = DataLoader(prediction_data, sampler=prediction_sampler, batch_size=batch_size)\n",
    "\n",
    "# Prediction on test set\n",
    "\n",
    "print('Predicting labels for {:,} test sentences...'.format(len(input_ids)))\n",
    "\n",
    "# Put model in evaluation mode\n",
    "model.eval()\n",
    "\n",
    "# Tracking variables \n",
    "predictions , true_labels = [], []\n",
    "\n",
    "# Predict \n",
    "for batch in prediction_dataloader:\n",
    "    # Add batch to GPU\n",
    "    batch = tuple(t.to(device) for t in batch)\n",
    "    \n",
    "    # Unpack the inputs from our dataloader\n",
    "    b_input_ids, b_input_mask, b_labels = batch\n",
    "    \n",
    "    # Telling the model not to compute or store gradients, saving memory and \n",
    "    # speeding up prediction\n",
    "    with torch.no_grad():\n",
    "        # Forward pass, calculate logit predictions\n",
    "        outputs = model(b_input_ids, token_type_ids=None, \n",
    "                        attention_mask=b_input_mask)\n",
    "\n",
    "    logits = outputs[0]\n",
    "    \n",
    "\n",
    "    # Move logits and labels to CPU\n",
    "    logits = logits.detach().cpu().numpy()\n",
    "    label_ids = b_labels.to('cpu').numpy()\n",
    "    \n",
    "    # Store predictions and true labels\n",
    "    predictions.append(logits)\n",
    "    true_labels.append(label_ids)\n",
    "\n",
    "print('    DONE.')\n",
    "  \n",
    "# Combine the results across all batches. \n",
    "flat_pred = np.concatenate(predictions, axis=0)\n",
    "# For each sample, pick the label (0 or 1) with the higher score.\n",
    "flat_predictions = np.argmax(flat_pred, axis=1).flatten()\n",
    "\n",
    "# Combine the correct labels for each batch into a single list.\n",
    "flat_true_labels = np.concatenate(true_labels, axis=0)\n",
    "\n",
    "# Return metrics\n",
    "f1 = f1_score(flat_true_labels, flat_predictions)\n",
    "print('Total F1: %.3f' % f1)\n",
    "acc = accuracy_score(flat_true_labels,flat_predictions)\n",
    "print('Accuracy: %.2f' % acc)\n",
    "accuracies.append(acc)\n",
    "\n",
    "# Print Confusion matrix\n",
    "cf_matrix = confusion_matrix(flat_true_labels, flat_predictions)\n",
    "group_names = ['True Neg','False Pos','False Neg','True Pos']\n",
    "group_counts = ['{0:0.0f}'.format(value) for value in\n",
    "                cf_matrix.flatten()]\n",
    "group_percentages = ['{0:.2%}'.format(value) for value in\n",
    "                    cf_matrix.flatten()/np.sum(cf_matrix)]\n",
    "labels = [f'{v1}\\n{v2}\\n{v3}' for v1, v2, v3 in\n",
    "        zip(group_names,group_counts,group_percentages)]\n",
    "matrix = pd.DataFrame(np.array([cf_matrix[0],cf_matrix[1]]), columns = ['Nontoxic','Toxic'], index=['Nontoxic','Toxic'])\n",
    "matrix = matrix.rename_axis(\"True Label\")\n",
    "matrix = matrix.rename_axis(\"Predicted Label\",axis=\"columns\")\n",
    "try:\n",
    "    labels = np.asarray(labels).reshape(2,2)\n",
    "    sns.heatmap(matrix, annot=labels, fmt='',cbar = False, cmap='Blues')\n",
    "    plt.show()\n",
    "except ValueError:\n",
    "    print(\"could not display\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "Toxic_BERT.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "050fad76094442ccabc0a9dd1841b1e7": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "13892e698d894bb7b7555e3c725f7bff": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "2d24a0780c6e46e3b5d2c348c788d383": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": "initial"
     }
    },
    "2f72600eb7d241d38861be5e6cac560d": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "312fbca9a0d34423bf15e7bb52755bf1": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "Downloading: 100%",
      "description_tooltip": null,
      "layout": "IPY_MODEL_3cef259bc6c348139134a71ad635082f",
      "max": 440473133,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_ce6d4c02eb45429cb45832f86228b98e",
      "value": 440473133
     }
    },
    "3a643aebf84147d2baec20687a8d467e": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "3cef259bc6c348139134a71ad635082f": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "4d6dfec252104ceeb314babbf507bf6c": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "4ef1d475bfb44fb5b4e8f77843e9c13d": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "Downloading: 100%",
      "description_tooltip": null,
      "layout": "IPY_MODEL_7245dba34af84f019e9aa7b4167655c2",
      "max": 231508,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_a679570eb7834b98b460e7235fab57be",
      "value": 231508
     }
    },
    "5523466dab5342c1976c15d4495362a0": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "6c549a6980514e7fbc05d2f3bded708a": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "7035649df34f421b936faded0d3ee5b6": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "7245dba34af84f019e9aa7b4167655c2": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "73f18bedea76480fb9981b5d526cbc2d": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_e5186ba30dbd4973a6983d88ba06ee17",
       "IPY_MODEL_7b11996e92974efaaa6db91f5ac2e59f"
      ],
      "layout": "IPY_MODEL_5523466dab5342c1976c15d4495362a0"
     }
    },
    "7b11996e92974efaaa6db91f5ac2e59f": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_7035649df34f421b936faded0d3ee5b6",
      "placeholder": "​",
      "style": "IPY_MODEL_13892e698d894bb7b7555e3c725f7bff",
      "value": " 433/433 [00:20&lt;00:00, 21.6B/s]"
     }
    },
    "82a19fe3427542d38429d1b8ccaa931d": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_6c549a6980514e7fbc05d2f3bded708a",
      "placeholder": "​",
      "style": "IPY_MODEL_4d6dfec252104ceeb314babbf507bf6c",
      "value": " 440M/440M [00:05&lt;00:00, 74.0MB/s]"
     }
    },
    "9a413a00269e406f910a554babc8ddac": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_4ef1d475bfb44fb5b4e8f77843e9c13d",
       "IPY_MODEL_c27bc61cdcfe419eab175f61768cb692"
      ],
      "layout": "IPY_MODEL_050fad76094442ccabc0a9dd1841b1e7"
     }
    },
    "a679570eb7834b98b460e7235fab57be": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": "initial"
     }
    },
    "b0aa11e7b5f44d7a9c094b3860f1fe1f": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "c27bc61cdcfe419eab175f61768cb692": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_b0aa11e7b5f44d7a9c094b3860f1fe1f",
      "placeholder": "​",
      "style": "IPY_MODEL_2f72600eb7d241d38861be5e6cac560d",
      "value": " 232k/232k [00:00&lt;00:00, 627kB/s]"
     }
    },
    "ce6d4c02eb45429cb45832f86228b98e": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": "initial"
     }
    },
    "cf76c66b89b749e4a79a179e56bd8b78": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "e5186ba30dbd4973a6983d88ba06ee17": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "Downloading: 100%",
      "description_tooltip": null,
      "layout": "IPY_MODEL_cf76c66b89b749e4a79a179e56bd8b78",
      "max": 433,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_2d24a0780c6e46e3b5d2c348c788d383",
      "value": 433
     }
    },
    "ef0f5c28845d44b6ada41f72ec2dd982": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_312fbca9a0d34423bf15e7bb52755bf1",
       "IPY_MODEL_82a19fe3427542d38429d1b8ccaa931d"
      ],
      "layout": "IPY_MODEL_3a643aebf84147d2baec20687a8d467e"
     }
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
